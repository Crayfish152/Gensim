{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Word2Vec Model\n",
    "==============\n",
    "\n",
    "Introduces Gensim's Word2Vec model and demonstrates its use on the `Lee Evaluation Corpus\n",
    "<https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf>`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T05:49:13.016881100Z",
     "start_time": "2024-05-07T05:49:13.002864Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you missed the buzz, Word2Vec is a widely used algorithm based on neural\n",
    "networks, commonly referred to as \"deep learning\" (though word2vec itself is rather shallow).\n",
    "Using large amounts of unannotated plain text, word2vec learns relationships\n",
    "between words automatically. The output are vectors, one vector per word,\n",
    "with remarkable linear relationships that allow us to do things like:\n",
    "\n",
    "* vec(\"king\") - vec(\"man\") + vec(\"woman\") =~ vec(\"queen\")\n",
    "* vec(\"Montreal Canadiens\") – vec(\"Montreal\") + vec(\"Toronto\") =~ vec(\"Toronto Maple Leafs\").\n",
    "\n",
    "Word2vec is very useful in `automatic text tagging\n",
    "<https://github.com/RaRe-Technologies/movie-plots-by-genre>`_\\ , recommender\n",
    "systems and machine translation.\n",
    "\n",
    "This tutorial:\n",
    "\n",
    "#. Introduces ``Word2Vec`` as an improvement over traditional bag-of-words\n",
    "#. Shows off a demo of ``Word2Vec`` using a pre-trained model\n",
    "#. Demonstrates training a new model from your own data\n",
    "#. Demonstrates loading and saving models\n",
    "#. Introduces several training parameters and demonstrates their effect\n",
    "#. Discusses memory requirements\n",
    "#. Visualizes Word2Vec embeddings by applying dimensionality reduction\n",
    "\n",
    "Review: Bag-of-words\n",
    "--------------------\n",
    "\n",
    ".. Note:: Feel free to skip these review sections if you're already familiar with the models.\n",
    "\n",
    "You may be familiar with the `bag-of-words model\n",
    "<https://en.wikipedia.org/wiki/Bag-of-words_model>`_ from the\n",
    "`core_concepts_vector` section.\n",
    "This model transforms each document to a fixed-length vector of integers.\n",
    "For example, given the sentences:\n",
    "\n",
    "- ``John likes to watch movies. Mary likes movies too.``\n",
    "- ``John also likes to watch football games. Mary hates football.``\n",
    "\n",
    "The model outputs the vectors:\n",
    "\n",
    "- ``[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]``\n",
    "- ``[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]``\n",
    "\n",
    "Each vector has 10 elements, where each element counts the number of times a\n",
    "particular word occurred in the document.\n",
    "The order of elements is arbitrary.\n",
    "In the example above, the order of the elements corresponds to the words:\n",
    "``[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\", \"hates\"]``.\n",
    "\n",
    "Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "\n",
    "First, they lose all information about word order: \"John likes Mary\" and\n",
    "\"Mary likes John\" correspond to identical vectors. There is a solution: bag\n",
    "of `n-grams <https://en.wikipedia.org/wiki/N-gram>`__\n",
    "models consider word phrases of length n to represent documents as\n",
    "fixed-length vectors to capture local word order but suffer from data\n",
    "sparsity and high dimensionality.\n",
    "\n",
    "Second, the model does not attempt to learn the meaning of the underlying\n",
    "words, and as a consequence, the distance between vectors doesn't always\n",
    "reflect the difference in meaning.  The ``Word2Vec`` model addresses this\n",
    "second problem.\n",
    "\n",
    "Introducing: the ``Word2Vec`` Model\n",
    "-----------------------------------\n",
    "\n",
    "``Word2Vec`` is a more recent model that embeds words in a lower-dimensional\n",
    "vector space using a shallow neural network. The result is a set of\n",
    "word-vectors where vectors close together in vector space have similar\n",
    "meanings based on context, and word-vectors distant to each other have\n",
    "differing meanings. For example, ``strong`` and ``powerful`` would be close\n",
    "together and ``strong`` and ``Paris`` would be relatively far.\n",
    "\n",
    "The are two versions of this model and :py:class:`~gensim.models.word2vec.Word2Vec`\n",
    "class implements them both:\n",
    "\n",
    "1. Skip-grams (SG)\n",
    "2. Continuous-bag-of-words (CBOW)\n",
    "\n",
    ".. Important::\n",
    "  Don't let the implementation details below scare you.\n",
    "  They're advanced material: if it's too much, then move on to the next section.\n",
    "\n",
    "The `Word2Vec Skip-gram <http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model>`__\n",
    "model, for example, takes in pairs (word1, word2) generated by moving a\n",
    "window across text data, and trains a 1-hidden-layer neural network based on\n",
    "the synthetic task of given an input word, giving us a predicted probability\n",
    "distribution of nearby words to the input. A virtual `one-hot\n",
    "<https://en.wikipedia.org/wiki/One-hot>`__ encoding of words\n",
    "goes through a 'projection layer' to the hidden layer; these projection\n",
    "weights are later interpreted as the word embeddings. So if the hidden layer\n",
    "has 300 neurons, this network will give us 300-dimensional word embeddings.\n",
    "\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It\n",
    "is also a 1-hidden-layer neural network. The synthetic training task now uses\n",
    "the average of multiple input context words, rather than a single word as in\n",
    "skip-gram, to predict the center word. Again, the projection weights that\n",
    "turn one-hot words into averageable vectors, of the same width as the hidden\n",
    "layer, are interpreted as the word embeddings.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec Demo\n",
    "-------------\n",
    "\n",
    "To see what ``Word2Vec`` can do, let's download a pre-trained model and play\n",
    "around with it. We will fetch the Word2Vec model trained on part of the\n",
    "Google News dataset, covering approximately 3 million words and phrases. Such\n",
    "a model can take hours to train, but since it's already available,\n",
    "downloading and loading it with Gensim takes minutes.\n",
    "\n",
    ".. Important::\n",
    "  The model is approximately 2GB, so you'll need a decent network connection\n",
    "  to proceed.  Otherwise, skip ahead to the \"Training Your Own Model\" section\n",
    "  below.\n",
    "\n",
    "You may also check out an `online word2vec demo\n",
    "<http://radimrehurek.com/2014/02/word2vec-tutorial/#app>`_ where you can try\n",
    "this vector algebra for yourself. That demo runs ``word2vec`` on the\n",
    "**entire** Google News dataset, of **about 100 billion words**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:02:49.142447900Z",
     "start_time": "2024-05-07T05:55:32.135515100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 13:55:33,347 : INFO : Creating C:\\Users\\017731431/gensim-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.4% 1653.6/1662.8MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:00:39,714 : INFO : word2vec-google-news-300 downloaded\n",
      "2024-05-07 14:00:39,719 : INFO : loading projection weights from C:\\Users\\017731431/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2024-05-07 14:02:18,344 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\017731431/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-05-07T14:02:18.326823', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation is to retrieve the vocabulary of a model. That is trivial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:04:01.040647300Z",
     "start_time": "2024-05-07T06:04:00.993352600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily obtain vectors for terms the model is familiar with:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:04:49.111872800Z",
     "start_time": "2024-05-07T06:04:49.083947900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
      " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
      "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
      " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
      "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
      "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
      "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
      "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
      "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
      "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
      "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
      "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
      " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
      " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
      " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
      "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
      "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
      " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
      " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
      " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
      "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
      "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
      "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
      " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
      " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
      "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
      " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
      "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
      " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
      " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
      "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
      " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
      " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
      "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
      " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
      "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
      "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
      " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
      " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
      " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
      " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
      " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
      "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
      "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
      "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
      " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
      "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
      "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
      " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
      " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
      " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
      "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
      "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
      " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
      "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
      " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
      "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
      "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
      " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
      "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
      "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
      "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
      "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
      "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
      " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
      "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
      " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
      "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
      "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
      " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
      "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
      "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
      "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
      " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
      " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
     ]
    }
   ],
   "source": [
    "vec_king = wv['king']\n",
    "print(vec_king)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model is unable to infer vectors for unfamiliar words.\n",
    "This is one limitation of Word2Vec: if this limitation matters to you, check\n",
    "out the FastText model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:05:08.877296900Z",
     "start_time": "2024-05-07T06:05:08.851631300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, ``Word2Vec`` supports several word similarity tasks out of the\n",
    "box.  You can see how the similarity intuitively decreases as the words get\n",
    "less and less similar.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:08:02.384500200Z",
     "start_time": "2024-05-07T06:08:02.338659400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 5 most similar words to \"car\" or \"minivan\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:09:35.369786900Z",
     "start_time": "2024-05-07T06:08:50.784636500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532191514968872), ('vehicle', 0.8175783753395081), ('pickup_truck', 0.7763689160346985), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565719485282898)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the below does not belong in the sequence?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:09:40.137540600Z",
     "start_time": "2024-05-07T06:09:40.050816200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Your Own Model\n",
    "-----------------------\n",
    "\n",
    "To start, you'll need some data for training the model. For the following\n",
    "examples, we'll use the `Lee Evaluation Corpus\n",
    "<https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf>`_\n",
    "(which you `already have\n",
    "<https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/lee_background.cor>`_\n",
    "if you've installed Gensim).\n",
    "\n",
    "This corpus is small enough to fit entirely in memory, but we'll implement a\n",
    "memory-friendly iterator that reads it line-by-line to demonstrate how you\n",
    "would handle a larger corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:09:54.685504900Z",
     "start_time": "2024-05-07T06:09:54.474256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:09:54,525 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2024-05-07 14:09:54,527 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2024-05-07 14:09:54,530 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\", 'datetime': '2024-05-07T14:09:54.529160', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to do any custom preprocessing, e.g. decode a non-standard\n",
    "encoding, lowercase, remove numbers, extract named entities... All of this can\n",
    "be done inside the ``MyCorpus`` iterator and ``word2vec`` doesn’t need to\n",
    "know. All that is required is that the input yields one sentence (list of\n",
    "utf8 words) after another.\n",
    "\n",
    "Let's go ahead and train a model on our corpus.  Don't worry about the\n",
    "training parameters much for now, we'll revisit them later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:11:07.164717400Z",
     "start_time": "2024-05-07T06:11:06.128318100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:11:06,148 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:11:06,150 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:11:06,287 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2024-05-07 14:11:06,289 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:11:06,299 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.068041827818366%% of original 6981, drops 5231)', 'datetime': '2024-05-07T14:11:06.299867', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:11:06,300 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.83801073049938%% of original 58152, drops 8817)', 'datetime': '2024-05-07T14:11:06.300855', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:11:06,316 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2024-05-07 14:11:06,320 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2024-05-07 14:11:06,321 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2024-05-07T14:11:06.321939', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:11:06,355 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2024-05-07 14:11:06,356 : INFO : resetting layer weights\n",
      "2024-05-07 14:11:06,365 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:11:06.365685', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:11:06,367 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:11:06.367680', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:11:06,544 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:11:06,544 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:11:06,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:11:06,554 : INFO : EPOCH - 1 : training on 58152 raw words (35883 effective words) took 0.2s, 207604 effective words/s\n",
      "2024-05-07 14:11:06,691 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:11:06,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:11:06,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:11:06,701 : INFO : EPOCH - 2 : training on 58152 raw words (35909 effective words) took 0.1s, 254067 effective words/s\n",
      "2024-05-07 14:11:06,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:11:06,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:11:06,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:11:06,861 : INFO : EPOCH - 3 : training on 58152 raw words (36011 effective words) took 0.2s, 233142 effective words/s\n",
      "2024-05-07 14:11:06,995 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:11:06,996 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:11:07,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:11:07,014 : INFO : EPOCH - 4 : training on 58152 raw words (35955 effective words) took 0.1s, 251955 effective words/s\n",
      "2024-05-07 14:11:07,130 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:11:07,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:11:07,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:11:07,141 : INFO : EPOCH - 5 : training on 58152 raw words (35937 effective words) took 0.1s, 291569 effective words/s\n",
      "2024-05-07 14:11:07,142 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179695 effective words) took 0.8s, 231948 effective words/s', 'datetime': '2024-05-07T14:11:07.142767', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:11:07,143 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1750, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:11:07.143765', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model, we can use it in the same way as in the demo above.\n",
    "\n",
    "The main part of the model is ``model.wv``\\ , where \"wv\" stands for \"word vectors\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:11:57.393971800Z",
     "start_time": "2024-05-07T06:11:57.368017900Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_king = model.wv['king']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the vocabulary works the same way:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:12:04.336697300Z",
     "start_time": "2024-05-07T06:12:04.277339600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing and loading models\n",
    "--------------------------\n",
    "\n",
    "You'll notice that training non-trivial models can take time.  Once you've\n",
    "trained your model and it works as expected, you can save it to disk.  That\n",
    "way, you don't have to spend time training it all over again later.\n",
    "\n",
    "You can store/load models using the standard gensim methods:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:12:23.658460500Z",
     "start_time": "2024-05-07T06:12:23.301339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:12:23,301 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\017731~1\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-725bqza5', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-05-07T14:12:23.301339', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2024-05-07 14:12:23,308 : INFO : not storing attribute cum_table\n",
      "2024-05-07 14:12:23,325 : INFO : saved C:\\Users\\017731~1\\AppData\\Local\\Temp\\gensim-model-725bqza5\n",
      "2024-05-07 14:12:23,325 : INFO : loading Word2Vec object from C:\\Users\\017731~1\\AppData\\Local\\Temp\\gensim-model-725bqza5\n",
      "2024-05-07 14:12:23,337 : INFO : loading wv recursively from C:\\Users\\017731~1\\AppData\\Local\\Temp\\gensim-model-725bqza5.wv.* with mmap=None\n",
      "2024-05-07 14:12:23,339 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-07 14:12:23,383 : INFO : Word2Vec lifecycle event {'fname': 'C:\\\\Users\\\\017731~1\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-725bqza5', 'datetime': '2024-05-07T14:12:23.383498', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which uses pickle internally, optionally ``mmap``\\ ‘ing the model’s internal\n",
    "large NumPy matrices into virtual memory directly from disk files, for\n",
    "inter-process memory sharing.\n",
    "\n",
    "In addition, you can load models created by the original C tool, both using\n",
    "its text and binary formats::\n",
    "\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.txt', binary=False)\n",
    "  # using gzipped/bz2 input works too, no need to unzip\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.bin.gz', binary=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters\n",
    "-------------------\n",
    "\n",
    "``Word2Vec`` accepts several parameters that affect both training speed and quality.\n",
    "\n",
    "min_count\n",
    "---------\n",
    "\n",
    "``min_count`` is for pruning the internal dictionary. Words that appear only\n",
    "once or twice in a billion-word corpus are probably uninteresting typos and\n",
    "garbage. In addition, there’s not enough data to make any meaningful training\n",
    "on those words, so it’s best to ignore them:\n",
    "\n",
    "default value of min_count=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:16:33.573698100Z",
     "start_time": "2024-05-07T06:16:32.654742600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:16:32,651 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:16:32,653 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:16:32,794 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2024-05-07 14:16:32,796 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:16:32,805 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 889 unique words (12.734565248531728%% of original 6981, drops 6092)', 'datetime': '2024-05-07T14:16:32.805913', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:16:32,806 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 43776 word corpus (75.2785802723896%% of original 58152, drops 14376)', 'datetime': '2024-05-07T14:16:32.806888', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:16:32,814 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2024-05-07 14:16:32,815 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2024-05-07 14:16:32,815 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 29691.39528319831 word corpus (67.8%% of prior 43776)', 'datetime': '2024-05-07T14:16:32.815857', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:16:32,828 : INFO : estimated required memory for 889 words and 100 dimensions: 1155700 bytes\n",
      "2024-05-07 14:16:32,830 : INFO : resetting layer weights\n",
      "2024-05-07 14:16:32,835 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:16:32.835100', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:16:32,836 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 889 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:16:32.836822', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:16:33,000 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:33,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:33,015 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:33,016 : INFO : EPOCH - 1 : training on 58152 raw words (29735 effective words) took 0.2s, 171730 effective words/s\n",
      "2024-05-07 14:16:33,139 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:33,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:33,152 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:33,153 : INFO : EPOCH - 2 : training on 58152 raw words (29761 effective words) took 0.1s, 220952 effective words/s\n",
      "2024-05-07 14:16:33,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:33,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:33,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:33,306 : INFO : EPOCH - 3 : training on 58152 raw words (29660 effective words) took 0.1s, 204199 effective words/s\n",
      "2024-05-07 14:16:33,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:33,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:33,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:33,438 : INFO : EPOCH - 4 : training on 58152 raw words (29620 effective words) took 0.1s, 237445 effective words/s\n",
      "2024-05-07 14:16:33,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:33,551 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:33,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:33,557 : INFO : EPOCH - 5 : training on 58152 raw words (29668 effective words) took 0.1s, 253245 effective words/s\n",
      "2024-05-07 14:16:33,558 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (148444 effective words) took 0.7s, 206527 effective words/s', 'datetime': '2024-05-07T14:16:33.558539', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:16:33,558 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=889, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:16:33.558539', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector_size\n",
    "-----------\n",
    "\n",
    "``vector_size`` is the number of dimensions (N) of the N-dimensional space that\n",
    "gensim Word2Vec maps the words onto.\n",
    "\n",
    "Bigger size values require more training data, but can lead to better (more\n",
    "accurate) models. Reasonable values are in the tens to hundreds.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:16:52.570534700Z",
     "start_time": "2024-05-07T06:16:51.585936300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:16:51,573 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:16:51,584 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:16:51,722 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2024-05-07 14:16:51,723 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:16:51,741 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.068041827818366%% of original 6981, drops 5231)', 'datetime': '2024-05-07T14:16:51.741521', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:16:51,742 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.83801073049938%% of original 58152, drops 8817)', 'datetime': '2024-05-07T14:16:51.742521', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:16:51,757 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2024-05-07 14:16:51,758 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2024-05-07 14:16:51,760 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2024-05-07T14:16:51.760816', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:16:51,782 : INFO : estimated required memory for 1750 words and 200 dimensions: 3675000 bytes\n",
      "2024-05-07 14:16:51,783 : INFO : resetting layer weights\n",
      "2024-05-07 14:16:51,786 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:16:51.786942', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:16:51,787 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:16:51.787942', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:16:51,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:51,915 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:51,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:51,923 : INFO : EPOCH - 1 : training on 58152 raw words (35883 effective words) took 0.1s, 268837 effective words/s\n",
      "2024-05-07 14:16:52,052 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:52,053 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:52,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:52,065 : INFO : EPOCH - 2 : training on 58152 raw words (35909 effective words) took 0.1s, 257515 effective words/s\n",
      "2024-05-07 14:16:52,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:52,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:52,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:52,200 : INFO : EPOCH - 3 : training on 58152 raw words (36011 effective words) took 0.1s, 272606 effective words/s\n",
      "2024-05-07 14:16:52,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:52,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:52,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:52,369 : INFO : EPOCH - 4 : training on 58152 raw words (35955 effective words) took 0.2s, 218038 effective words/s\n",
      "2024-05-07 14:16:52,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:16:52,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:16:52,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:16:52,538 : INFO : EPOCH - 5 : training on 58152 raw words (35937 effective words) took 0.2s, 225799 effective words/s\n",
      "2024-05-07 14:16:52,538 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179695 effective words) took 0.8s, 239434 effective words/s', 'datetime': '2024-05-07T14:16:52.538806', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:16:52,539 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1750, vector_size=200, alpha=0.025)', 'datetime': '2024-05-07T14:16:52.539817', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# The default value of vector_size is 100.\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workers\n",
    "-------\n",
    "\n",
    "``workers`` , the last of the major parameters (full list `here\n",
    "<http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec>`_)\n",
    "is for training parallelization, to speed up training:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:17:15.568553600Z",
     "start_time": "2024-05-07T06:17:14.720311900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:17:14,717 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:17:14,719 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:17:14,824 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2024-05-07 14:17:14,826 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:17:14,839 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.068041827818366%% of original 6981, drops 5231)', 'datetime': '2024-05-07T14:17:14.838392', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:17:14,840 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.83801073049938%% of original 58152, drops 8817)', 'datetime': '2024-05-07T14:17:14.840353', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:17:14,853 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2024-05-07 14:17:14,854 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2024-05-07 14:17:14,854 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2024-05-07T14:17:14.854392', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:17:14,881 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2024-05-07 14:17:14,882 : INFO : resetting layer weights\n",
      "2024-05-07 14:17:14,884 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:17:14.884635', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:17:14,885 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:17:14.885624', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:17:15,016 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2024-05-07 14:17:15,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:17:15,017 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:17:15,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:17:15,027 : INFO : EPOCH - 1 : training on 58152 raw words (35883 effective words) took 0.1s, 264208 effective words/s\n",
      "2024-05-07 14:17:15,130 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2024-05-07 14:17:15,131 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:17:15,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:17:15,137 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:17:15,138 : INFO : EPOCH - 2 : training on 58152 raw words (35909 effective words) took 0.1s, 335554 effective words/s\n",
      "2024-05-07 14:17:15,261 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2024-05-07 14:17:15,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:17:15,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:17:15,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:17:15,275 : INFO : EPOCH - 3 : training on 58152 raw words (36011 effective words) took 0.1s, 270848 effective words/s\n",
      "2024-05-07 14:17:15,408 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2024-05-07 14:17:15,409 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:17:15,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:17:15,416 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:17:15,416 : INFO : EPOCH - 4 : training on 58152 raw words (35955 effective words) took 0.1s, 263970 effective words/s\n",
      "2024-05-07 14:17:15,531 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2024-05-07 14:17:15,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:17:15,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:17:15,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:17:15,540 : INFO : EPOCH - 5 : training on 58152 raw words (35937 effective words) took 0.1s, 295661 effective words/s\n",
      "2024-05-07 14:17:15,541 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179695 effective words) took 0.7s, 274596 effective words/s', 'datetime': '2024-05-07T14:17:15.541361', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:17:15,541 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1750, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:17:15.541361', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# default value of workers=3 (tutorial says 1...)\n",
    "model = gensim.models.Word2Vec(sentences, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``workers`` parameter only has an effect if you have `Cython\n",
    "<http://cython.org/>`_ installed. Without Cython, you’ll only be able to use\n",
    "one core because of the `GIL\n",
    "<https://wiki.python.org/moin/GlobalInterpreterLock>`_ (and ``word2vec``\n",
    "training will be `miserably slow\n",
    "<http://rare-technologies.com/word2vec-in-python-part-two-optimizing/>`_\\ ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory\n",
    "------\n",
    "\n",
    "At its core, ``word2vec`` model parameters are stored as matrices (NumPy\n",
    "arrays). Each array is **#vocabulary** (controlled by the ``min_count`` parameter)\n",
    "times **vector size** (the ``vector_size`` parameter) of floats (single precision aka 4 bytes).\n",
    "\n",
    "Three such matrices are held in RAM (work is underway to reduce that number\n",
    "to two, or even one). So if your input contains 100,000 unique words, and you\n",
    "asked for layer ``vector_size=200``\\ , the model will require approx.\n",
    "``100,000*200*4*3 bytes = ~229MB``.\n",
    "\n",
    "There’s a little extra memory needed for storing the vocabulary tree (100,000 words would\n",
    "take a few megabytes), but unless your words are extremely loooong strings, memory\n",
    "footprint will be dominated by the three matrices above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating\n",
    "----------\n",
    "\n",
    "``Word2Vec`` training is an unsupervised task, there’s no good way to\n",
    "objectively evaluate the result. Evaluation depends on your end application.\n",
    "\n",
    "Google has released their testing set of about 20,000 syntactic and semantic\n",
    "test examples, following the “A is to B as C is to D” task. It is provided in\n",
    "the 'datasets' folder.\n",
    "\n",
    "For example a syntactic analogy of comparative type is ``bad:worse;good:?``.\n",
    "There are total of 9 types of syntactic comparisons in the dataset like\n",
    "plural nouns and nouns of opposite meaning.\n",
    "\n",
    "The semantic questions contain five types of semantic analogies, such as\n",
    "capital cities (``Paris:France;Tokyo:?``) or family members\n",
    "(``brother:sister;dad:?``).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim supports the same evaluation set, in exactly the same format:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:18:33.580667900Z",
     "start_time": "2024-05-07T06:18:33.176529500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:18:33,173 : INFO : Evaluating word analogies for top 300000 words in the model on C:\\Users\\017731431\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\questions-words.txt\n",
      "2024-05-07 14:18:33,190 : INFO : capital-common-countries: 0.0% (0/6)\n",
      "2024-05-07 14:18:33,216 : INFO : capital-world: 0.0% (0/2)\n",
      "2024-05-07 14:18:33,237 : INFO : family: 0.0% (0/6)\n",
      "2024-05-07 14:18:33,270 : INFO : gram3-comparative: 0.0% (0/20)\n",
      "2024-05-07 14:18:33,280 : INFO : gram4-superlative: 0.0% (0/12)\n",
      "2024-05-07 14:18:33,291 : INFO : gram5-present-participle: 0.0% (0/20)\n",
      "2024-05-07 14:18:33,305 : INFO : gram6-nationality-adjective: 0.0% (0/30)\n",
      "2024-05-07 14:18:33,319 : INFO : gram7-past-tense: 0.0% (0/20)\n",
      "2024-05-07 14:18:33,333 : INFO : gram8-plural: 0.0% (0/30)\n",
      "2024-05-07 14:18:33,338 : INFO : Quadruplets with out-of-vocabulary words: 99.3%\n",
      "2024-05-07 14:18:33,340 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2024-05-07 14:18:33,340 : INFO : Total accuracy: 0.0% (0/146)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.0,\n [{'section': 'capital-common-countries',\n   'correct': [],\n   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN')]},\n  {'section': 'capital-world',\n   'correct': [],\n   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE')]},\n  {'section': 'currency', 'correct': [], 'incorrect': []},\n  {'section': 'city-in-state', 'correct': [], 'incorrect': []},\n  {'section': 'family',\n   'correct': [],\n   'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n    ('HE', 'SHE', 'MAN', 'WOMAN'),\n    ('HIS', 'HER', 'MAN', 'WOMAN'),\n    ('HIS', 'HER', 'HE', 'SHE'),\n    ('MAN', 'WOMAN', 'HE', 'SHE'),\n    ('MAN', 'WOMAN', 'HIS', 'HER')]},\n  {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []},\n  {'section': 'gram2-opposite', 'correct': [], 'incorrect': []},\n  {'section': 'gram3-comparative',\n   'correct': [],\n   'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n    ('SMALL', 'SMALLER', 'LOW', 'LOWER')]},\n  {'section': 'gram4-superlative',\n   'correct': [],\n   'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')]},\n  {'section': 'gram5-present-participle',\n   'correct': [],\n   'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n    ('GO', 'GOING', 'RUN', 'RUNNING'),\n    ('GO', 'GOING', 'SAY', 'SAYING'),\n    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n    ('RUN', 'RUNNING', 'GO', 'GOING'),\n    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n    ('SAY', 'SAYING', 'GO', 'GOING'),\n    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n    ('SAY', 'SAYING', 'RUN', 'RUNNING')]},\n  {'section': 'gram6-nationality-adjective',\n   'correct': [],\n   'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE')]},\n  {'section': 'gram7-past-tense',\n   'correct': [],\n   'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n    ('GOING', 'WENT', 'SAYING', 'SAID'),\n    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n    ('PAYING', 'PAID', 'GOING', 'WENT'),\n    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n    ('SAYING', 'SAID', 'GOING', 'WENT'),\n    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n    ('TAKING', 'TOOK', 'SAYING', 'SAID')]},\n  {'section': 'gram8-plural',\n   'correct': [],\n   'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n    ('CAR', 'CARS', 'MAN', 'MEN'),\n    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n    ('MAN', 'MEN', 'CAR', 'CARS'),\n    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]},\n  {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []},\n  {'section': 'Total accuracy',\n   'correct': [],\n   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN'),\n    ('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n    ('HE', 'SHE', 'HIS', 'HER'),\n    ('HE', 'SHE', 'MAN', 'WOMAN'),\n    ('HIS', 'HER', 'MAN', 'WOMAN'),\n    ('HIS', 'HER', 'HE', 'SHE'),\n    ('MAN', 'WOMAN', 'HE', 'SHE'),\n    ('MAN', 'WOMAN', 'HIS', 'HER'),\n    ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n    ('SMALL', 'SMALLER', 'LOW', 'LOWER'),\n    ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n    ('GO', 'GOING', 'LOOK', 'LOOKING'),\n    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n    ('GO', 'GOING', 'RUN', 'RUNNING'),\n    ('GO', 'GOING', 'SAY', 'SAYING'),\n    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n    ('RUN', 'RUNNING', 'GO', 'GOING'),\n    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n    ('SAY', 'SAYING', 'GO', 'GOING'),\n    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n    ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE'),\n    ('GOING', 'WENT', 'PAYING', 'PAID'),\n    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n    ('GOING', 'WENT', 'SAYING', 'SAID'),\n    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n    ('PAYING', 'PAID', 'GOING', 'WENT'),\n    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n    ('SAYING', 'SAID', 'GOING', 'WENT'),\n    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n    ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n    ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n    ('CAR', 'CARS', 'MAN', 'MEN'),\n    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n    ('MAN', 'MEN', 'CAR', 'CARS'),\n    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]}])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ``evaluate_word_analogies`` method takes an `optional parameter\n",
    "<http://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.evaluate_word_analogies>`_\n",
    "``restrict_vocab`` which limits which test examples are to be considered.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.\n",
    "\n",
    "By default it uses an academic dataset WS-353 but one can create a dataset\n",
    "specific to your business based on it. It contains word pairs together with\n",
    "human-assigned similarity judgments. It measures the relatedness or\n",
    "co-occurrence of two words. For example, 'coast' and 'shore' are very similar\n",
    "as they appear in the same context. At the same time 'clothes' and 'closet'\n",
    "are less similar because they are related but not interchangeable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:19:34.275741Z",
     "start_time": "2024-05-07T06:19:34.137108900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:19:34,223 : INFO : Pearson correlation coefficient against C:\\Users\\017731431\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\wordsim353.tsv: 0.1535\n",
      "2024-05-07 14:19:34,224 : INFO : Spearman rank-order correlation coefficient against C:\\Users\\017731431\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\wordsim353.tsv: 0.1137\n",
      "2024-05-07 14:19:34,225 : INFO : Pairs with unknown words ratio: 83.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": "((0.15346525506572328, 0.2417271226971635),\n SpearmanrResult(correlation=0.1137140482223238, pvalue=0.38698000921784215),\n 83.0028328611898)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Important::\n",
    "  Good performance on Google's or WS-353 test set doesn’t mean word2vec will\n",
    "  work well in your application, or vice versa. It’s always best to evaluate\n",
    "  directly on your intended task. For an example of how to use word2vec in a\n",
    "  classifier pipeline, see this `tutorial\n",
    "  <https://github.com/RaRe-Technologies/movie-plots-by-genre>`_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online training / Resuming training\n",
    "-----------------------------------\n",
    "\n",
    "Advanced users can load a model and continue training it with more sentences\n",
    "and `new vocabulary words <online_w2v_tutorial.ipynb>`_:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:20:28.753561100Z",
     "start_time": "2024-05-07T06:20:28.490868400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:20:28,491 : INFO : loading Word2Vec object from C:\\Users\\017731~1\\AppData\\Local\\Temp\\gensim-model-725bqza5\n",
      "2024-05-07 14:20:28,494 : INFO : loading wv recursively from C:\\Users\\017731~1\\AppData\\Local\\Temp\\gensim-model-725bqza5.wv.* with mmap=None\n",
      "2024-05-07 14:20:28,496 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-07 14:20:28,527 : INFO : Word2Vec lifecycle event {'fname': 'C:\\\\Users\\\\017731~1\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-725bqza5', 'datetime': '2024-05-07T14:20:28.527840', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'loaded'}\n",
      "2024-05-07 14:20:28,530 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:20:28,532 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:20:28,534 : INFO : collected 13 word types from a corpus of 13 raw words and 1 sentences\n",
      "2024-05-07 14:20:28,535 : INFO : Updating model with new vocabulary\n",
      "2024-05-07 14:20:28,546 : INFO : Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.0%% of original 13) and increased the count of 0 pre-existing words (0.0%% of original 13)', 'datetime': '2024-05-07T14:20:28.546554', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:20:28,547 : INFO : deleting the raw counts dictionary of 13 items\n",
      "2024-05-07 14:20:28,548 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2024-05-07 14:20:28,553 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 0 word corpus (0.0%% of prior 0)', 'datetime': '2024-05-07T14:20:28.553588', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:20:28,576 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2024-05-07 14:20:28,577 : INFO : updating layer weights\n",
      "2024-05-07 14:20:28,578 : INFO : Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2024-05-07T14:20:28.578657', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:20:28,580 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2024-05-07 14:20:28,581 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:20:28.581652', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:20:28,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:20:28,590 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:20:28,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:20:28,591 : INFO : EPOCH - 1 : training on 13 raw words (6 effective words) took 0.0s, 2323 effective words/s\n",
      "2024-05-07 14:20:28,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:20:28,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:20:28,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:20:28,603 : INFO : EPOCH - 2 : training on 13 raw words (5 effective words) took 0.0s, 588 effective words/s\n",
      "2024-05-07 14:20:28,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:20:28,615 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:20:28,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:20:28,622 : INFO : EPOCH - 3 : training on 13 raw words (5 effective words) took 0.0s, 485 effective words/s\n",
      "2024-05-07 14:20:28,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:20:28,627 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:20:28,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:20:28,628 : INFO : EPOCH - 4 : training on 13 raw words (6 effective words) took 0.0s, 2454 effective words/s\n",
      "2024-05-07 14:20:28,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:20:28,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:20:28,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:20:28,642 : INFO : EPOCH - 5 : training on 13 raw words (5 effective words) took 0.0s, 1076 effective words/s\n",
      "2024-05-07 14:20:28,643 : INFO : Word2Vec lifecycle event {'msg': 'training on 65 raw words (27 effective words) took 0.1s, 448 effective words/s', 'datetime': '2024-05-07T14:20:28.643485', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences'],\n",
    "]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# cleaning up temporary file\n",
    "import os\n",
    "os.remove(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to tweak the ``total_words`` parameter to ``train()``,\n",
    "depending on what learning rate decay you want to simulate.\n",
    "\n",
    "Note that it’s not possible to resume training with models generated by the C\n",
    "tool, ``KeyedVectors.load_word2vec_format()``. You can still use them for\n",
    "querying/similarity, but information vital for training (the vocab tree) is\n",
    "missing there.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loss Computation\n",
    "-------------------------\n",
    "\n",
    "The parameter ``compute_loss`` can be used to toggle computation of loss\n",
    "while training the Word2Vec model. The computed loss is stored in the model\n",
    "attribute ``running_training_loss`` and can be retrieved using the function\n",
    "``get_latest_training_loss`` as follows :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:21:06.688949700Z",
     "start_time": "2024-05-07T06:21:04.823366100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:21:04,820 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:21:04,821 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:21:04,935 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2024-05-07 14:21:04,936 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:21:04,973 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 6981 unique words (100.0%% of original 6981, drops 0)', 'datetime': '2024-05-07T14:21:04.973445', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:21:04,974 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 58152 word corpus (100.0%% of original 58152, drops 0)', 'datetime': '2024-05-07T14:21:04.974443', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:21:05,034 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2024-05-07 14:21:05,035 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2024-05-07 14:21:05,036 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 45723.4541622429 word corpus (78.6%% of prior 58152)', 'datetime': '2024-05-07T14:21:05.036805', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:21:05,122 : INFO : estimated required memory for 6981 words and 100 dimensions: 9075300 bytes\n",
      "2024-05-07 14:21:05,123 : INFO : resetting layer weights\n",
      "2024-05-07 14:21:05,132 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:21:05.132564', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:21:05,133 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 6981 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:21:05.133560', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:21:05,326 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:21:05,340 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:21:05,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:21:05,364 : INFO : EPOCH - 1 : training on 58152 raw words (45666 effective words) took 0.2s, 199255 effective words/s\n",
      "2024-05-07 14:21:05,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:21:05,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:21:05,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:21:05,687 : INFO : EPOCH - 2 : training on 58152 raw words (45568 effective words) took 0.3s, 143059 effective words/s\n",
      "2024-05-07 14:21:06,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:21:06,059 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:21:06,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:21:06,121 : INFO : EPOCH - 3 : training on 58152 raw words (45760 effective words) took 0.4s, 108221 effective words/s\n",
      "2024-05-07 14:21:06,354 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:21:06,388 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:21:06,415 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:21:06,418 : INFO : EPOCH - 4 : training on 58152 raw words (45680 effective words) took 0.3s, 156353 effective words/s\n",
      "2024-05-07 14:21:06,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:21:06,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:21:06,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:21:06,671 : INFO : EPOCH - 5 : training on 58152 raw words (45658 effective words) took 0.2s, 182765 effective words/s\n",
      "2024-05-07 14:21:06,671 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (228332 effective words) took 1.5s, 148423 effective words/s', 'datetime': '2024-05-07T14:21:06.671994', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:21:06,672 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=6981, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:21:06.672985', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360887.75\n"
     ]
    }
   ],
   "source": [
    "# instantiating and training the Word2Vec model\n",
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks\n",
    "----------\n",
    "\n",
    "Let's run some benchmarks to see effect of the training loss computation code\n",
    "on training time.\n",
    "\n",
    "We'll use the following data for the benchmarks:\n",
    "\n",
    "#. Lee Background corpus: included in gensim's test data\n",
    "#. Text8 corpus.  To demonstrate the effect of corpus size, we'll look at the\n",
    "   first 1MB, 10MB, 50MB of the corpus, as well as the entire thing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:22:12.627570500Z",
     "start_time": "2024-05-07T06:21:25.371255700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:22:03,450 : INFO : text8 downloaded\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import gensim.downloader as api\n",
    "import smart_open\n",
    "\n",
    "\n",
    "def head(path, size):\n",
    "    with smart_open.open(path) as fin:\n",
    "        return io.StringIO(fin.read(size))\n",
    "\n",
    "\n",
    "def generate_input_data():\n",
    "    lee_path = datapath('lee_background.cor')\n",
    "    ls = gensim.models.word2vec.LineSentence(lee_path)\n",
    "    ls.name = '25kB'\n",
    "    yield ls\n",
    "\n",
    "    text8_path = api.load('text8').fn\n",
    "    labels = ('1MB', '10MB', '50MB', '100MB')\n",
    "    sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)\n",
    "    for l, s in zip(labels, sizes):\n",
    "        ls = gensim.models.word2vec.LineSentence(head(text8_path, s))\n",
    "        ls.name = l\n",
    "        yield ls\n",
    "\n",
    "\n",
    "input_data = list(generate_input_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the training time taken for different combinations of input\n",
    "data and model training parameters like ``hs`` and ``sg``.\n",
    "\n",
    "For each combination, we repeat the test several times to obtain the mean and\n",
    "standard deviation of the test duration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-07T06:35:43.646596200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:43,645 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:43,654 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:43,688 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:43,689 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:43,704 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:43.704750', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:43,705 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:43.705749', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:43,724 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:43,725 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:43,726 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:43.726737', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:43,751 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:43,752 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:43,755 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:43.755649', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:43,756 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:43.756646', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:43,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:43,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:43,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:43,827 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 488447 effective words/s\n",
      "2024-05-07 14:35:43,880 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:43,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:43,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:43,895 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 502471 effective words/s\n",
      "2024-05-07 14:35:43,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:43,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:43,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:43,952 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 641992 effective words/s\n",
      "2024-05-07 14:35:43,987 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:43,992 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:43,997 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:43,998 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 744880 effective words/s\n",
      "2024-05-07 14:35:44,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,051 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 639327 effective words/s\n",
      "2024-05-07 14:35:44,051 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 553722 effective words/s', 'datetime': '2024-05-07T14:35:44.051566', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:44,053 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:44.053099', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:44,063 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:44,064 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:44,093 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:44,094 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:44,111 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:44.111465', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:44,112 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:44.112463', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:44,127 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:44,130 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:44,132 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:44.132411', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:44,153 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:44,154 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:44,157 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:44.157427', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:44,157 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:44.157427', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:44,221 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,237 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,238 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 415882 effective words/s\n",
      "2024-05-07 14:35:44,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,369 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 257404 effective words/s\n",
      "2024-05-07 14:35:44,457 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,472 : INFO : EPOCH - 3 : training on 59890 raw words (32579 effective words) took 0.1s, 336205 effective words/s\n",
      "2024-05-07 14:35:44,534 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,549 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,550 : INFO : EPOCH - 4 : training on 59890 raw words (32589 effective words) took 0.1s, 426814 effective words/s\n",
      "2024-05-07 14:35:44,627 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,643 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,645 : INFO : EPOCH - 5 : training on 59890 raw words (32640 effective words) took 0.1s, 363162 effective words/s\n",
      "2024-05-07 14:35:44,649 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162903 effective words) took 0.5s, 331984 effective words/s', 'datetime': '2024-05-07T14:35:44.649495', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:44,650 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:44.650475', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:44,655 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:44,659 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:44,712 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:44,714 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:44,734 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:44.734688', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:44,736 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:44.735641', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:44,758 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:44,760 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:44,761 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:44.761490', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:44,794 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:44,795 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:44,801 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:44.801409', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:44,803 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:44.803402', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:44,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,888 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 430710 effective words/s\n",
      "2024-05-07 14:35:44,954 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:44,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:44,973 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:44,975 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 409106 effective words/s\n",
      "2024-05-07 14:35:45,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,057 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,058 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 415075 effective words/s\n",
      "2024-05-07 14:35:45,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,127 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,139 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,140 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 413272 effective words/s\n",
      "2024-05-07 14:35:45,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,217 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,220 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 420825 effective words/s\n",
      "2024-05-07 14:35:45,220 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 392030 effective words/s', 'datetime': '2024-05-07T14:35:45.220826', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:45,221 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:45.221832', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:45,223 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:45,224 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:45,255 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:45,255 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:45,277 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:45.277640', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:45,278 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:45.278637', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:45,300 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:45,304 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:45,305 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:45.305564', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:45,331 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:45,332 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:45,335 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:45.335481', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:45,335 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:45.335481', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:45,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,407 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #0: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.5260810057322184, 'train_time_std': 0.07717710351773173}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:45,408 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 462721 effective words/s\n",
      "2024-05-07 14:35:45,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,486 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 429320 effective words/s\n",
      "2024-05-07 14:35:45,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,562 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 443491 effective words/s\n",
      "2024-05-07 14:35:45,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,662 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 351807 effective words/s\n",
      "2024-05-07 14:35:45,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,728 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,743 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 447691 effective words/s\n",
      "2024-05-07 14:35:45,743 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 399612 effective words/s', 'datetime': '2024-05-07T14:35:45.743423', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:45,744 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:45.744435', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:45,745 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:45,748 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:45,803 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:45,804 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:45,818 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:45.818707', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:45,818 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:45.818707', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:45,837 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:45,839 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:45,841 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:45.841765', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:45,872 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:45,873 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:45,876 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:45.876556', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:45,877 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:45.877552', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:45,944 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:45,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:45,955 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:45,956 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 442762 effective words/s\n",
      "2024-05-07 14:35:46,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,053 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 343428 effective words/s\n",
      "2024-05-07 14:35:46,115 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,127 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 450523 effective words/s\n",
      "2024-05-07 14:35:46,191 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,207 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,208 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 416611 effective words/s\n",
      "2024-05-07 14:35:46,286 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,303 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 354478 effective words/s\n",
      "2024-05-07 14:35:46,304 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 381917 effective words/s', 'datetime': '2024-05-07T14:35:46.304778', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:46,306 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:46.305554', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:46,307 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:46,310 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:46,365 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:46,366 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:46,391 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:46.391530', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:46,392 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:46.392497', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:46,415 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:46,419 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:46,420 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:46.420601', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:46,453 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:46,455 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:46,458 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:46.458502', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:46,459 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:46.459495', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:46,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,531 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,541 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 441236 effective words/s\n",
      "2024-05-07 14:35:46,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,598 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,609 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 490826 effective words/s\n",
      "2024-05-07 14:35:46,670 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,691 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,692 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 410095 effective words/s\n",
      "2024-05-07 14:35:46,771 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,785 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,785 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 366319 effective words/s\n",
      "2024-05-07 14:35:46,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:46,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:46,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:46,882 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 350766 effective words/s\n",
      "2024-05-07 14:35:46,883 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 385588 effective words/s', 'datetime': '2024-05-07T14:35:46.883509', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:46,883 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:46.883509', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:46,885 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:46,886 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:46,924 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:46,924 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:46,942 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:46.942675', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:46,943 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:46.943760', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:46,965 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:46,967 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:46,968 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:46.968573', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:46,970 : INFO : constructing a huffman tree from 1762 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #1: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.5538877646128336, 'train_time_std': 0.02292401661280489}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:47,072 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:47,112 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:47,117 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:47,121 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:47.120454', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:47,121 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:47.121450', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:47,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:47,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:47,244 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:47,244 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 271400 effective words/s\n",
      "2024-05-07 14:35:47,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:47,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:47,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:47,352 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 313963 effective words/s\n",
      "2024-05-07 14:35:47,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:47,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:47,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:47,478 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 266141 effective words/s\n",
      "2024-05-07 14:35:47,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:47,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:47,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:47,624 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 233561 effective words/s\n",
      "2024-05-07 14:35:47,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:47,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:47,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:47,759 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 244710 effective words/s\n",
      "2024-05-07 14:35:47,760 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 255133 effective words/s', 'datetime': '2024-05-07T14:35:47.760785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:47,761 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:47.761801', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:47,765 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:47,770 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:47,809 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:47,809 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:47,825 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:47.825665', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:47,826 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:47.826670', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:47,851 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:47,853 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:47,854 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:47.854681', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:47,856 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:35:47,976 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:48,001 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:48,005 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:48,008 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:48.008583', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:48,009 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:48.009577', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:48,089 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,116 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,117 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 307692 effective words/s\n",
      "2024-05-07 14:35:48,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,219 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 325001 effective words/s\n",
      "2024-05-07 14:35:48,318 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,329 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,336 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 291203 effective words/s\n",
      "2024-05-07 14:35:48,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,438 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 330221 effective words/s\n",
      "2024-05-07 14:35:48,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,543 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,544 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 320063 effective words/s\n",
      "2024-05-07 14:35:48,545 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.5s, 304112 effective words/s', 'datetime': '2024-05-07T14:35:48.544653', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:48,550 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:48.550908', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:48,554 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:48,555 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:48,594 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:48,594 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:48,612 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:48.612785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:48,615 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:48.615785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:48,636 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:48,638 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:48,639 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:48.639704', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:48,640 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:35:48,706 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:48,728 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:48,729 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:48,735 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:48.735446', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:48,736 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:48.736439', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:48,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,846 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,847 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 300193 effective words/s\n",
      "2024-05-07 14:35:48,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:48,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:48,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:48,958 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 310507 effective words/s\n",
      "2024-05-07 14:35:49,055 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:49,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:49,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:49,077 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 277544 effective words/s\n",
      "2024-05-07 14:35:49,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:49,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:49,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:49,192 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 297877 effective words/s\n",
      "2024-05-07 14:35:49,274 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:49,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:49,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:49,291 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 335597 effective words/s\n",
      "2024-05-07 14:35:49,291 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 293422 effective words/s', 'datetime': '2024-05-07T14:35:49.291840', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:49,292 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:49.292836', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:49,293 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:49,295 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:49,368 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:49,368 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:49,394 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:49.394173', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:49,397 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:49.397719', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:49,430 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:49,437 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:49,440 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:49.440932', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:49,450 : INFO : constructing a huffman tree from 1762 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #2: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 0.8031094074249268, 'train_time_std': 0.05813979644289963}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:49,554 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:49,590 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:49,591 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:49,596 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:49.596982', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:49,601 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:49.601015', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:49,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:49,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:49,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:49,733 : INFO : EPOCH - 1 : training on 59890 raw words (32528 effective words) took 0.1s, 262149 effective words/s\n",
      "2024-05-07 14:35:49,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:49,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:49,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:49,852 : INFO : EPOCH - 2 : training on 59890 raw words (32557 effective words) took 0.1s, 288322 effective words/s\n",
      "2024-05-07 14:35:49,938 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:49,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:49,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:49,960 : INFO : EPOCH - 3 : training on 59890 raw words (32654 effective words) took 0.1s, 309796 effective words/s\n",
      "2024-05-07 14:35:50,060 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,067 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,075 : INFO : EPOCH - 4 : training on 59890 raw words (32527 effective words) took 0.1s, 306068 effective words/s\n",
      "2024-05-07 14:35:50,167 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,191 : INFO : EPOCH - 5 : training on 59890 raw words (32640 effective words) took 0.1s, 284239 effective words/s\n",
      "2024-05-07 14:35:50,192 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162906 effective words) took 0.6s, 276126 effective words/s', 'datetime': '2024-05-07T14:35:50.192764', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:50,192 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:50.192764', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:50,197 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:50,201 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:50,235 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:50,236 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:50,253 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:50.253586', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:50,255 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:50.255581', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:50,273 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:50,274 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:50,275 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:50.275696', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:50,277 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:35:50,352 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:50,375 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:50,376 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:50,379 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:50.379446', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:50,382 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:50.382403', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:50,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,489 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 315010 effective words/s\n",
      "2024-05-07 14:35:50,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,605 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 313074 effective words/s\n",
      "2024-05-07 14:35:50,702 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,715 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,728 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 269430 effective words/s\n",
      "2024-05-07 14:35:50,821 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,842 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,843 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 303604 effective words/s\n",
      "2024-05-07 14:35:50,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:50,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:50,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:50,959 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 301524 effective words/s\n",
      "2024-05-07 14:35:50,961 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 281457 effective words/s', 'datetime': '2024-05-07T14:35:50.961709', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:50,965 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:50.965694', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:50,967 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:50,968 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:51,003 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:51,004 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:51,020 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:51.020591', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:51,021 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:51.021574', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:51,042 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:51,044 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:51,046 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:51.046646', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:51,052 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:35:51,127 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:51,155 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:51,156 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:51,159 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:51.159031', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:51,159 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:51.159031', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:51,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:51,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:51,259 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:51,261 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 334678 effective words/s\n",
      "2024-05-07 14:35:51,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:51,375 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:51,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:51,386 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 310733 effective words/s\n",
      "2024-05-07 14:35:51,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:51,501 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:51,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:51,503 : INFO : EPOCH - 3 : training on 59890 raw words (32578 effective words) took 0.1s, 288191 effective words/s\n",
      "2024-05-07 14:35:51,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:51,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:51,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:51,619 : INFO : EPOCH - 4 : training on 59890 raw words (32597 effective words) took 0.1s, 284317 effective words/s\n",
      "2024-05-07 14:35:51,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:51,731 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:51,740 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:51,740 : INFO : EPOCH - 5 : training on 59890 raw words (32628 effective words) took 0.1s, 275017 effective words/s\n",
      "2024-05-07 14:35:51,741 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162898 effective words) took 0.6s, 279874 effective words/s', 'datetime': '2024-05-07T14:35:51.741650', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:51,742 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:51.742648', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:51,745 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:51,748 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:51,780 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:51,782 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:51,798 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:51.798489', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:51,799 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:51.799488', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:51,820 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:51,822 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:51,823 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:51.823544', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:51,851 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:51,852 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:51,855 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:51.855999', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:51,857 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:51.857934', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #3: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 0.8166093826293945, 'train_time_std': 0.06089251187775398}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:52,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:52,050 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:52,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:52,056 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 174290 effective words/s\n",
      "2024-05-07 14:35:52,174 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:52,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:52,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:52,205 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 222348 effective words/s\n",
      "2024-05-07 14:35:52,318 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:52,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:52,336 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:52,338 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 251269 effective words/s\n",
      "2024-05-07 14:35:52,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:52,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:52,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:52,487 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 222715 effective words/s\n",
      "2024-05-07 14:35:52,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:52,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:52,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:52,633 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 234377 effective words/s\n",
      "2024-05-07 14:35:52,634 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.8s, 210011 effective words/s', 'datetime': '2024-05-07T14:35:52.634688', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:52,637 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:52.636991', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:52,641 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:52,643 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:52,678 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:52,681 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:52,698 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:52.698733', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:52,701 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:52.701314', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:52,718 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:52,719 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:52,720 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:52.720932', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:52,742 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:52,742 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:52,747 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:52.747117', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:52,748 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:52.748871', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:52,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:52,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:52,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:52,887 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 241616 effective words/s\n",
      "2024-05-07 14:35:53,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:53,020 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:53,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:53,025 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 240922 effective words/s\n",
      "2024-05-07 14:35:53,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:53,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:53,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:53,173 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 224076 effective words/s\n",
      "2024-05-07 14:35:53,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:53,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:53,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:53,312 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 238916 effective words/s\n",
      "2024-05-07 14:35:53,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:53,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:53,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:53,475 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.2s, 205232 effective words/s\n",
      "2024-05-07 14:35:53,476 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.7s, 223932 effective words/s', 'datetime': '2024-05-07T14:35:53.476659', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:53,476 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:53.476659', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:53,477 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:53,479 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:53,517 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:53,517 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:53,535 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:53.535547', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:53,537 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:53.537543', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:53,555 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:53,557 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:53,558 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:53.558745', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:53,587 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:53,588 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:53,593 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:53.593487', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:53,595 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:53.595480', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:53,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:53,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:53,750 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:53,752 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 219956 effective words/s\n",
      "2024-05-07 14:35:53,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:53,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:53,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:53,903 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 226156 effective words/s\n",
      "2024-05-07 14:35:54,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:54,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:54,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:54,051 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 224243 effective words/s\n",
      "2024-05-07 14:35:54,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:54,202 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:54,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:54,209 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.2s, 209142 effective words/s\n",
      "2024-05-07 14:35:54,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:54,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:54,359 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:54,361 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 225649 effective words/s\n",
      "2024-05-07 14:35:54,363 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.8s, 213114 effective words/s', 'datetime': '2024-05-07T14:35:54.363907', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:54,365 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:54.365661', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:54,370 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:54,372 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:54,436 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:54,437 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:54,457 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:54.457631', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:54,458 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:54.457631', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:54,474 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:54,477 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:54,481 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:54.481888', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:54,518 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:54,519 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:54,522 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:54.521628', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:54,524 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:54.524618', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #4: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 0.8745242754618326, 'train_time_std': 0.026599108925272903}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:54,659 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:54,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:54,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:54,677 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 215466 effective words/s\n",
      "2024-05-07 14:35:54,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:54,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:54,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:54,825 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 229447 effective words/s\n",
      "2024-05-07 14:35:54,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:54,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:54,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:54,985 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.2s, 207243 effective words/s\n",
      "2024-05-07 14:35:55,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:55,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:55,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:55,125 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 240714 effective words/s\n",
      "2024-05-07 14:35:55,253 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:55,255 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:55,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:55,271 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 227390 effective words/s\n",
      "2024-05-07 14:35:55,275 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.8s, 217063 effective words/s', 'datetime': '2024-05-07T14:35:55.275820', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:55,277 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:55.277797', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:55,279 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:55,285 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:55,318 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:55,318 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:55,333 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:55.333166', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:55,334 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:55.334172', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:55,353 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:55,355 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:55,356 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:55.356104', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:55,384 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:55,385 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:55,387 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:55.387354', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:55,388 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:55.388345', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:55,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:55,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:55,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:55,522 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 246993 effective words/s\n",
      "2024-05-07 14:35:55,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:55,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:55,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:55,664 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 234112 effective words/s\n",
      "2024-05-07 14:35:55,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:55,784 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:55,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:55,790 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 274698 effective words/s\n",
      "2024-05-07 14:35:55,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:55,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:55,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:55,935 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 228299 effective words/s\n",
      "2024-05-07 14:35:56,055 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:56,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:56,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:56,073 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 242875 effective words/s\n",
      "2024-05-07 14:35:56,074 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.7s, 237542 effective words/s', 'datetime': '2024-05-07T14:35:56.074197', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:56,074 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:56.074197', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:56,075 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:56,076 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:56,106 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:56,106 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:56,123 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:56.123294', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:56,125 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:56.125292', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:56,144 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:56,148 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:56,149 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:56.149224', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:56,173 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2024-05-07 14:35:56,174 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:56,175 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:56.175154', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:56,176 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:56.176151', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:56,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:56,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:56,305 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:56,306 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 254562 effective words/s\n",
      "2024-05-07 14:35:56,433 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:56,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:56,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:56,452 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 227518 effective words/s\n",
      "2024-05-07 14:35:56,579 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:56,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:56,596 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:56,598 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 226078 effective words/s\n",
      "2024-05-07 14:35:56,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:56,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:56,728 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:56,732 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 249799 effective words/s\n",
      "2024-05-07 14:35:56,857 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:56,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:56,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:56,877 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 234044 effective words/s\n",
      "2024-05-07 14:35:56,877 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.7s, 232298 effective words/s', 'datetime': '2024-05-07T14:35:56.877493', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:56,879 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:56.879503', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:56,883 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:56,884 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:56,919 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:56,922 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:56,940 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:56.940317', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:56,940 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:56.940317', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:56,957 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:56,958 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:56,959 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:56.959266', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:56,961 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:35:57,035 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:57,061 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #5: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 0.8376061916351318, 'train_time_std': 0.05152817399655957}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:35:57,066 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:57,070 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:57.070967', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:57,071 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:57.071988', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:57,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:57,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:57,348 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:57,350 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.3s, 117654 effective words/s\n",
      "2024-05-07 14:35:57,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:57,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:57,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:57,611 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.3s, 126472 effective words/s\n",
      "2024-05-07 14:35:57,878 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:57,882 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:57,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:57,907 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.3s, 112881 effective words/s\n",
      "2024-05-07 14:35:58,170 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:58,191 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:58,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:58,210 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.3s, 108225 effective words/s\n",
      "2024-05-07 14:35:58,467 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:58,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:58,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:58,484 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.3s, 122253 effective words/s\n",
      "2024-05-07 14:35:58,485 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 1.4s, 115209 effective words/s', 'datetime': '2024-05-07T14:35:58.485540', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:58,486 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:35:58.486548', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:35:58,487 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:35:58,489 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:35:58,539 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:35:58,539 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:35:58,553 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:35:58.553830', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:58,554 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:35:58.554430', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:58,573 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:35:58,575 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:35:58,575 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:35:58.575366', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:35:58,577 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:35:58,652 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:35:58,684 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:35:58,686 : INFO : resetting layer weights\n",
      "2024-05-07 14:35:58,688 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:35:58.688037', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:35:58,689 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:35:58.689065', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:35:58,944 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:58,950 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:58,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:58,961 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.3s, 121274 effective words/s\n",
      "2024-05-07 14:35:59,251 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:59,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:59,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:59,268 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.3s, 108443 effective words/s\n",
      "2024-05-07 14:35:59,562 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:59,570 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:59,580 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:59,583 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.3s, 104563 effective words/s\n",
      "2024-05-07 14:35:59,843 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:35:59,852 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:35:59,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:35:59,860 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.3s, 119160 effective words/s\n",
      "2024-05-07 14:36:00,125 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:00,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:00,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:00,152 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.3s, 115218 effective words/s\n",
      "2024-05-07 14:36:00,153 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 1.5s, 111255 effective words/s', 'datetime': '2024-05-07T14:36:00.153633', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:00,154 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:00.154632', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:00,157 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:00,163 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:00,207 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:36:00,207 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:00,225 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:36:00.225830', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:00,228 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:36:00.228890', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:00,252 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:36:00,254 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:36:00,255 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:36:00.255650', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:00,256 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:36:00,326 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:36:00,365 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:36:00,365 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:00,368 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:00.368071', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:00,369 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:00.369078', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:00,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:00,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:00,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:00,720 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.3s, 93412 effective words/s\n",
      "2024-05-07 14:36:00,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:00,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:01,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:01,006 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.3s, 114685 effective words/s\n",
      "2024-05-07 14:36:01,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:01,273 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:01,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:01,293 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.3s, 114583 effective words/s\n",
      "2024-05-07 14:36:01,542 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:01,554 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:01,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:01,568 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.3s, 121012 effective words/s\n",
      "2024-05-07 14:36:01,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:01,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:01,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:01,910 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.3s, 96116 effective words/s\n",
      "2024-05-07 14:36:01,911 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 1.5s, 105612 effective words/s', 'datetime': '2024-05-07T14:36:01.911492', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:01,915 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:01.915493', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:01,918 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:01,920 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:01,956 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:36:01,958 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:01,975 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:36:01.975578', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:01,976 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:36:01.976575', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:01,992 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:36:01,993 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:36:01,996 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:36:01.996450', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:01,999 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:36:02,075 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:36:02,102 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #6: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 1.6783344745635986, 'train_time_std': 0.06393772863909893}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:02,106 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:02,111 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:02.111113', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:02,112 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:02.112625', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:02,422 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:02,436 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:02,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:02,459 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.3s, 95335 effective words/s\n",
      "2024-05-07 14:36:02,743 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:02,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:02,766 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:02,767 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.3s, 110268 effective words/s\n",
      "2024-05-07 14:36:03,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:03,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:03,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:03,051 : INFO : EPOCH - 3 : training on 59890 raw words (32685 effective words) took 0.3s, 116014 effective words/s\n",
      "2024-05-07 14:36:03,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:03,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:03,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:03,392 : INFO : EPOCH - 4 : training on 59890 raw words (32526 effective words) took 0.3s, 96216 effective words/s\n",
      "2024-05-07 14:36:03,640 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:03,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:03,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:03,651 : INFO : EPOCH - 5 : training on 59890 raw words (32549 effective words) took 0.3s, 127605 effective words/s\n",
      "2024-05-07 14:36:03,654 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162855 effective words) took 1.5s, 105871 effective words/s', 'datetime': '2024-05-07T14:36:03.654765', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:03,655 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:03.655301', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:03,659 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:03,665 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:03,697 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:36:03,697 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:03,710 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:36:03.710208', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:03,713 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:36:03.713921', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:03,733 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:36:03,737 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:36:03,740 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:36:03.740545', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:03,746 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:36:03,820 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:36:03,843 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:36:03,844 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:03,849 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:03.848496', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:03,850 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:03.850490', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:04,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:04,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:04,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:04,102 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 130768 effective words/s\n",
      "2024-05-07 14:36:04,336 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:04,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:04,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:04,360 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.3s, 127536 effective words/s\n",
      "2024-05-07 14:36:04,647 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:04,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:04,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:04,669 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.3s, 108565 effective words/s\n",
      "2024-05-07 14:36:04,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:04,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:04,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:04,951 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.3s, 117194 effective words/s\n",
      "2024-05-07 14:36:05,223 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:05,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:05,254 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:05,256 : INFO : EPOCH - 5 : training on 59890 raw words (32556 effective words) took 0.3s, 109261 effective words/s\n",
      "2024-05-07 14:36:05,258 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162841 effective words) took 1.4s, 115729 effective words/s', 'datetime': '2024-05-07T14:36:05.258494', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:05,259 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:05.259020', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:05,270 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:05,274 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:05,316 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2024-05-07 14:36:05,317 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:05,339 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2024-05-07T14:36:05.339259', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:05,340 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2024-05-07T14:36:05.340692', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:05,377 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2024-05-07 14:36:05,382 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2024-05-07 14:36:05,384 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2024-05-07T14:36:05.384782', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:05,386 : INFO : constructing a huffman tree from 1762 words\n",
      "2024-05-07 14:36:05,470 : INFO : built huffman tree with maximum node depth 13\n",
      "2024-05-07 14:36:05,496 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2024-05-07 14:36:05,501 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:05,503 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:05.503638', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:05,504 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:05.504995', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:05,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:05,772 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:05,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:05,782 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.3s, 118119 effective words/s\n",
      "2024-05-07 14:36:06,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:06,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:06,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:06,055 : INFO : EPOCH - 2 : training on 59890 raw words (32616 effective words) took 0.3s, 121658 effective words/s\n",
      "2024-05-07 14:36:06,337 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:06,338 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:06,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:06,347 : INFO : EPOCH - 3 : training on 59890 raw words (32670 effective words) took 0.3s, 113275 effective words/s\n",
      "2024-05-07 14:36:06,619 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:06,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:06,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:06,654 : INFO : EPOCH - 4 : training on 59890 raw words (32605 effective words) took 0.3s, 107384 effective words/s\n",
      "2024-05-07 14:36:06,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:06,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:06,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:06,925 : INFO : EPOCH - 5 : training on 59890 raw words (32405 effective words) took 0.3s, 120579 effective words/s\n",
      "2024-05-07 14:36:06,927 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162839 effective words) took 1.4s, 114527 effective words/s', 'datetime': '2024-05-07T14:36:06.927615', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:06,930 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:06.929785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:06,934 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:06,967 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:07,034 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:07,037 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:07,066 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:07.064974', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:07,066 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:07.066967', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #7: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 1.6713317235310872, 'train_time_std': 0.05449187211022092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:07,117 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:07,120 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:07,120 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:07.120462', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:07,186 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:07,187 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:07,191 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:07.191182', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:07,192 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:07.192180', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:07,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:07,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:07,372 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:07,373 : INFO : EPOCH - 1 : training on 175599 raw words (110235 effective words) took 0.2s, 734068 effective words/s\n",
      "2024-05-07 14:36:07,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:07,533 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:07,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:07,539 : INFO : EPOCH - 2 : training on 175599 raw words (110247 effective words) took 0.1s, 795840 effective words/s\n",
      "2024-05-07 14:36:07,702 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:07,706 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:07,716 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:07,718 : INFO : EPOCH - 3 : training on 175599 raw words (110187 effective words) took 0.1s, 737829 effective words/s\n",
      "2024-05-07 14:36:07,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:07,878 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:07,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:07,882 : INFO : EPOCH - 4 : training on 175599 raw words (110295 effective words) took 0.1s, 823858 effective words/s\n",
      "2024-05-07 14:36:08,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:08,037 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:08,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:08,041 : INFO : EPOCH - 5 : training on 175599 raw words (110328 effective words) took 0.1s, 825022 effective words/s\n",
      "2024-05-07 14:36:08,041 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551292 effective words) took 0.8s, 650883 effective words/s', 'datetime': '2024-05-07T14:36:08.041539', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:08,041 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:08.041539', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:08,048 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:08,073 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:08,145 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:08,147 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:08,179 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:08.179809', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:08,180 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:08.180809', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:08,222 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:08,223 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:08,224 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:08.224937', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:08,289 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:08,289 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:08,292 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:08.292662', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:08,295 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:08.294667', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:08,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:08,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:08,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:08,489 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.2s, 643417 effective words/s\n",
      "2024-05-07 14:36:08,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:08,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:08,704 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:08,705 : INFO : EPOCH - 2 : training on 175599 raw words (110213 effective words) took 0.2s, 609995 effective words/s\n",
      "2024-05-07 14:36:08,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:08,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:08,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:08,870 : INFO : EPOCH - 3 : training on 175599 raw words (110355 effective words) took 0.2s, 712127 effective words/s\n",
      "2024-05-07 14:36:09,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:09,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:09,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:09,035 : INFO : EPOCH - 4 : training on 175599 raw words (110246 effective words) took 0.1s, 798513 effective words/s\n",
      "2024-05-07 14:36:09,195 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:09,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:09,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:09,207 : INFO : EPOCH - 5 : training on 175599 raw words (110449 effective words) took 0.1s, 771096 effective words/s\n",
      "2024-05-07 14:36:09,207 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551607 effective words) took 0.9s, 605646 effective words/s', 'datetime': '2024-05-07T14:36:09.207573', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:09,208 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:09.208542', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:09,211 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:09,238 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:09,307 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:09,308 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:09,340 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:09.340034', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:09,342 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:09.342599', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:09,378 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:09,382 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:09,383 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:09.383462', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:09,446 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:09,448 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:09,451 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:09.451878', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:09,452 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:09.452915', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:09,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:09,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:09,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:09,653 : INFO : EPOCH - 1 : training on 175599 raw words (110228 effective words) took 0.2s, 614322 effective words/s\n",
      "2024-05-07 14:36:09,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:09,817 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:09,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:09,821 : INFO : EPOCH - 2 : training on 175599 raw words (110126 effective words) took 0.2s, 707000 effective words/s\n",
      "2024-05-07 14:36:09,980 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:09,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:09,983 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:09,984 : INFO : EPOCH - 3 : training on 175599 raw words (110064 effective words) took 0.1s, 800609 effective words/s\n",
      "2024-05-07 14:36:10,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:10,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:10,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:10,146 : INFO : EPOCH - 4 : training on 175599 raw words (110135 effective words) took 0.1s, 786620 effective words/s\n",
      "2024-05-07 14:36:10,308 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:10,317 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:10,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:10,321 : INFO : EPOCH - 5 : training on 175599 raw words (110278 effective words) took 0.2s, 734184 effective words/s\n",
      "2024-05-07 14:36:10,322 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550831 effective words) took 0.9s, 633703 effective words/s', 'datetime': '2024-05-07T14:36:10.322809', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:10,323 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:10.323487', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:10,325 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:10,357 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:10,424 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:10,425 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:10,457 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:10.457985', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:10,457 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:10.457985', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:10,495 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:10,501 : INFO : sample=0.001 downsamples 40 most-common words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #8: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 1.130063533782959, 'train_time_std': 0.02519748554166105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:10,501 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:10.501479', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:10,572 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:10,579 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:10,585 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:10.585074', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:10,586 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:10.586095', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:10,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:10,808 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:10,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:10,818 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.2s, 547717 effective words/s\n",
      "2024-05-07 14:36:10,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:10,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:10,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:10,995 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 753360 effective words/s\n",
      "2024-05-07 14:36:11,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:11,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:11,158 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:11,159 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.1s, 846345 effective words/s\n",
      "2024-05-07 14:36:11,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:11,310 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:11,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:11,312 : INFO : EPOCH - 4 : training on 175599 raw words (110233 effective words) took 0.1s, 888268 effective words/s\n",
      "2024-05-07 14:36:11,454 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:11,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:11,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:11,465 : INFO : EPOCH - 5 : training on 175599 raw words (110149 effective words) took 0.1s, 887122 effective words/s\n",
      "2024-05-07 14:36:11,465 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551145 effective words) took 0.9s, 627705 effective words/s', 'datetime': '2024-05-07T14:36:11.465581', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:11,465 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:11.465999', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:11,467 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:11,497 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:11,568 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:11,569 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:11,596 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:11.596935', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:11,597 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:11.597983', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:11,657 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:11,666 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:11,670 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:11.670711', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:11,780 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:11,781 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:11,786 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:11.786859', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:11,790 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:11.790890', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:11,998 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:12,007 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:12,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:12,015 : INFO : EPOCH - 1 : training on 175599 raw words (110226 effective words) took 0.2s, 557905 effective words/s\n",
      "2024-05-07 14:36:12,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:12,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:12,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:12,205 : INFO : EPOCH - 2 : training on 175599 raw words (110160 effective words) took 0.2s, 732335 effective words/s\n",
      "2024-05-07 14:36:12,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:12,398 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:12,402 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:12,403 : INFO : EPOCH - 3 : training on 175599 raw words (110191 effective words) took 0.2s, 641529 effective words/s\n",
      "2024-05-07 14:36:12,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:12,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:12,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:12,593 : INFO : EPOCH - 4 : training on 175599 raw words (110321 effective words) took 0.2s, 646144 effective words/s\n",
      "2024-05-07 14:36:12,770 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:12,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:12,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:12,784 : INFO : EPOCH - 5 : training on 175599 raw words (110163 effective words) took 0.2s, 698568 effective words/s\n",
      "2024-05-07 14:36:12,785 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551061 effective words) took 1.0s, 555177 effective words/s', 'datetime': '2024-05-07T14:36:12.785403', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:12,786 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:12.786000', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:12,787 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:12,824 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:12,925 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:12,929 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:12,959 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:12.959831', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:12,963 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:12.963886', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:13,005 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:13,007 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:13,007 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:13.007696', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:13,081 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:13,082 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:13,085 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:13.085452', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:13,086 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:13.086449', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:13,258 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:13,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:13,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:13,270 : INFO : EPOCH - 1 : training on 175599 raw words (110225 effective words) took 0.2s, 702462 effective words/s\n",
      "2024-05-07 14:36:13,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:13,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:13,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:13,441 : INFO : EPOCH - 2 : training on 175599 raw words (110192 effective words) took 0.1s, 767056 effective words/s\n",
      "2024-05-07 14:36:13,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:13,602 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:13,603 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:13,604 : INFO : EPOCH - 3 : training on 175599 raw words (110127 effective words) took 0.1s, 801997 effective words/s\n",
      "2024-05-07 14:36:13,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:13,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:13,754 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:13,754 : INFO : EPOCH - 4 : training on 175599 raw words (110254 effective words) took 0.1s, 846008 effective words/s\n",
      "2024-05-07 14:36:13,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:13,919 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:13,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:13,921 : INFO : EPOCH - 5 : training on 175599 raw words (110318 effective words) took 0.1s, 790824 effective words/s\n",
      "2024-05-07 14:36:13,922 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551116 effective words) took 0.8s, 659492 effective words/s', 'datetime': '2024-05-07T14:36:13.922461', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:13,923 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:13.923459', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:13,925 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:13,947 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:14,020 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:14,022 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:14,056 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:14.056943', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:14,058 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:14.058464', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:14,097 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:14,098 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:14,099 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:14.099458', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:14,104 : INFO : constructing a huffman tree from 4125 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #9: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 1.199663559595744, 'train_time_std': 0.08430354818821928}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:14,279 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:14,336 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:14,336 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:14,339 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:14.339860', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:14,340 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:14.340859', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:14,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:14,681 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:14,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:14,685 : INFO : EPOCH - 1 : training on 175599 raw words (110158 effective words) took 0.3s, 343850 effective words/s\n",
      "2024-05-07 14:36:14,978 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:15,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:15,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:15,010 : INFO : EPOCH - 2 : training on 175599 raw words (110360 effective words) took 0.3s, 372558 effective words/s\n",
      "2024-05-07 14:36:15,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:15,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:15,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:15,312 : INFO : EPOCH - 3 : training on 175599 raw words (109939 effective words) took 0.3s, 415395 effective words/s\n",
      "2024-05-07 14:36:15,587 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:15,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:15,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:15,608 : INFO : EPOCH - 4 : training on 175599 raw words (110250 effective words) took 0.3s, 410382 effective words/s\n",
      "2024-05-07 14:36:15,878 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:15,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:15,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:15,905 : INFO : EPOCH - 5 : training on 175599 raw words (110247 effective words) took 0.3s, 407523 effective words/s\n",
      "2024-05-07 14:36:15,905 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550954 effective words) took 1.6s, 352151 effective words/s', 'datetime': '2024-05-07T14:36:15.905848', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:15,906 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:15.906789', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:15,908 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:15,933 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:16,000 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:16,001 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:16,023 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:16.023645', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:16,024 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:16.024641', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:16,070 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:16,072 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:16,073 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:16.073658', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:16,078 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:16,237 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:16,282 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:16,283 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:16,285 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:16.285540', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:16,286 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:16.286572', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:16,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:16,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:16,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:16,565 : INFO : EPOCH - 1 : training on 175599 raw words (110346 effective words) took 0.3s, 427676 effective words/s\n",
      "2024-05-07 14:36:16,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:16,854 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:16,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:16,863 : INFO : EPOCH - 2 : training on 175599 raw words (110115 effective words) took 0.3s, 417395 effective words/s\n",
      "2024-05-07 14:36:17,139 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:17,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:17,152 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:17,153 : INFO : EPOCH - 3 : training on 175599 raw words (110249 effective words) took 0.3s, 410699 effective words/s\n",
      "2024-05-07 14:36:17,414 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:17,418 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:17,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:17,430 : INFO : EPOCH - 4 : training on 175599 raw words (110428 effective words) took 0.3s, 435946 effective words/s\n",
      "2024-05-07 14:36:17,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:17,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:17,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:17,721 : INFO : EPOCH - 5 : training on 175599 raw words (110229 effective words) took 0.3s, 418873 effective words/s\n",
      "2024-05-07 14:36:17,721 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551367 effective words) took 1.4s, 384207 effective words/s', 'datetime': '2024-05-07T14:36:17.721781', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:17,722 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:17.722478', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:17,724 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:17,752 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:17,820 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:17,821 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:17,849 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:17.849795', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:17,851 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:17.851026', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:17,886 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:17,890 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:17,892 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:17.892560', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:17,899 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:18,048 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:18,099 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:18,100 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:18,102 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:18.102114', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:18,103 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:18.103112', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:18,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:18,396 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:18,415 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:18,417 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.3s, 383537 effective words/s\n",
      "2024-05-07 14:36:18,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:18,705 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:18,716 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:18,717 : INFO : EPOCH - 2 : training on 175599 raw words (110172 effective words) took 0.3s, 401045 effective words/s\n",
      "2024-05-07 14:36:18,970 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:18,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:18,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:18,996 : INFO : EPOCH - 3 : training on 175599 raw words (110187 effective words) took 0.3s, 429201 effective words/s\n",
      "2024-05-07 14:36:19,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:19,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:19,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:19,302 : INFO : EPOCH - 4 : training on 175599 raw words (110428 effective words) took 0.3s, 408406 effective words/s\n",
      "2024-05-07 14:36:19,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:19,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:19,619 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:19,620 : INFO : EPOCH - 5 : training on 175599 raw words (110400 effective words) took 0.3s, 378657 effective words/s\n",
      "2024-05-07 14:36:19,622 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551531 effective words) took 1.5s, 363240 effective words/s', 'datetime': '2024-05-07T14:36:19.622813', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:19,623 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:19.623807', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:19,633 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:19,661 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:19,749 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:19,750 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:19,779 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:19.779691', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:19,780 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:19.780720', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:19,818 : INFO : deleting the raw counts dictionary of 17251 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #10: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 1.9027797381083171, 'train_time_std': 0.06800264017794423}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:19,821 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:19,822 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:19.822566', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:19,825 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:20,191 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:20,250 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:20,251 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:20,254 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:20.254277', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:20,255 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:20.255274', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:20,535 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:20,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:20,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:20,551 : INFO : EPOCH - 1 : training on 175599 raw words (110366 effective words) took 0.3s, 409050 effective words/s\n",
      "2024-05-07 14:36:20,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:20,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:20,828 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:20,829 : INFO : EPOCH - 2 : training on 175599 raw words (110114 effective words) took 0.3s, 432599 effective words/s\n",
      "2024-05-07 14:36:21,101 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:21,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:21,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:21,107 : INFO : EPOCH - 3 : training on 175599 raw words (110384 effective words) took 0.3s, 437401 effective words/s\n",
      "2024-05-07 14:36:21,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:21,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:21,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:21,412 : INFO : EPOCH - 4 : training on 175599 raw words (110190 effective words) took 0.3s, 396284 effective words/s\n",
      "2024-05-07 14:36:21,666 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:21,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:21,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:21,681 : INFO : EPOCH - 5 : training on 175599 raw words (110103 effective words) took 0.2s, 449377 effective words/s\n",
      "2024-05-07 14:36:21,682 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551157 effective words) took 1.4s, 386204 effective words/s', 'datetime': '2024-05-07T14:36:21.682887', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:21,685 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:21.685962', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:21,689 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:21,714 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:21,779 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:21,780 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:21,806 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:21.806707', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:21,807 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:21.807675', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:21,841 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:21,847 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:21,848 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:21.848567', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:21,850 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:22,004 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:22,049 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:22,050 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:22,053 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:22.053535', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:22,054 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:22.054533', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:22,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:22,332 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:22,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:22,346 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.3s, 405231 effective words/s\n",
      "2024-05-07 14:36:22,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:22,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:22,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:22,630 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.3s, 419282 effective words/s\n",
      "2024-05-07 14:36:22,894 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:22,902 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:22,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:22,910 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.3s, 430292 effective words/s\n",
      "2024-05-07 14:36:23,168 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:23,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:23,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:23,187 : INFO : EPOCH - 4 : training on 175599 raw words (110337 effective words) took 0.2s, 452226 effective words/s\n",
      "2024-05-07 14:36:23,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:23,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:23,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:23,467 : INFO : EPOCH - 5 : training on 175599 raw words (110462 effective words) took 0.3s, 433992 effective words/s\n",
      "2024-05-07 14:36:23,468 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551562 effective words) took 1.4s, 390219 effective words/s', 'datetime': '2024-05-07T14:36:23.468404', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:23,469 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:23.469660', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:23,477 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:23,502 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:23,561 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:23,562 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:23,590 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:23.590154', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:23,591 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:23.591153', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:23,621 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:23,623 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:23,624 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:23.624376', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:23,632 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:23,780 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:23,836 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:23,836 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:23,839 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:23.839032', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:23,840 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:23.840043', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:24,103 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:24,116 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:24,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:24,126 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.3s, 420188 effective words/s\n",
      "2024-05-07 14:36:24,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:24,396 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:24,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:24,404 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.3s, 435771 effective words/s\n",
      "2024-05-07 14:36:24,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:24,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:24,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:24,772 : INFO : EPOCH - 3 : training on 175599 raw words (110253 effective words) took 0.3s, 328943 effective words/s\n",
      "2024-05-07 14:36:25,132 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:25,164 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:25,168 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:25,170 : INFO : EPOCH - 4 : training on 175599 raw words (110474 effective words) took 0.3s, 316163 effective words/s\n",
      "2024-05-07 14:36:25,698 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:25,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:25,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:25,735 : INFO : EPOCH - 5 : training on 175599 raw words (110470 effective words) took 0.5s, 208692 effective words/s\n",
      "2024-05-07 14:36:25,736 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551608 effective words) took 1.9s, 291025 effective words/s', 'datetime': '2024-05-07T14:36:25.736296', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:25,737 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:25.737293', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:25,741 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:25,766 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:25,846 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:25,847 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:25,884 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:25.884561', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:25,885 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:25.885558', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:25,931 : INFO : deleting the raw counts dictionary of 17251 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #11: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 2.0358245372772217, 'train_time_std': 0.19500670210826954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:25,934 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:25,935 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:25.935568', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:26,012 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:26,012 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:26,023 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:26.023597', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:26,028 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:26.027580', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:26,544 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:26,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:26,587 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:26,587 : INFO : EPOCH - 1 : training on 175599 raw words (110366 effective words) took 0.5s, 207642 effective words/s\n",
      "2024-05-07 14:36:27,103 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:27,130 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:27,132 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:27,132 : INFO : EPOCH - 2 : training on 175599 raw words (110447 effective words) took 0.5s, 214259 effective words/s\n",
      "2024-05-07 14:36:27,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:27,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:27,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:27,714 : INFO : EPOCH - 3 : training on 175599 raw words (110423 effective words) took 0.5s, 202589 effective words/s\n",
      "2024-05-07 14:36:28,169 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:28,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:28,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:28,193 : INFO : EPOCH - 4 : training on 175599 raw words (110085 effective words) took 0.5s, 240793 effective words/s\n",
      "2024-05-07 14:36:28,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:28,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:28,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:28,720 : INFO : EPOCH - 5 : training on 175599 raw words (110133 effective words) took 0.5s, 219514 effective words/s\n",
      "2024-05-07 14:36:28,722 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551454 effective words) took 2.7s, 205162 effective words/s', 'datetime': '2024-05-07T14:36:28.722218', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:28,723 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:28.723216', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:28,731 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:28,755 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:28,830 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:28,832 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:28,866 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:28.866666', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:28,867 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:28.867674', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:28,905 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:28,913 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:28,914 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:28.914626', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:28,992 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:28,993 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:28,996 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:28.996537', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:28,997 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:28.997534', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:29,524 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:29,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:29,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:29,537 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.5s, 217928 effective words/s\n",
      "2024-05-07 14:36:30,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:30,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:30,129 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:30,129 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.6s, 197326 effective words/s\n",
      "2024-05-07 14:36:30,646 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:30,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:30,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:30,688 : INFO : EPOCH - 3 : training on 175599 raw words (110292 effective words) took 0.5s, 209317 effective words/s\n",
      "2024-05-07 14:36:31,216 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:31,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:31,251 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:31,251 : INFO : EPOCH - 4 : training on 175599 raw words (110008 effective words) took 0.5s, 211969 effective words/s\n",
      "2024-05-07 14:36:31,799 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:31,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:31,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:31,807 : INFO : EPOCH - 5 : training on 175599 raw words (110195 effective words) took 0.5s, 210677 effective words/s\n",
      "2024-05-07 14:36:31,808 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550906 effective words) took 2.8s, 196011 effective words/s', 'datetime': '2024-05-07T14:36:31.807891', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:31,809 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:31.809886', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:31,813 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:31,849 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:31,924 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:31,929 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:31,961 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:31.961723', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:31,962 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:31.962856', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:32,001 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:32,003 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:32,004 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:32.003722', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:32,071 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:32,072 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:32,078 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:32.078996', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:32,081 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:32.081057', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:32,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:32,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:32,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:32,635 : INFO : EPOCH - 1 : training on 175599 raw words (110144 effective words) took 0.5s, 207419 effective words/s\n",
      "2024-05-07 14:36:33,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:33,219 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:33,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:33,231 : INFO : EPOCH - 2 : training on 175599 raw words (110273 effective words) took 0.6s, 188383 effective words/s\n",
      "2024-05-07 14:36:33,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:33,818 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:33,822 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:33,823 : INFO : EPOCH - 3 : training on 175599 raw words (110217 effective words) took 0.6s, 196348 effective words/s\n",
      "2024-05-07 14:36:34,357 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:34,374 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:34,389 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:34,392 : INFO : EPOCH - 4 : training on 175599 raw words (110094 effective words) took 0.5s, 205301 effective words/s\n",
      "2024-05-07 14:36:34,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:35,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:35,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:35,030 : INFO : EPOCH - 5 : training on 175599 raw words (110398 effective words) took 0.6s, 185548 effective words/s\n",
      "2024-05-07 14:36:35,031 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551126 effective words) took 2.9s, 186847 effective words/s', 'datetime': '2024-05-07T14:36:35.031654', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:35,031 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:35.031885', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:35,034 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:35,060 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:35,151 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:35,152 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:35,183 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:35.183909', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:35,185 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:35.185131', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #12: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 3.0974958737691245, 'train_time_std': 0.09537362784568652}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:35,233 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:35,236 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:35,236 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:35.236941', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:35,308 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:35,309 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:35,314 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:35.314901', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:35,314 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:35.314901', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:35,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:35,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:35,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:35,937 : INFO : EPOCH - 1 : training on 175599 raw words (110226 effective words) took 0.6s, 187204 effective words/s\n",
      "2024-05-07 14:36:36,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:36,486 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:36,490 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:36,492 : INFO : EPOCH - 2 : training on 175599 raw words (110026 effective words) took 0.5s, 209760 effective words/s\n",
      "2024-05-07 14:36:37,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:37,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:37,053 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:37,054 : INFO : EPOCH - 3 : training on 175599 raw words (110152 effective words) took 0.5s, 208327 effective words/s\n",
      "2024-05-07 14:36:37,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:37,581 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:37,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:37,583 : INFO : EPOCH - 4 : training on 175599 raw words (110227 effective words) took 0.5s, 222525 effective words/s\n",
      "2024-05-07 14:36:38,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:38,116 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:38,118 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:38,118 : INFO : EPOCH - 5 : training on 175599 raw words (110170 effective words) took 0.5s, 218184 effective words/s\n",
      "2024-05-07 14:36:38,119 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550801 effective words) took 2.8s, 196504 effective words/s', 'datetime': '2024-05-07T14:36:38.119085', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:38,119 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:38.119687', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:38,125 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:38,161 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:38,228 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:38,229 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:38,256 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:38.255755', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:38,259 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:38.259715', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:38,298 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:38,300 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:38,301 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:38.301600', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:38,363 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:38,364 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:38,371 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:38.371884', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:38,372 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:38.372845', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:38,900 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:38,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:38,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:38,917 : INFO : EPOCH - 1 : training on 175599 raw words (110226 effective words) took 0.5s, 213295 effective words/s\n",
      "2024-05-07 14:36:39,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:39,410 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:39,435 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:39,436 : INFO : EPOCH - 2 : training on 175599 raw words (110160 effective words) took 0.5s, 221635 effective words/s\n",
      "2024-05-07 14:36:39,979 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:40,028 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:40,042 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:40,047 : INFO : EPOCH - 3 : training on 175599 raw words (110172 effective words) took 0.6s, 190289 effective words/s\n",
      "2024-05-07 14:36:40,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:40,760 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:40,787 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:40,788 : INFO : EPOCH - 4 : training on 175599 raw words (110324 effective words) took 0.7s, 157092 effective words/s\n",
      "2024-05-07 14:36:41,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:41,516 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:41,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:41,520 : INFO : EPOCH - 5 : training on 175599 raw words (110248 effective words) took 0.7s, 158359 effective words/s\n",
      "2024-05-07 14:36:41,521 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551130 effective words) took 3.1s, 175217 effective words/s', 'datetime': '2024-05-07T14:36:41.521046', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:41,521 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:41.521888', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:41,525 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:41,549 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:41,646 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:41,648 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:41,682 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:41.682623', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:41,684 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:41.684616', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:41,732 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:41,733 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:41,734 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:41.734951', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:41,797 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2024-05-07 14:36:41,798 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:41,802 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:41.802860', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:41,802 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:41.802860', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:42,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:42,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:42,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:42,447 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.6s, 179012 effective words/s\n",
      "2024-05-07 14:36:43,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:43,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:43,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:43,045 : INFO : EPOCH - 2 : training on 175599 raw words (110085 effective words) took 0.6s, 191653 effective words/s\n",
      "2024-05-07 14:36:43,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:43,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:43,568 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:43,569 : INFO : EPOCH - 3 : training on 175599 raw words (110170 effective words) took 0.5s, 226607 effective words/s\n",
      "2024-05-07 14:36:44,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:44,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:44,234 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:44,236 : INFO : EPOCH - 4 : training on 175599 raw words (110309 effective words) took 0.6s, 175573 effective words/s\n",
      "2024-05-07 14:36:44,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:44,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:44,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:44,819 : INFO : EPOCH - 5 : training on 175599 raw words (110109 effective words) took 0.6s, 200054 effective words/s\n",
      "2024-05-07 14:36:44,820 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550957 effective words) took 3.0s, 182639 effective words/s', 'datetime': '2024-05-07T14:36:44.820421', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:44,821 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:44.821420', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:44,825 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:44,855 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:44,956 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:44,958 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:45,001 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:45.001071', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:45,002 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:45.002069', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #13: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 3.263568560282389, 'train_time_std': 0.12991905761535893}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:36:45,049 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:45,052 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:45,053 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:45.053631', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:45,059 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:45,265 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:45,348 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:45,349 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:45,353 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:45.353755', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:45,356 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:45.355753', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:46,467 : INFO : EPOCH 1 - PROGRESS: at 72.22% examples, 76056 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:36:46,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:46,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:46,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:46,650 : INFO : EPOCH - 1 : training on 175599 raw words (110415 effective words) took 1.3s, 87518 effective words/s\n",
      "2024-05-07 14:36:47,766 : INFO : EPOCH 2 - PROGRESS: at 72.22% examples, 74811 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:36:47,876 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:47,937 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:47,940 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:47,942 : INFO : EPOCH - 2 : training on 175599 raw words (110063 effective words) took 1.3s, 86826 effective words/s\n",
      "2024-05-07 14:36:49,035 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 76624 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:36:49,184 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:49,236 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:49,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:49,262 : INFO : EPOCH - 3 : training on 175599 raw words (110303 effective words) took 1.3s, 85043 effective words/s\n",
      "2024-05-07 14:36:50,386 : INFO : EPOCH 4 - PROGRESS: at 72.22% examples, 74851 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:36:50,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:50,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:50,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:50,609 : INFO : EPOCH - 4 : training on 175599 raw words (110306 effective words) took 1.3s, 83638 effective words/s\n",
      "2024-05-07 14:36:51,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:51,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:51,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:51,573 : INFO : EPOCH - 5 : training on 175599 raw words (110462 effective words) took 0.9s, 118356 effective words/s\n",
      "2024-05-07 14:36:51,574 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551549 effective words) took 6.2s, 88732 effective words/s', 'datetime': '2024-05-07T14:36:51.574583', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:51,576 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:51.575543', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:51,578 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:51,599 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:51,675 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:51,676 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:51,711 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:51.711576', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:51,712 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:51.712570', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:51,746 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:51,749 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:51,749 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:51.749607', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:51,753 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:51,913 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:51,967 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:51,969 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:51,974 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:51.974565', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:51,976 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:51.975746', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:52,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:52,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:52,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:52,940 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.9s, 116817 effective words/s\n",
      "2024-05-07 14:36:53,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:53,985 : INFO : EPOCH 2 - PROGRESS: at 94.44% examples, 101681 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:36:53,986 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:53,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:53,994 : INFO : EPOCH - 2 : training on 175599 raw words (110177 effective words) took 1.0s, 106778 effective words/s\n",
      "2024-05-07 14:36:54,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:54,932 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:54,976 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:54,977 : INFO : EPOCH - 3 : training on 175599 raw words (110291 effective words) took 1.0s, 114221 effective words/s\n",
      "2024-05-07 14:36:56,008 : INFO : EPOCH 4 - PROGRESS: at 77.78% examples, 86674 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:36:56,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:56,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:56,184 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:56,185 : INFO : EPOCH - 4 : training on 175599 raw words (110180 effective words) took 1.2s, 92446 effective words/s\n",
      "2024-05-07 14:36:57,136 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:57,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:57,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:57,183 : INFO : EPOCH - 5 : training on 175599 raw words (110156 effective words) took 1.0s, 115250 effective words/s\n",
      "2024-05-07 14:36:57,184 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550798 effective words) took 5.2s, 105789 effective words/s', 'datetime': '2024-05-07T14:36:57.184503', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:57,184 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:36:57.184503', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:36:57,187 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:36:57,211 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:36:57,278 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:36:57,279 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:36:57,314 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:36:57.314621', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:57,316 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:36:57.316585', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:57,349 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:36:57,351 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:36:57,351 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:36:57.351612', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:36:57,359 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:36:57,523 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:36:57,581 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:36:57,582 : INFO : resetting layer weights\n",
      "2024-05-07 14:36:57,585 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:36:57.585485', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:36:57,586 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:36:57.586585', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:36:58,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:58,540 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:58,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:58,552 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.9s, 119298 effective words/s\n",
      "2024-05-07 14:36:59,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:36:59,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:36:59,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:36:59,556 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 1.0s, 112991 effective words/s\n",
      "2024-05-07 14:37:00,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:00,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:00,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:00,574 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 1.0s, 112545 effective words/s\n",
      "2024-05-07 14:37:01,565 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:01,606 : INFO : EPOCH 4 - PROGRESS: at 94.44% examples, 103944 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:37:01,607 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:01,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:01,610 : INFO : EPOCH - 4 : training on 175599 raw words (110298 effective words) took 1.0s, 109526 effective words/s\n",
      "2024-05-07 14:37:02,542 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:02,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:02,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:02,582 : INFO : EPOCH - 5 : training on 175599 raw words (110225 effective words) took 0.9s, 117348 effective words/s\n",
      "2024-05-07 14:37:02,583 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551286 effective words) took 5.0s, 110401 effective words/s', 'datetime': '2024-05-07T14:37:02.583499', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:02,584 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:02.584508', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:02,591 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:02,627 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:37:02,716 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:37:02,716 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:02,755 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:37:02.755138', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:02,759 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:37:02.759712', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #14: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 5.921028772989909, 'train_time_std': 0.5937261185365141}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:37:02,813 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:37:02,815 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:37:02,816 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:37:02.816195', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:02,825 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:37:03,077 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:37:03,145 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:37:03,146 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:03,150 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:03.150909', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:03,151 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:03.151890', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:04,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:04,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:04,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:04,114 : INFO : EPOCH - 1 : training on 175599 raw words (110226 effective words) took 0.9s, 118087 effective words/s\n",
      "2024-05-07 14:37:05,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:05,085 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:05,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:05,144 : INFO : EPOCH - 2 : training on 175599 raw words (110160 effective words) took 1.0s, 110163 effective words/s\n",
      "2024-05-07 14:37:06,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:06,158 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:06,177 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:06,178 : INFO : EPOCH - 3 : training on 175599 raw words (110165 effective words) took 1.0s, 110758 effective words/s\n",
      "2024-05-07 14:37:07,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:07,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:07,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:07,129 : INFO : EPOCH - 4 : training on 175599 raw words (110103 effective words) took 0.9s, 119943 effective words/s\n",
      "2024-05-07 14:37:08,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:08,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:08,063 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:08,063 : INFO : EPOCH - 5 : training on 175599 raw words (110288 effective words) took 0.9s, 122302 effective words/s\n",
      "2024-05-07 14:37:08,064 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550942 effective words) took 4.9s, 112159 effective words/s', 'datetime': '2024-05-07T14:37:08.064251', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:08,064 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:08.064909', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:08,067 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:08,093 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:37:08,155 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:37:08,156 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:08,193 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:37:08.193606', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:08,194 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:37:08.194675', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:08,230 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:37:08,234 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:37:08,238 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:37:08.238092', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:08,241 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:37:08,453 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:37:08,507 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:37:08,508 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:08,515 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:08.515539', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:08,517 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:08.517533', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:09,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:09,543 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:09,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:09,544 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 1.0s, 111877 effective words/s\n",
      "2024-05-07 14:37:10,553 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:10,605 : INFO : EPOCH 2 - PROGRESS: at 94.44% examples, 102119 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:37:10,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:10,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:10,615 : INFO : EPOCH - 2 : training on 175599 raw words (110246 effective words) took 1.0s, 107226 effective words/s\n",
      "2024-05-07 14:37:11,548 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:11,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:11,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:11,597 : INFO : EPOCH - 3 : training on 175599 raw words (110205 effective words) took 0.9s, 116373 effective words/s\n",
      "2024-05-07 14:37:12,449 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:12,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:12,499 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:12,500 : INFO : EPOCH - 4 : training on 175599 raw words (110278 effective words) took 0.9s, 125829 effective words/s\n",
      "2024-05-07 14:37:13,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:13,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:13,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:13,422 : INFO : EPOCH - 5 : training on 175599 raw words (110217 effective words) took 0.9s, 124001 effective words/s\n",
      "2024-05-07 14:37:13,423 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551230 effective words) took 4.9s, 112386 effective words/s', 'datetime': '2024-05-07T14:37:13.423192', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:13,423 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:13.423789', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:13,425 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:13,450 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:37:13,511 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2024-05-07 14:37:13,512 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:13,543 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2024-05-07T14:37:13.543523', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:13,544 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2024-05-07T14:37:13.544520', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:13,579 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2024-05-07 14:37:13,581 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-05-07 14:37:13,582 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2024-05-07T14:37:13.582525', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:13,584 : INFO : constructing a huffman tree from 4125 words\n",
      "2024-05-07 14:37:13,751 : INFO : built huffman tree with maximum node depth 15\n",
      "2024-05-07 14:37:13,807 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2024-05-07 14:37:13,808 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:13,812 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:13.812905', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:13,815 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:13.814936', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:14,663 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:14,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:14,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:14,710 : INFO : EPOCH - 1 : training on 175599 raw words (110382 effective words) took 0.9s, 128327 effective words/s\n",
      "2024-05-07 14:37:15,749 : INFO : EPOCH 2 - PROGRESS: at 72.22% examples, 80583 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:15,985 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:16,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:16,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:16,057 : INFO : EPOCH - 2 : training on 175599 raw words (110231 effective words) took 1.3s, 83240 effective words/s\n",
      "2024-05-07 14:37:17,131 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 80352 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:17,296 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:17,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:17,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:17,339 : INFO : EPOCH - 3 : training on 175599 raw words (110167 effective words) took 1.2s, 89884 effective words/s\n",
      "2024-05-07 14:37:18,264 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:18,331 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:18,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:18,344 : INFO : EPOCH - 4 : training on 175599 raw words (110375 effective words) took 1.0s, 112650 effective words/s\n",
      "2024-05-07 14:37:19,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:19,351 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:19,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:19,357 : INFO : EPOCH - 5 : training on 175599 raw words (110094 effective words) took 1.0s, 113322 effective words/s\n",
      "2024-05-07 14:37:19,358 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551249 effective words) took 5.5s, 99487 effective words/s', 'datetime': '2024-05-07T14:37:19.358215', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:19,358 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:19.358730', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:19,361 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:19,640 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #15: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 5.589967727661133, 'train_time_std': 0.2486306329102352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:37:20,184 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:37:20,185 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:20,372 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:37:20.372024', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:20,373 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:37:20.373026', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:20,548 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:37:20,560 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:37:20,561 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:37:20.561633', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:20,832 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:37:20,833 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:20,860 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:20.859534', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:20,861 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:20.861708', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:21,917 : INFO : EPOCH 1 - PROGRESS: at 50.28% examples, 624762 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:22,694 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:22,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:22,718 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:22,719 : INFO : EPOCH - 1 : training on 1788017 raw words (1242987 effective words) took 1.8s, 686410 effective words/s\n",
      "2024-05-07 14:37:23,760 : INFO : EPOCH 2 - PROGRESS: at 46.93% examples, 587316 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:24,654 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:24,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:24,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:24,671 : INFO : EPOCH - 2 : training on 1788017 raw words (1242023 effective words) took 1.9s, 649140 effective words/s\n",
      "2024-05-07 14:37:25,724 : INFO : EPOCH 3 - PROGRESS: at 43.58% examples, 546834 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:26,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:26,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:26,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:26,666 : INFO : EPOCH - 3 : training on 1788017 raw words (1241596 effective words) took 1.9s, 639202 effective words/s\n",
      "2024-05-07 14:37:27,724 : INFO : EPOCH 4 - PROGRESS: at 50.28% examples, 622559 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:28,489 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:28,496 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:28,505 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:28,507 : INFO : EPOCH - 4 : training on 1788017 raw words (1242058 effective words) took 1.8s, 692142 effective words/s\n",
      "2024-05-07 14:37:29,559 : INFO : EPOCH 5 - PROGRESS: at 55.31% examples, 682560 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:30,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:30,290 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:30,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:30,292 : INFO : EPOCH - 5 : training on 1788017 raw words (1241789 effective words) took 1.7s, 711986 effective words/s\n",
      "2024-05-07 14:37:30,292 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210453 effective words) took 9.4s, 658606 effective words/s', 'datetime': '2024-05-07T14:37:30.292494', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:30,293 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:30.293493', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:30,297 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:30,594 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:37:31,215 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:37:31,216 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:31,358 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:37:31.358480', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:31,359 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:37:31.359477', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:31,519 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:37:31,528 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:37:31,530 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:37:31.529998', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:31,780 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:37:31,780 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:31,797 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:31.797504', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:31,799 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:31.799454', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:32,843 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 596004 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:37:33,672 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:33,685 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:33,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:33,688 : INFO : EPOCH - 1 : training on 1788017 raw words (1243016 effective words) took 1.8s, 673496 effective words/s\n",
      "2024-05-07 14:37:34,928 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 804139 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:35,506 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:35,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:35,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:35,532 : INFO : EPOCH - 2 : training on 1788017 raw words (1242244 effective words) took 1.6s, 773897 effective words/s\n",
      "2024-05-07 14:37:36,586 : INFO : EPOCH 3 - PROGRESS: at 53.07% examples, 656774 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:37,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:37,341 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:37,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:37,344 : INFO : EPOCH - 3 : training on 1788017 raw words (1242536 effective words) took 1.8s, 702980 effective words/s\n",
      "2024-05-07 14:37:38,400 : INFO : EPOCH 4 - PROGRESS: at 54.19% examples, 670181 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:39,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:39,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:39,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:39,264 : INFO : EPOCH - 4 : training on 1788017 raw words (1242619 effective words) took 1.9s, 663012 effective words/s\n",
      "2024-05-07 14:37:40,325 : INFO : EPOCH 5 - PROGRESS: at 50.84% examples, 637145 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:41,245 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:41,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:41,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:41,266 : INFO : EPOCH - 5 : training on 1788017 raw words (1242308 effective words) took 1.9s, 639859 effective words/s\n",
      "2024-05-07 14:37:41,269 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212723 effective words) took 9.5s, 656212 effective words/s', 'datetime': '2024-05-07T14:37:41.269744', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:41,270 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:41.270741', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:41,277 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:41,546 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:37:42,163 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:37:42,165 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:42,374 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:37:42.374936', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:42,375 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:37:42.375663', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:42,586 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:37:42,591 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:37:42,592 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:37:42.592486', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:42,864 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:37:42,868 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:42,884 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:42.884663', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:42,888 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:42.888226', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:43,938 : INFO : EPOCH 1 - PROGRESS: at 48.60% examples, 603044 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:44,946 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 592004 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:44,986 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:45,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:45,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:45,010 : INFO : EPOCH - 1 : training on 1788017 raw words (1242514 effective words) took 2.1s, 596431 effective words/s\n",
      "2024-05-07 14:37:46,092 : INFO : EPOCH 2 - PROGRESS: at 37.99% examples, 470989 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:37:47,109 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 512765 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:37:47,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:47,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:47,846 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:47,847 : INFO : EPOCH - 2 : training on 1788017 raw words (1242057 effective words) took 2.8s, 448262 effective words/s\n",
      "2024-05-07 14:37:48,974 : INFO : EPOCH 3 - PROGRESS: at 30.73% examples, 383362 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:49,979 : INFO : EPOCH 3 - PROGRESS: at 82.68% examples, 510218 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:50,396 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:50,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:50,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:50,433 : INFO : EPOCH - 3 : training on 1788017 raw words (1242290 effective words) took 2.5s, 502982 effective words/s\n",
      "2024-05-07 14:37:51,480 : INFO : EPOCH 4 - PROGRESS: at 37.99% examples, 478158 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:52,481 : INFO : EPOCH 4 - PROGRESS: at 96.09% examples, 597298 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:52,517 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:52,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:52,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:52,545 : INFO : EPOCH - 4 : training on 1788017 raw words (1242710 effective words) took 2.1s, 601540 effective words/s\n",
      "2024-05-07 14:37:53,634 : INFO : EPOCH 5 - PROGRESS: at 44.13% examples, 547820 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:54,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:54,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:54,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:54,573 : INFO : EPOCH - 5 : training on 1788017 raw words (1242690 effective words) took 2.0s, 637019 effective words/s\n",
      "2024-05-07 14:37:54,573 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212261 effective words) took 11.7s, 531660 effective words/s', 'datetime': '2024-05-07T14:37:54.573682', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:54,574 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:37:54.574564', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:37:54,587 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:37:54,829 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #16: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 11.741263310114542, 'train_time_std': 1.10786076035788}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:37:55,522 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:37:55,523 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:37:55,723 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:37:55.723801', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:55,724 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:37:55.724931', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:55,897 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:37:55,904 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:37:55,905 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:37:55.905681', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:37:56,217 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:37:56,218 : INFO : resetting layer weights\n",
      "2024-05-07 14:37:56,239 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:37:56.239236', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:37:56,240 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:37:56.240206', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:37:57,290 : INFO : EPOCH 1 - PROGRESS: at 40.22% examples, 505949 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:58,308 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 592269 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:37:58,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:37:58,376 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:37:58,378 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:37:58,378 : INFO : EPOCH - 1 : training on 1788017 raw words (1242430 effective words) took 2.1s, 594786 effective words/s\n",
      "2024-05-07 14:37:59,451 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 339027 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:00,473 : INFO : EPOCH 2 - PROGRESS: at 60.89% examples, 370415 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:38:01,526 : INFO : EPOCH 2 - PROGRESS: at 77.09% examples, 309797 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:02,567 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 288854 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:02,624 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:02,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:02,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:02,642 : INFO : EPOCH - 2 : training on 1788017 raw words (1242495 effective words) took 4.2s, 294766 effective words/s\n",
      "2024-05-07 14:38:03,691 : INFO : EPOCH 3 - PROGRESS: at 25.14% examples, 318657 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:04,706 : INFO : EPOCH 3 - PROGRESS: at 68.16% examples, 420027 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:05,337 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:05,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:05,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:05,357 : INFO : EPOCH - 3 : training on 1788017 raw words (1242811 effective words) took 2.7s, 466002 effective words/s\n",
      "2024-05-07 14:38:06,403 : INFO : EPOCH 4 - PROGRESS: at 34.64% examples, 431426 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:07,407 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 558817 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:07,579 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:07,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:07,594 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:07,594 : INFO : EPOCH - 4 : training on 1788017 raw words (1242670 effective words) took 2.2s, 564065 effective words/s\n",
      "2024-05-07 14:38:08,639 : INFO : EPOCH 5 - PROGRESS: at 46.37% examples, 580071 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:09,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:09,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:09,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:09,636 : INFO : EPOCH - 5 : training on 1788017 raw words (1242711 effective words) took 2.0s, 621012 effective words/s\n",
      "2024-05-07 14:38:09,637 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6213117 effective words) took 13.4s, 463827 effective words/s', 'datetime': '2024-05-07T14:38:09.637734', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:09,637 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:38:09.637734', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:38:09,643 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:38:09,863 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:38:10,390 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:38:10,390 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:38:10,506 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:38:10.506452', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:10,506 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:38:10.506452', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:10,655 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:38:10,663 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:38:10,668 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:38:10.668264', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:10,930 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:38:10,931 : INFO : resetting layer weights\n",
      "2024-05-07 14:38:10,944 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:38:10.944670', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:38:10,947 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:38:10.946585', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:11,990 : INFO : EPOCH 1 - PROGRESS: at 51.96% examples, 650679 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:12,721 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:12,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:12,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:12,741 : INFO : EPOCH - 1 : training on 1788017 raw words (1241630 effective words) took 1.8s, 709261 effective words/s\n",
      "2024-05-07 14:38:13,778 : INFO : EPOCH 2 - PROGRESS: at 52.51% examples, 656118 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:14,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:14,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:14,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:14,534 : INFO : EPOCH - 2 : training on 1788017 raw words (1242255 effective words) took 1.8s, 706814 effective words/s\n",
      "2024-05-07 14:38:15,580 : INFO : EPOCH 3 - PROGRESS: at 53.07% examples, 658816 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:16,358 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:16,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:16,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:16,372 : INFO : EPOCH - 3 : training on 1788017 raw words (1242009 effective words) took 1.8s, 690383 effective words/s\n",
      "2024-05-07 14:38:17,415 : INFO : EPOCH 4 - PROGRESS: at 51.96% examples, 645669 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:18,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:18,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:18,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:18,123 : INFO : EPOCH - 4 : training on 1788017 raw words (1241959 effective words) took 1.7s, 723891 effective words/s\n",
      "2024-05-07 14:38:19,158 : INFO : EPOCH 5 - PROGRESS: at 55.87% examples, 694323 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:19,833 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:19,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:19,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:19,848 : INFO : EPOCH - 5 : training on 1788017 raw words (1242121 effective words) took 1.7s, 733778 effective words/s\n",
      "2024-05-07 14:38:19,848 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209974 effective words) took 8.9s, 697734 effective words/s', 'datetime': '2024-05-07T14:38:19.848498', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:19,849 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:38:19.849495', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:38:19,854 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:38:20,057 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:38:20,571 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:38:20,572 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:38:20,690 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:38:20.690560', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:20,691 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:38:20.691519', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:20,850 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:38:20,855 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:38:20,856 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:38:20.856478', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:21,127 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:38:21,128 : INFO : resetting layer weights\n",
      "2024-05-07 14:38:21,145 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:38:21.145591', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:38:21,146 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:38:21.146586', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:22,177 : INFO : EPOCH 1 - PROGRESS: at 53.07% examples, 661395 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:22,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:22,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:22,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:22,908 : INFO : EPOCH - 1 : training on 1788017 raw words (1242458 effective words) took 1.7s, 716275 effective words/s\n",
      "2024-05-07 14:38:23,942 : INFO : EPOCH 2 - PROGRESS: at 53.63% examples, 669822 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:24,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:24,618 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:24,625 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:24,630 : INFO : EPOCH - 2 : training on 1788017 raw words (1242073 effective words) took 1.7s, 735590 effective words/s\n",
      "2024-05-07 14:38:25,665 : INFO : EPOCH 3 - PROGRESS: at 55.31% examples, 687478 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:26,439 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:26,450 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:26,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:26,453 : INFO : EPOCH - 3 : training on 1788017 raw words (1241675 effective words) took 1.8s, 693018 effective words/s\n",
      "2024-05-07 14:38:27,490 : INFO : EPOCH 4 - PROGRESS: at 46.93% examples, 588002 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:28,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:28,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:28,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:28,377 : INFO : EPOCH - 4 : training on 1788017 raw words (1242712 effective words) took 1.9s, 657843 effective words/s\n",
      "2024-05-07 14:38:29,442 : INFO : EPOCH 5 - PROGRESS: at 43.58% examples, 541064 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:30,440 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:30,453 : INFO : EPOCH 5 - PROGRESS: at 99.44% examples, 611828 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:38:30,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:30,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:30,470 : INFO : EPOCH - 5 : training on 1788017 raw words (1242375 effective words) took 2.0s, 609252 effective words/s\n",
      "2024-05-07 14:38:30,471 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211293 effective words) took 9.3s, 666151 effective words/s', 'datetime': '2024-05-07T14:38:30.471113', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:30,472 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:38:30.472241', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:38:30,482 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:38:30,728 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #17: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 11.965096235275269, 'train_time_std': 2.193017183047823}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:38:31,390 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:38:31,391 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:38:31,520 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:38:31.520504', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:31,521 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:38:31.521516', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:31,676 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:38:31,682 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:38:31,683 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:38:31.683785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:31,698 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:38:32,739 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:38:33,013 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:38:33,014 : INFO : resetting layer weights\n",
      "2024-05-07 14:38:33,038 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:38:33.038207', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:38:33,038 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:38:33.038418', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:34,093 : INFO : EPOCH 1 - PROGRESS: at 18.99% examples, 237679 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:35,180 : INFO : EPOCH 1 - PROGRESS: at 37.43% examples, 224172 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:38:36,185 : INFO : EPOCH 1 - PROGRESS: at 49.16% examples, 198432 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:38:37,256 : INFO : EPOCH 1 - PROGRESS: at 66.48% examples, 197727 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:38,267 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 208994 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:38,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:38,784 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:38,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:38,794 : INFO : EPOCH - 1 : training on 1788017 raw words (1242569 effective words) took 5.7s, 217421 effective words/s\n",
      "2024-05-07 14:38:39,883 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 260360 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:40,896 : INFO : EPOCH 2 - PROGRESS: at 43.58% examples, 267437 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:41,938 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 273929 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:42,944 : INFO : EPOCH 2 - PROGRESS: at 93.30% examples, 283313 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:43,195 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:43,230 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:43,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:43,237 : INFO : EPOCH - 2 : training on 1788017 raw words (1242527 effective words) took 4.4s, 283111 effective words/s\n",
      "2024-05-07 14:38:44,276 : INFO : EPOCH 3 - PROGRESS: at 20.67% examples, 260452 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:45,306 : INFO : EPOCH 3 - PROGRESS: at 48.60% examples, 299435 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:46,312 : INFO : EPOCH 3 - PROGRESS: at 75.98% examples, 310662 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:47,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:47,134 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:47,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:47,146 : INFO : EPOCH - 3 : training on 1788017 raw words (1241746 effective words) took 3.9s, 320351 effective words/s\n",
      "2024-05-07 14:38:48,221 : INFO : EPOCH 4 - PROGRESS: at 9.50% examples, 120544 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:49,275 : INFO : EPOCH 4 - PROGRESS: at 29.05% examples, 178564 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:50,292 : INFO : EPOCH 4 - PROGRESS: at 55.87% examples, 226435 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:51,313 : INFO : EPOCH 4 - PROGRESS: at 79.33% examples, 240718 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:52,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:52,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:52,183 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:52,184 : INFO : EPOCH - 4 : training on 1788017 raw words (1241661 effective words) took 5.0s, 249775 effective words/s\n",
      "2024-05-07 14:38:53,266 : INFO : EPOCH 5 - PROGRESS: at 19.55% examples, 240916 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:38:54,266 : INFO : EPOCH 5 - PROGRESS: at 45.25% examples, 279588 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:38:55,285 : INFO : EPOCH 5 - PROGRESS: at 66.48% examples, 270716 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:56,297 : INFO : EPOCH 5 - PROGRESS: at 79.33% examples, 243032 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:57,312 : INFO : EPOCH 5 - PROGRESS: at 96.09% examples, 235457 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:38:57,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:38:57,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:38:57,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:38:57,446 : INFO : EPOCH - 5 : training on 1788017 raw words (1242376 effective words) took 5.2s, 238359 effective words/s\n",
      "2024-05-07 14:38:57,447 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210879 effective words) took 24.4s, 254454 effective words/s', 'datetime': '2024-05-07T14:38:57.447902', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:38:57,448 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:38:57.448805', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:38:57,470 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:38:57,795 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:38:58,503 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:38:58,505 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:38:58,650 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:38:58.650441', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:58,651 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:38:58.651438', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:58,829 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:38:58,834 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:38:58,835 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:38:58.835449', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:38:58,849 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:38:59,754 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:38:59,991 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:38:59,992 : INFO : resetting layer weights\n",
      "2024-05-07 14:39:00,015 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:39:00.015388', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:39:00,016 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:39:00.016937', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:39:01,109 : INFO : EPOCH 1 - PROGRESS: at 19.55% examples, 235184 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:02,121 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 288414 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:03,140 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 308702 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:03,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:03,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:03,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:03,910 : INFO : EPOCH - 1 : training on 1788017 raw words (1242340 effective words) took 3.9s, 322156 effective words/s\n",
      "2024-05-07 14:39:04,955 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 280974 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:05,982 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 332547 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:06,987 : INFO : EPOCH 2 - PROGRESS: at 82.68% examples, 338061 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:07,596 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:07,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:07,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:07,635 : INFO : EPOCH - 2 : training on 1788017 raw words (1242686 effective words) took 3.7s, 336829 effective words/s\n",
      "2024-05-07 14:39:08,698 : INFO : EPOCH 3 - PROGRESS: at 19.55% examples, 242066 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:09,702 : INFO : EPOCH 3 - PROGRESS: at 45.25% examples, 279848 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:10,787 : INFO : EPOCH 3 - PROGRESS: at 69.83% examples, 278560 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:39:11,816 : INFO : EPOCH 3 - PROGRESS: at 89.39% examples, 268425 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:12,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:12,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:12,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:12,198 : INFO : EPOCH - 3 : training on 1788017 raw words (1242582 effective words) took 4.5s, 274503 effective words/s\n",
      "2024-05-07 14:39:13,260 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 213949 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:39:14,274 : INFO : EPOCH 4 - PROGRESS: at 41.34% examples, 254831 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:15,296 : INFO : EPOCH 4 - PROGRESS: at 68.72% examples, 278649 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:16,296 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 290692 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:39:16,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:16,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:16,499 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:16,500 : INFO : EPOCH - 4 : training on 1788017 raw words (1242401 effective words) took 4.3s, 291141 effective words/s\n",
      "2024-05-07 14:39:17,547 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 240885 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:39:18,558 : INFO : EPOCH 5 - PROGRESS: at 46.93% examples, 292736 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:19,561 : INFO : EPOCH 5 - PROGRESS: at 79.89% examples, 329651 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:20,224 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:20,248 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:20,250 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:20,250 : INFO : EPOCH - 5 : training on 1788017 raw words (1242729 effective words) took 3.7s, 335416 effective words/s\n",
      "2024-05-07 14:39:20,255 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212738 effective words) took 20.2s, 306999 effective words/s', 'datetime': '2024-05-07T14:39:20.254442', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:39:20,258 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:39:20.258125', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:39:20,277 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:39:20,470 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:39:21,003 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:39:21,004 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:39:21,127 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:39:21.127806', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:39:21,128 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:39:21.128774', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:39:21,266 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:39:21,272 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:39:21,273 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:39:21.273465', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:39:21,291 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:39:22,298 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:39:22,533 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:39:22,534 : INFO : resetting layer weights\n",
      "2024-05-07 14:39:22,548 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:39:22.548711', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:39:22,549 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:39:22.549627', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:39:23,590 : INFO : EPOCH 1 - PROGRESS: at 24.58% examples, 308230 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:24,597 : INFO : EPOCH 1 - PROGRESS: at 54.75% examples, 338861 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:25,598 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 322389 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:26,331 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:26,363 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:26,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:26,372 : INFO : EPOCH - 1 : training on 1788017 raw words (1242624 effective words) took 3.8s, 327641 effective words/s\n",
      "2024-05-07 14:39:27,430 : INFO : EPOCH 2 - PROGRESS: at 19.55% examples, 244179 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:28,441 : INFO : EPOCH 2 - PROGRESS: at 46.37% examples, 286950 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:29,442 : INFO : EPOCH 2 - PROGRESS: at 70.95% examples, 290911 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:30,486 : INFO : EPOCH 2 - PROGRESS: at 97.77% examples, 298540 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:39:30,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:30,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:30,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:30,530 : INFO : EPOCH - 2 : training on 1788017 raw words (1241972 effective words) took 4.1s, 301640 effective words/s\n",
      "2024-05-07 14:39:31,580 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 194992 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:32,592 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 259366 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:33,603 : INFO : EPOCH 3 - PROGRESS: at 72.63% examples, 296899 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:34,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:34,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:34,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:34,606 : INFO : EPOCH - 3 : training on 1788017 raw words (1242598 effective words) took 4.0s, 307243 effective words/s\n",
      "2024-05-07 14:39:35,642 : INFO : EPOCH 4 - PROGRESS: at 21.23% examples, 269149 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:36,725 : INFO : EPOCH 4 - PROGRESS: at 49.16% examples, 296093 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:37,728 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 294823 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:38,630 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:38,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:38,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:38,667 : INFO : EPOCH - 4 : training on 1788017 raw words (1242623 effective words) took 4.0s, 308677 effective words/s\n",
      "2024-05-07 14:39:39,748 : INFO : EPOCH 5 - PROGRESS: at 19.55% examples, 237738 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:40,750 : INFO : EPOCH 5 - PROGRESS: at 48.60% examples, 298128 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:41,780 : INFO : EPOCH 5 - PROGRESS: at 75.42% examples, 304962 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:39:42,700 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:42,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:42,744 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:42,745 : INFO : EPOCH - 5 : training on 1788017 raw words (1242267 effective words) took 4.0s, 307406 effective words/s\n",
      "2024-05-07 14:39:42,746 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212084 effective words) took 20.2s, 307583 effective words/s', 'datetime': '2024-05-07T14:39:42.746874', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:39:42,747 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:39:42.747139', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:39:42,766 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #18: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 24.094276348749798, 'train_time_std': 2.0501386098028562}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:39:43,076 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:39:44,151 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:39:44,152 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:39:44,337 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:39:44.337168', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:39:44,338 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:39:44.338165', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:39:44,576 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:39:44,585 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:39:44,587 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:39:44.587453', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:39:44,610 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:39:45,654 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:39:46,010 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:39:46,011 : INFO : resetting layer weights\n",
      "2024-05-07 14:39:46,033 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:39:46.033006', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:39:46,035 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:39:46.034005', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:39:47,144 : INFO : EPOCH 1 - PROGRESS: at 14.53% examples, 175690 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:48,147 : INFO : EPOCH 1 - PROGRESS: at 33.52% examples, 205952 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:49,163 : INFO : EPOCH 1 - PROGRESS: at 56.42% examples, 229431 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:50,164 : INFO : EPOCH 1 - PROGRESS: at 83.24% examples, 254482 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:50,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:50,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:50,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:50,992 : INFO : EPOCH - 1 : training on 1788017 raw words (1242623 effective words) took 4.9s, 253719 effective words/s\n",
      "2024-05-07 14:39:52,054 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 265148 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:53,079 : INFO : EPOCH 2 - PROGRESS: at 49.72% examples, 305469 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:54,090 : INFO : EPOCH 2 - PROGRESS: at 78.21% examples, 318619 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:54,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:54,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:54,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:54,937 : INFO : EPOCH - 2 : training on 1788017 raw words (1241284 effective words) took 3.9s, 318306 effective words/s\n",
      "2024-05-07 14:39:55,972 : INFO : EPOCH 3 - PROGRESS: at 21.79% examples, 275850 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:39:56,994 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 315005 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:58,012 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 320008 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:39:58,876 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:39:58,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:39:58,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:39:58,916 : INFO : EPOCH - 3 : training on 1788017 raw words (1243038 effective words) took 3.9s, 314957 effective words/s\n",
      "2024-05-07 14:39:59,967 : INFO : EPOCH 4 - PROGRESS: at 16.76% examples, 211614 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:00,996 : INFO : EPOCH 4 - PROGRESS: at 41.34% examples, 255368 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:02,039 : INFO : EPOCH 4 - PROGRESS: at 64.25% examples, 259192 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:03,069 : INFO : EPOCH 4 - PROGRESS: at 87.15% examples, 263761 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:03,572 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:03,589 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:03,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:03,606 : INFO : EPOCH - 4 : training on 1788017 raw words (1241924 effective words) took 4.6s, 267350 effective words/s\n",
      "2024-05-07 14:40:04,687 : INFO : EPOCH 5 - PROGRESS: at 16.20% examples, 199197 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:05,702 : INFO : EPOCH 5 - PROGRESS: at 39.11% examples, 240615 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:06,724 : INFO : EPOCH 5 - PROGRESS: at 64.25% examples, 260087 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:07,730 : INFO : EPOCH 5 - PROGRESS: at 89.39% examples, 273012 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:40:08,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:08,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:08,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:08,071 : INFO : EPOCH - 5 : training on 1788017 raw words (1242547 effective words) took 4.4s, 281268 effective words/s\n",
      "2024-05-07 14:40:08,072 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211416 effective words) took 22.0s, 281869 effective words/s', 'datetime': '2024-05-07T14:40:08.072766', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:40:08,073 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:40:08.073764', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:40:08,088 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:40:08,299 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:40:08,992 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:40:08,993 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:40:09,120 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:40:09.120240', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:09,121 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:40:09.121242', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:09,270 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:40:09,276 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:40:09,276 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:40:09.276826', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:09,291 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:40:10,335 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:40:10,574 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:40:10,575 : INFO : resetting layer weights\n",
      "2024-05-07 14:40:10,589 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:40:10.589684', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:40:10,591 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:40:10.591245', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:40:11,646 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 259117 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:12,649 : INFO : EPOCH 1 - PROGRESS: at 46.93% examples, 292124 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:13,656 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 315114 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:14,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:14,450 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:14,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:14,459 : INFO : EPOCH - 1 : training on 1788017 raw words (1242388 effective words) took 3.8s, 324764 effective words/s\n",
      "2024-05-07 14:40:15,518 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 263059 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:16,533 : INFO : EPOCH 2 - PROGRESS: at 49.16% examples, 302494 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:17,541 : INFO : EPOCH 2 - PROGRESS: at 76.54% examples, 312572 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:18,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:18,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:18,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:18,502 : INFO : EPOCH - 2 : training on 1788017 raw words (1241843 effective words) took 4.0s, 309906 effective words/s\n",
      "2024-05-07 14:40:19,588 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 217164 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:40:20,626 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 257100 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:40:21,648 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 284763 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:40:22,654 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 298216 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:40:22,666 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:22,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:22,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:22,702 : INFO : EPOCH - 3 : training on 1788017 raw words (1242397 effective words) took 4.1s, 301084 effective words/s\n",
      "2024-05-07 14:40:23,758 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 278586 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:24,766 : INFO : EPOCH 4 - PROGRESS: at 51.96% examples, 321321 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:25,780 : INFO : EPOCH 4 - PROGRESS: at 83.24% examples, 340624 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:26,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:26,321 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:26,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:26,325 : INFO : EPOCH - 4 : training on 1788017 raw words (1242114 effective words) took 3.6s, 346596 effective words/s\n",
      "2024-05-07 14:40:27,384 : INFO : EPOCH 5 - PROGRESS: at 24.58% examples, 304900 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:28,392 : INFO : EPOCH 5 - PROGRESS: at 56.42% examples, 346679 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:29,392 : INFO : EPOCH 5 - PROGRESS: at 86.59% examples, 355405 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:29,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:29,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:29,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:29,933 : INFO : EPOCH - 5 : training on 1788017 raw words (1241968 effective words) took 3.6s, 347730 effective words/s\n",
      "2024-05-07 14:40:29,934 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210710 effective words) took 19.3s, 321079 effective words/s', 'datetime': '2024-05-07T14:40:29.934679', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:40:29,935 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:40:29.935785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:40:29,951 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:40:30,161 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:40:30,751 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:40:30,752 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:40:30,876 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:40:30.876204', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:30,878 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:40:30.878210', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:31,021 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:40:31,026 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:40:31,028 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:40:31.027518', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:31,045 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:40:32,387 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:40:32,671 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:40:32,672 : INFO : resetting layer weights\n",
      "2024-05-07 14:40:32,687 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:40:32.687396', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:40:32,688 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:40:32.688395', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:40:33,726 : INFO : EPOCH 1 - PROGRESS: at 16.20% examples, 204239 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:34,726 : INFO : EPOCH 1 - PROGRESS: at 38.55% examples, 241895 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:35,752 : INFO : EPOCH 1 - PROGRESS: at 64.80% examples, 265405 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:36,764 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 292028 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:40:36,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:36,905 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:36,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:36,908 : INFO : EPOCH - 1 : training on 1788017 raw words (1242507 effective words) took 4.2s, 296611 effective words/s\n",
      "2024-05-07 14:40:37,946 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 269253 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:40:38,970 : INFO : EPOCH 2 - PROGRESS: at 51.40% examples, 318385 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:39,977 : INFO : EPOCH 2 - PROGRESS: at 83.24% examples, 341518 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:40,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:40,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:40,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:40,545 : INFO : EPOCH - 2 : training on 1788017 raw words (1242211 effective words) took 3.6s, 345130 effective words/s\n",
      "2024-05-07 14:40:41,625 : INFO : EPOCH 3 - PROGRESS: at 22.91% examples, 277937 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:42,632 : INFO : EPOCH 3 - PROGRESS: at 52.51% examples, 320148 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:43,637 : INFO : EPOCH 3 - PROGRESS: at 80.45% examples, 327456 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:44,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:44,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:44,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:44,380 : INFO : EPOCH - 3 : training on 1788017 raw words (1242405 effective words) took 3.8s, 326957 effective words/s\n",
      "2024-05-07 14:40:45,425 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 247763 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:46,426 : INFO : EPOCH 4 - PROGRESS: at 47.49% examples, 297618 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:47,464 : INFO : EPOCH 4 - PROGRESS: at 75.98% examples, 310979 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:48,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:48,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:48,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:48,305 : INFO : EPOCH - 4 : training on 1788017 raw words (1242907 effective words) took 3.9s, 320142 effective words/s\n",
      "2024-05-07 14:40:49,348 : INFO : EPOCH 5 - PROGRESS: at 22.91% examples, 288313 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:40:50,352 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 336408 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:40:51,364 : INFO : EPOCH 5 - PROGRESS: at 84.36% examples, 347090 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:51,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:51,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:51,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:51,932 : INFO : EPOCH - 5 : training on 1788017 raw words (1242062 effective words) took 3.6s, 345848 effective words/s\n",
      "2024-05-07 14:40:51,933 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212092 effective words) took 19.2s, 322796 effective words/s', 'datetime': '2024-05-07T14:40:51.933615', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:40:51,934 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:40:51.934609', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:40:51,950 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:40:52,153 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #19: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 23.061163902282715, 'train_time_std': 1.5991094748610017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:40:52,737 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:40:52,737 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:40:52,861 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:40:52.861246', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:52,862 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:40:52.862231', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:53,017 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:40:53,021 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:40:53,021 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:40:53.021416', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:40:53,284 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:40:53,285 : INFO : resetting layer weights\n",
      "2024-05-07 14:40:53,298 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:40:53.298744', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:40:53,299 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:40:53.299741', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:40:54,363 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 172647 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:55,380 : INFO : EPOCH 1 - PROGRESS: at 32.40% examples, 199782 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:56,394 : INFO : EPOCH 1 - PROGRESS: at 49.16% examples, 201696 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:57,398 : INFO : EPOCH 1 - PROGRESS: at 62.01% examples, 189628 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:58,407 : INFO : EPOCH 1 - PROGRESS: at 77.09% examples, 189211 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:59,428 : INFO : EPOCH 1 - PROGRESS: at 94.41% examples, 192604 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:40:59,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:40:59,731 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:40:59,741 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:40:59,742 : INFO : EPOCH - 1 : training on 1788017 raw words (1241821 effective words) took 6.4s, 193816 effective words/s\n",
      "2024-05-07 14:41:00,809 : INFO : EPOCH 2 - PROGRESS: at 12.29% examples, 151056 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:01,817 : INFO : EPOCH 2 - PROGRESS: at 30.17% examples, 186616 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:02,831 : INFO : EPOCH 2 - PROGRESS: at 45.25% examples, 185692 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:03,843 : INFO : EPOCH 2 - PROGRESS: at 62.57% examples, 190948 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:04,897 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 195303 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:05,919 : INFO : EPOCH 2 - PROGRESS: at 95.53% examples, 193227 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:41:06,304 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:06,425 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:06,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:06,437 : INFO : EPOCH - 2 : training on 1788017 raw words (1241997 effective words) took 6.7s, 186370 effective words/s\n",
      "2024-05-07 14:41:07,621 : INFO : EPOCH 3 - PROGRESS: at 7.26% examples, 82038 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:08,662 : INFO : EPOCH 3 - PROGRESS: at 18.44% examples, 107559 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:09,691 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 133964 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:10,698 : INFO : EPOCH 3 - PROGRESS: at 48.04% examples, 143177 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:11,730 : INFO : EPOCH 3 - PROGRESS: at 62.57% examples, 148206 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:12,735 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 155670 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:13,747 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 161640 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:41:13,960 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:14,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:14,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:14,045 : INFO : EPOCH - 3 : training on 1788017 raw words (1242024 effective words) took 7.6s, 164266 effective words/s\n",
      "2024-05-07 14:41:15,100 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 153399 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:16,111 : INFO : EPOCH 4 - PROGRESS: at 29.05% examples, 181137 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:17,165 : INFO : EPOCH 4 - PROGRESS: at 47.49% examples, 193143 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:18,187 : INFO : EPOCH 4 - PROGRESS: at 64.25% examples, 194343 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:19,217 : INFO : EPOCH 4 - PROGRESS: at 82.12% examples, 198782 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:20,200 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:20,254 : INFO : EPOCH 4 - PROGRESS: at 99.44% examples, 200060 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:41:20,256 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:20,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:20,271 : INFO : EPOCH - 4 : training on 1788017 raw words (1242521 effective words) took 6.2s, 200669 effective words/s\n",
      "2024-05-07 14:41:21,312 : INFO : EPOCH 5 - PROGRESS: at 12.85% examples, 162471 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:22,313 : INFO : EPOCH 5 - PROGRESS: at 29.61% examples, 186722 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:23,326 : INFO : EPOCH 5 - PROGRESS: at 46.93% examples, 194922 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:41:24,348 : INFO : EPOCH 5 - PROGRESS: at 64.25% examples, 197326 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:41:25,371 : INFO : EPOCH 5 - PROGRESS: at 81.56% examples, 200140 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:26,377 : INFO : EPOCH 5 - PROGRESS: at 97.21% examples, 199103 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:26,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:26,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:26,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:26,527 : INFO : EPOCH - 5 : training on 1788017 raw words (1242422 effective words) took 6.2s, 199634 effective words/s\n",
      "2024-05-07 14:41:26,531 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210785 effective words) took 33.2s, 186898 effective words/s', 'datetime': '2024-05-07T14:41:26.531800', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:41:26,533 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:41:26.533041', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:41:26,549 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:41:26,784 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:41:27,383 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:41:27,384 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:41:27,539 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:41:27.539058', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:41:27,539 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:41:27.539968', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:41:27,709 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:41:27,720 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:41:27,723 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:41:27.723632', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:41:28,040 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:41:28,043 : INFO : resetting layer weights\n",
      "2024-05-07 14:41:28,062 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:41:28.062505', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:41:28,064 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:41:28.064489', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:41:29,110 : INFO : EPOCH 1 - PROGRESS: at 12.85% examples, 162567 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:30,162 : INFO : EPOCH 1 - PROGRESS: at 30.73% examples, 188357 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:31,176 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 187119 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:32,178 : INFO : EPOCH 1 - PROGRESS: at 62.01% examples, 189109 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:33,197 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 187029 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:34,200 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 185876 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:34,724 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:34,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:34,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:34,798 : INFO : EPOCH - 1 : training on 1788017 raw words (1242511 effective words) took 6.7s, 185580 effective words/s\n",
      "2024-05-07 14:41:35,884 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 130214 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:41:36,924 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 146119 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:37,954 : INFO : EPOCH 2 - PROGRESS: at 36.31% examples, 146672 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:38,961 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 154612 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:39,995 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 164185 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:41,073 : INFO : EPOCH 2 - PROGRESS: at 87.15% examples, 173920 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:41:41,739 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:41,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:41,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:41,827 : INFO : EPOCH - 2 : training on 1788017 raw words (1242123 effective words) took 7.0s, 177772 effective words/s\n",
      "2024-05-07 14:41:42,882 : INFO : EPOCH 3 - PROGRESS: at 9.50% examples, 120737 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:43,894 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 161351 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:44,900 : INFO : EPOCH 3 - PROGRESS: at 38.55% examples, 160531 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:45,905 : INFO : EPOCH 3 - PROGRESS: at 56.42% examples, 174820 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:46,914 : INFO : EPOCH 3 - PROGRESS: at 70.95% examples, 175031 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:47,974 : INFO : EPOCH 3 - PROGRESS: at 86.59% examples, 176681 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:48,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:48,827 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:48,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:48,837 : INFO : EPOCH - 3 : training on 1788017 raw words (1242516 effective words) took 7.0s, 178485 effective words/s\n",
      "2024-05-07 14:41:49,881 : INFO : EPOCH 4 - PROGRESS: at 6.70% examples, 85435 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:50,911 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 139151 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:51,929 : INFO : EPOCH 4 - PROGRESS: at 39.66% examples, 163666 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:53,021 : INFO : EPOCH 4 - PROGRESS: at 50.28% examples, 152051 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:54,021 : INFO : EPOCH 4 - PROGRESS: at 63.13% examples, 152402 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:55,056 : INFO : EPOCH 4 - PROGRESS: at 79.89% examples, 160772 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:56,094 : INFO : EPOCH 4 - PROGRESS: at 96.09% examples, 165547 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:56,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:41:56,264 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:41:56,276 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:41:56,276 : INFO : EPOCH - 4 : training on 1788017 raw words (1242067 effective words) took 7.4s, 167822 effective words/s\n",
      "2024-05-07 14:41:57,330 : INFO : EPOCH 5 - PROGRESS: at 10.61% examples, 134357 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:58,398 : INFO : EPOCH 5 - PROGRESS: at 25.70% examples, 156503 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:41:59,428 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 171624 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:00,429 : INFO : EPOCH 5 - PROGRESS: at 59.22% examples, 179386 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:01,457 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 185402 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:02,469 : INFO : EPOCH 5 - PROGRESS: at 93.85% examples, 189736 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:02,785 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:02,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:02,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:02,861 : INFO : EPOCH - 5 : training on 1788017 raw words (1242458 effective words) took 6.5s, 189891 effective words/s\n",
      "2024-05-07 14:42:02,861 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211675 effective words) took 34.8s, 178513 effective words/s', 'datetime': '2024-05-07T14:42:02.861633', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:42:02,862 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:42:02.862629', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:42:02,869 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:42:03,108 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:42:03,686 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:42:03,687 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:42:03,808 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:42:03.807979', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:42:03,808 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:42:03.808909', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:42:03,980 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:42:03,986 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:42:03,986 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:42:03.986861', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:42:04,253 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:42:04,254 : INFO : resetting layer weights\n",
      "2024-05-07 14:42:04,267 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:42:04.266514', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:42:04,267 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:42:04.267543', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:42:05,311 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 175293 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:06,336 : INFO : EPOCH 1 - PROGRESS: at 32.96% examples, 204344 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:07,337 : INFO : EPOCH 1 - PROGRESS: at 50.84% examples, 209939 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:08,363 : INFO : EPOCH 1 - PROGRESS: at 67.60% examples, 206655 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:09,408 : INFO : EPOCH 1 - PROGRESS: at 84.36% examples, 205400 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:10,279 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:10,346 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:10,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:10,359 : INFO : EPOCH - 1 : training on 1788017 raw words (1242436 effective words) took 6.1s, 205090 effective words/s\n",
      "2024-05-07 14:42:11,436 : INFO : EPOCH 2 - PROGRESS: at 6.70% examples, 83642 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:12,506 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 134932 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:13,548 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 156821 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:14,557 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 163151 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:15,560 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 172443 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:42:16,581 : INFO : EPOCH 2 - PROGRESS: at 89.39% examples, 180103 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:17,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:17,222 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:17,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:17,235 : INFO : EPOCH - 2 : training on 1788017 raw words (1242298 effective words) took 6.8s, 181909 effective words/s\n",
      "2024-05-07 14:42:18,310 : INFO : EPOCH 3 - PROGRESS: at 11.17% examples, 138934 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:19,354 : INFO : EPOCH 3 - PROGRESS: at 27.37% examples, 167392 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:20,400 : INFO : EPOCH 3 - PROGRESS: at 45.81% examples, 184320 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:21,428 : INFO : EPOCH 3 - PROGRESS: at 60.89% examples, 182473 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:22,439 : INFO : EPOCH 3 - PROGRESS: at 77.09% examples, 186044 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:23,500 : INFO : EPOCH 3 - PROGRESS: at 94.97% examples, 189850 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:23,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:23,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:23,822 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:23,823 : INFO : EPOCH - 3 : training on 1788017 raw words (1241493 effective words) took 6.5s, 189799 effective words/s\n",
      "2024-05-07 14:42:24,887 : INFO : EPOCH 4 - PROGRESS: at 8.94% examples, 113617 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:25,920 : INFO : EPOCH 4 - PROGRESS: at 20.67% examples, 128553 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:26,983 : INFO : EPOCH 4 - PROGRESS: at 37.43% examples, 151659 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:28,126 : INFO : EPOCH 4 - PROGRESS: at 47.49% examples, 140309 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:29,176 : INFO : EPOCH 4 - PROGRESS: at 60.89% examples, 142936 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:30,188 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 154267 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:31,189 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 161615 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:42:31,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:31,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:31,455 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:31,456 : INFO : EPOCH - 4 : training on 1788017 raw words (1242490 effective words) took 7.6s, 163966 effective words/s\n",
      "2024-05-07 14:42:32,510 : INFO : EPOCH 5 - PROGRESS: at 13.41% examples, 167405 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:33,514 : INFO : EPOCH 5 - PROGRESS: at 29.05% examples, 181898 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:34,542 : INFO : EPOCH 5 - PROGRESS: at 45.25% examples, 186101 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:35,546 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 180117 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:36,558 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 179519 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:37,606 : INFO : EPOCH 5 - PROGRESS: at 88.83% examples, 180678 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:38,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:38,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:38,557 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:38,559 : INFO : EPOCH - 5 : training on 1788017 raw words (1242481 effective words) took 7.1s, 175806 effective words/s\n",
      "2024-05-07 14:42:38,560 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211198 effective words) took 34.3s, 181131 effective words/s', 'datetime': '2024-05-07T14:42:38.560038', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:42:38,564 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:42:38.564048', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:42:38,573 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:42:38,939 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #20: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 35.540812253952026, 'train_time_std': 0.7122043075515381}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:42:39,807 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:42:39,808 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:42:39,980 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:42:39.980443', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:42:39,981 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:42:39.981447', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:42:40,222 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:42:40,238 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:42:40,238 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:42:40.238838', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:42:40,638 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:42:40,639 : INFO : resetting layer weights\n",
      "2024-05-07 14:42:40,657 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:42:40.657605', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:42:40,658 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:42:40.658600', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:42:41,758 : INFO : EPOCH 1 - PROGRESS: at 8.94% examples, 108834 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:42,788 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 136095 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:43,840 : INFO : EPOCH 1 - PROGRESS: at 36.31% examples, 145763 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:44,876 : INFO : EPOCH 1 - PROGRESS: at 49.16% examples, 147928 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:45,882 : INFO : EPOCH 1 - PROGRESS: at 61.45% examples, 147566 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:46,956 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 142262 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:48,005 : INFO : EPOCH 1 - PROGRESS: at 83.24% examples, 141848 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:49,040 : INFO : EPOCH 1 - PROGRESS: at 93.85% examples, 140012 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:49,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:49,531 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:49,546 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:49,546 : INFO : EPOCH - 1 : training on 1788017 raw words (1241951 effective words) took 8.8s, 140468 effective words/s\n",
      "2024-05-07 14:42:50,717 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 83333 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:51,728 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 103223 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:52,781 : INFO : EPOCH 2 - PROGRESS: at 29.05% examples, 115710 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:42:53,785 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 127474 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:54,806 : INFO : EPOCH 2 - PROGRESS: at 56.42% examples, 135190 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:55,834 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 142524 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:56,867 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 146178 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:42:57,910 : INFO : EPOCH 2 - PROGRESS: at 97.77% examples, 146288 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:42:57,922 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:42:58,020 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:42:58,040 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:42:58,043 : INFO : EPOCH - 2 : training on 1788017 raw words (1241990 effective words) took 8.4s, 147111 effective words/s\n",
      "2024-05-07 14:42:59,100 : INFO : EPOCH 3 - PROGRESS: at 7.82% examples, 100107 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:00,183 : INFO : EPOCH 3 - PROGRESS: at 20.67% examples, 125954 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:01,234 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 136987 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:02,253 : INFO : EPOCH 3 - PROGRESS: at 47.49% examples, 143486 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:03,271 : INFO : EPOCH 3 - PROGRESS: at 61.45% examples, 147668 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:04,287 : INFO : EPOCH 3 - PROGRESS: at 73.74% examples, 148140 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:05,291 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 150708 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:06,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:06,176 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:06,187 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:06,188 : INFO : EPOCH - 3 : training on 1788017 raw words (1241842 effective words) took 8.1s, 153539 effective words/s\n",
      "2024-05-07 14:43:07,250 : INFO : EPOCH 4 - PROGRESS: at 10.06% examples, 127334 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:08,290 : INFO : EPOCH 4 - PROGRESS: at 24.02% examples, 148532 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:09,316 : INFO : EPOCH 4 - PROGRESS: at 37.43% examples, 153121 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:10,318 : INFO : EPOCH 4 - PROGRESS: at 51.96% examples, 159609 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:11,336 : INFO : EPOCH 4 - PROGRESS: at 65.92% examples, 160646 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:12,383 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 159555 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:13,465 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 158714 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:14,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:14,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:14,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:14,178 : INFO : EPOCH - 4 : training on 1788017 raw words (1242631 effective words) took 7.9s, 156502 effective words/s\n",
      "2024-05-07 14:43:15,242 : INFO : EPOCH 5 - PROGRESS: at 7.82% examples, 99536 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:16,256 : INFO : EPOCH 5 - PROGRESS: at 21.79% examples, 136616 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:17,310 : INFO : EPOCH 5 - PROGRESS: at 34.08% examples, 139665 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:18,319 : INFO : EPOCH 5 - PROGRESS: at 47.49% examples, 145947 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:19,379 : INFO : EPOCH 5 - PROGRESS: at 60.89% examples, 147125 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:20,446 : INFO : EPOCH 5 - PROGRESS: at 74.30% examples, 148742 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:21,447 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 150316 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:22,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:22,474 : INFO : EPOCH 5 - PROGRESS: at 99.44% examples, 149915 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:43:22,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:22,497 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:22,498 : INFO : EPOCH - 5 : training on 1788017 raw words (1242399 effective words) took 8.3s, 150341 effective words/s\n",
      "2024-05-07 14:43:22,498 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210813 effective words) took 41.8s, 148444 effective words/s', 'datetime': '2024-05-07T14:43:22.498795', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:43:22,499 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:43:22.499793', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:43:22,506 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:43:22,827 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:43:23,798 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:43:23,798 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:43:24,048 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:43:24.048427', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:43:24,049 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:43:24.049424', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:43:24,334 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:43:24,344 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:43:24,346 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:43:24.346646', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:43:24,710 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:43:24,711 : INFO : resetting layer weights\n",
      "2024-05-07 14:43:24,730 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:43:24.730966', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:43:24,731 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:43:24.731963', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:43:25,846 : INFO : EPOCH 1 - PROGRESS: at 8.94% examples, 107370 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:26,912 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 132886 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:27,945 : INFO : EPOCH 1 - PROGRESS: at 35.75% examples, 142163 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:28,998 : INFO : EPOCH 1 - PROGRESS: at 49.16% examples, 146235 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:30,062 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 147134 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:31,083 : INFO : EPOCH 1 - PROGRESS: at 75.98% examples, 149974 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:32,112 : INFO : EPOCH 1 - PROGRESS: at 89.94% examples, 152680 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:43:32,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:32,873 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:32,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:32,895 : INFO : EPOCH - 1 : training on 1788017 raw words (1242512 effective words) took 8.1s, 153083 effective words/s\n",
      "2024-05-07 14:43:34,025 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 105409 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:35,033 : INFO : EPOCH 2 - PROGRESS: at 21.79% examples, 131916 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:36,042 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 140552 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:37,065 : INFO : EPOCH 2 - PROGRESS: at 48.60% examples, 147773 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:38,091 : INFO : EPOCH 2 - PROGRESS: at 62.01% examples, 149544 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:39,129 : INFO : EPOCH 2 - PROGRESS: at 74.86% examples, 150440 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:40,153 : INFO : EPOCH 2 - PROGRESS: at 86.03% examples, 148353 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:41,157 : INFO : EPOCH 2 - PROGRESS: at 97.77% examples, 148015 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:43:41,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:41,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:41,259 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:41,260 : INFO : EPOCH - 2 : training on 1788017 raw words (1242261 effective words) took 8.3s, 149311 effective words/s\n",
      "2024-05-07 14:43:42,429 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 102638 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:43,466 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 131617 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:44,478 : INFO : EPOCH 3 - PROGRESS: at 33.52% examples, 133443 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:45,499 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 132447 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:46,529 : INFO : EPOCH 3 - PROGRESS: at 57.54% examples, 137495 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:47,531 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 142969 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:48,570 : INFO : EPOCH 3 - PROGRESS: at 86.59% examples, 148455 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:49,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:49,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:49,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:49,548 : INFO : EPOCH - 3 : training on 1788017 raw words (1241964 effective words) took 8.2s, 150829 effective words/s\n",
      "2024-05-07 14:43:50,609 : INFO : EPOCH 4 - PROGRESS: at 9.50% examples, 120386 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:51,615 : INFO : EPOCH 4 - PROGRESS: at 23.46% examples, 147592 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:52,659 : INFO : EPOCH 4 - PROGRESS: at 36.87% examples, 151582 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:53,684 : INFO : EPOCH 4 - PROGRESS: at 50.28% examples, 154305 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:54,733 : INFO : EPOCH 4 - PROGRESS: at 64.80% examples, 156833 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:55,759 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 159100 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:56,771 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 162738 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:57,117 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:43:57,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:43:57,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:43:57,223 : INFO : EPOCH - 4 : training on 1788017 raw words (1242467 effective words) took 7.6s, 162951 effective words/s\n",
      "2024-05-07 14:43:58,364 : INFO : EPOCH 5 - PROGRESS: at 10.61% examples, 123986 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:43:59,373 : INFO : EPOCH 5 - PROGRESS: at 24.58% examples, 148061 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:00,393 : INFO : EPOCH 5 - PROGRESS: at 38.55% examples, 155312 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:01,395 : INFO : EPOCH 5 - PROGRESS: at 52.51% examples, 159270 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:02,410 : INFO : EPOCH 5 - PROGRESS: at 67.60% examples, 163189 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:03,440 : INFO : EPOCH 5 - PROGRESS: at 82.12% examples, 165423 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:04,514 : INFO : EPOCH 5 - PROGRESS: at 96.09% examples, 164978 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:04,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:44:04,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:44:04,741 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:44:04,742 : INFO : EPOCH - 5 : training on 1788017 raw words (1242214 effective words) took 7.5s, 166213 effective words/s\n",
      "2024-05-07 14:44:04,742 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211418 effective words) took 40.0s, 155244 effective words/s', 'datetime': '2024-05-07T14:44:04.742906', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:44:04,743 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:44:04.743902', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:44:04,753 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:44:05,071 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:44:05,972 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:44:05,973 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:44:06,149 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:44:06.149347', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:44:06,150 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:44:06.150652', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:44:06,386 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:44:06,392 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:44:06,393 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:44:06.393630', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:44:06,774 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2024-05-07 14:44:06,774 : INFO : resetting layer weights\n",
      "2024-05-07 14:44:06,801 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:44:06.801703', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:44:06,804 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:44:06.804470', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:44:07,868 : INFO : EPOCH 1 - PROGRESS: at 5.59% examples, 70864 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:08,874 : INFO : EPOCH 1 - PROGRESS: at 18.44% examples, 115944 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:09,883 : INFO : EPOCH 1 - PROGRESS: at 29.61% examples, 123760 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:10,924 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 126125 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:12,009 : INFO : EPOCH 1 - PROGRESS: at 54.19% examples, 131363 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:13,031 : INFO : EPOCH 1 - PROGRESS: at 67.04% examples, 134778 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:14,063 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 135008 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:15,139 : INFO : EPOCH 1 - PROGRESS: at 90.50% examples, 135971 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:15,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:44:15,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:44:15,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:44:15,914 : INFO : EPOCH - 1 : training on 1788017 raw words (1242590 effective words) took 9.1s, 137139 effective words/s\n",
      "2024-05-07 14:44:17,027 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 106924 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:18,045 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 128793 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:19,134 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 137254 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:20,147 : INFO : EPOCH 2 - PROGRESS: at 46.93% examples, 140555 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:21,254 : INFO : EPOCH 2 - PROGRESS: at 59.78% examples, 140423 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:22,324 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 139618 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:23,334 : INFO : EPOCH 2 - PROGRESS: at 84.36% examples, 142230 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:24,338 : INFO : EPOCH 2 - PROGRESS: at 97.21% examples, 144234 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:24,482 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:44:24,614 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:44:24,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:44:24,638 : INFO : EPOCH - 2 : training on 1788017 raw words (1241991 effective words) took 8.7s, 143054 effective words/s\n",
      "2024-05-07 14:44:25,817 : INFO : EPOCH 3 - PROGRESS: at 7.26% examples, 83907 words/s, in_qsize 3, out_qsize 2\n",
      "2024-05-07 14:44:26,841 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 102960 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:27,870 : INFO : EPOCH 3 - PROGRESS: at 27.93% examples, 112048 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:28,926 : INFO : EPOCH 3 - PROGRESS: at 39.66% examples, 118377 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:29,989 : INFO : EPOCH 3 - PROGRESS: at 51.40% examples, 121912 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:31,058 : INFO : EPOCH 3 - PROGRESS: at 63.13% examples, 123442 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:32,124 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 125539 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:33,160 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 128246 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:34,160 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 128609 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:44:34,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:44:34,299 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:44:34,303 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:44:34,304 : INFO : EPOCH - 3 : training on 1788017 raw words (1241921 effective words) took 9.6s, 129404 effective words/s\n",
      "2024-05-07 14:44:35,470 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 83968 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:36,489 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 113205 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:37,512 : INFO : EPOCH 4 - PROGRESS: at 31.28% examples, 125114 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:38,523 : INFO : EPOCH 4 - PROGRESS: at 43.02% examples, 129804 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:39,527 : INFO : EPOCH 4 - PROGRESS: at 54.75% examples, 132335 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:40,552 : INFO : EPOCH 4 - PROGRESS: at 65.36% examples, 131154 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:41,664 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 133211 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:42,675 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 137915 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:43,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:44:43,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:44:43,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:44:43,372 : INFO : EPOCH - 4 : training on 1788017 raw words (1242659 effective words) took 9.0s, 137870 effective words/s\n",
      "2024-05-07 14:44:44,543 : INFO : EPOCH 5 - PROGRESS: at 8.94% examples, 102000 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:45,552 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 113112 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:46,559 : INFO : EPOCH 5 - PROGRESS: at 29.61% examples, 119511 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:47,577 : INFO : EPOCH 5 - PROGRESS: at 41.90% examples, 126772 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:48,629 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 129967 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:49,637 : INFO : EPOCH 5 - PROGRESS: at 68.16% examples, 136146 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:50,660 : INFO : EPOCH 5 - PROGRESS: at 79.33% examples, 136393 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:51,703 : INFO : EPOCH 5 - PROGRESS: at 91.62% examples, 137622 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:52,322 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:44:52,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:44:52,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:44:52,373 : INFO : EPOCH - 5 : training on 1788017 raw words (1242289 effective words) took 9.0s, 138779 effective words/s\n",
      "2024-05-07 14:44:52,375 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211450 effective words) took 45.6s, 136319 effective words/s', 'datetime': '2024-05-07T14:44:52.375120', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:44:52,377 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:44:52.376000', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:44:52,387 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:44:52,723 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #21: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 44.60437520345052, 'train_time_std': 2.2490797831593503}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:44:53,667 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:44:53,670 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:44:53,879 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:44:53.879216', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:44:53,880 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:44:53.880725', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:44:54,117 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:44:54,122 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:44:54,123 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:44:54.123859', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:44:54,152 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:44:55,488 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:44:55,901 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:44:55,903 : INFO : resetting layer weights\n",
      "2024-05-07 14:44:55,926 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:44:55.926688', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:44:55,929 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:44:55.929673', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:44:57,038 : INFO : EPOCH 1 - PROGRESS: at 2.23% examples, 27395 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:44:58,043 : INFO : EPOCH 1 - PROGRESS: at 8.38% examples, 52405 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:44:59,207 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 55166 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:00,419 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 59349 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:01,568 : INFO : EPOCH 1 - PROGRESS: at 27.37% examples, 62264 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:02,672 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 64303 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:03,799 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 65777 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:04,890 : INFO : EPOCH 1 - PROGRESS: at 46.93% examples, 66206 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:05,974 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 65870 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:06,994 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 65206 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:08,089 : INFO : EPOCH 1 - PROGRESS: at 64.25% examples, 65983 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:09,175 : INFO : EPOCH 1 - PROGRESS: at 70.39% examples, 66360 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:10,187 : INFO : EPOCH 1 - PROGRESS: at 75.98% examples, 66607 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:11,266 : INFO : EPOCH 1 - PROGRESS: at 82.12% examples, 66863 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:12,384 : INFO : EPOCH 1 - PROGRESS: at 88.83% examples, 67422 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:13,487 : INFO : EPOCH 1 - PROGRESS: at 95.53% examples, 67936 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:14,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:45:14,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:45:14,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:45:14,134 : INFO : EPOCH - 1 : training on 1788017 raw words (1242342 effective words) took 18.1s, 68488 effective words/s\n",
      "2024-05-07 14:45:15,422 : INFO : EPOCH 2 - PROGRESS: at 3.91% examples, 41035 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:16,428 : INFO : EPOCH 2 - PROGRESS: at 10.06% examples, 57651 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:17,630 : INFO : EPOCH 2 - PROGRESS: at 15.64% examples, 57807 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:18,699 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 62891 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:19,796 : INFO : EPOCH 2 - PROGRESS: at 29.05% examples, 65734 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:20,812 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 65942 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:21,879 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 66810 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:23,000 : INFO : EPOCH 2 - PROGRESS: at 47.49% examples, 67696 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:24,133 : INFO : EPOCH 2 - PROGRESS: at 54.75% examples, 68821 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:25,167 : INFO : EPOCH 2 - PROGRESS: at 61.45% examples, 69615 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:26,194 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 70528 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:27,231 : INFO : EPOCH 2 - PROGRESS: at 75.42% examples, 71995 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:28,247 : INFO : EPOCH 2 - PROGRESS: at 81.56% examples, 72172 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:29,283 : INFO : EPOCH 2 - PROGRESS: at 88.27% examples, 72798 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:30,317 : INFO : EPOCH 2 - PROGRESS: at 94.41% examples, 72832 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:31,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:45:31,166 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:45:31,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:45:31,180 : INFO : EPOCH - 2 : training on 1788017 raw words (1242191 effective words) took 17.0s, 73142 effective words/s\n",
      "2024-05-07 14:45:32,302 : INFO : EPOCH 3 - PROGRESS: at 3.91% examples, 46992 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:33,377 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 63220 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:34,502 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 67151 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:35,651 : INFO : EPOCH 3 - PROGRESS: at 24.02% examples, 68884 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:36,665 : INFO : EPOCH 3 - PROGRESS: at 30.73% examples, 71331 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:37,684 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 72946 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:38,696 : INFO : EPOCH 3 - PROGRESS: at 44.69% examples, 75198 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:39,823 : INFO : EPOCH 3 - PROGRESS: at 52.51% examples, 76500 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:40,846 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 76632 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:41,860 : INFO : EPOCH 3 - PROGRESS: at 66.48% examples, 77665 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:42,867 : INFO : EPOCH 3 - PROGRESS: at 73.18% examples, 78170 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:43,970 : INFO : EPOCH 3 - PROGRESS: at 80.45% examples, 78575 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:44,974 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 78873 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:46,018 : INFO : EPOCH 3 - PROGRESS: at 93.85% examples, 78924 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:46,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:45:46,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:45:46,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:45:46,890 : INFO : EPOCH - 3 : training on 1788017 raw words (1242326 effective words) took 15.7s, 79329 effective words/s\n",
      "2024-05-07 14:45:47,970 : INFO : EPOCH 4 - PROGRESS: at 3.91% examples, 48969 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:48,995 : INFO : EPOCH 4 - PROGRESS: at 10.61% examples, 66221 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:50,014 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 71558 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:51,085 : INFO : EPOCH 4 - PROGRESS: at 24.02% examples, 73481 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:52,127 : INFO : EPOCH 4 - PROGRESS: at 31.28% examples, 76018 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:53,148 : INFO : EPOCH 4 - PROGRESS: at 38.55% examples, 78215 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:54,259 : INFO : EPOCH 4 - PROGRESS: at 45.81% examples, 78598 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:55,274 : INFO : EPOCH 4 - PROGRESS: at 53.63% examples, 80475 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:56,295 : INFO : EPOCH 4 - PROGRESS: at 60.34% examples, 80288 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:57,363 : INFO : EPOCH 4 - PROGRESS: at 67.60% examples, 80542 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:45:58,364 : INFO : EPOCH 4 - PROGRESS: at 74.30% examples, 80912 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:45:59,376 : INFO : EPOCH 4 - PROGRESS: at 81.01% examples, 81077 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:00,428 : INFO : EPOCH 4 - PROGRESS: at 87.15% examples, 80399 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:01,430 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 80563 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:02,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:46:02,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:46:02,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:46:02,359 : INFO : EPOCH - 4 : training on 1788017 raw words (1242168 effective words) took 15.4s, 80576 effective words/s\n",
      "2024-05-07 14:46:03,460 : INFO : EPOCH 5 - PROGRESS: at 4.47% examples, 54723 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:04,469 : INFO : EPOCH 5 - PROGRESS: at 11.17% examples, 69304 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:46:05,486 : INFO : EPOCH 5 - PROGRESS: at 18.44% examples, 76034 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:06,545 : INFO : EPOCH 5 - PROGRESS: at 24.58% examples, 75357 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:07,560 : INFO : EPOCH 5 - PROGRESS: at 31.28% examples, 76520 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:08,600 : INFO : EPOCH 5 - PROGRESS: at 38.55% examples, 78388 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:09,689 : INFO : EPOCH 5 - PROGRESS: at 45.25% examples, 78012 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:10,763 : INFO : EPOCH 5 - PROGRESS: at 52.51% examples, 78681 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:11,770 : INFO : EPOCH 5 - PROGRESS: at 60.34% examples, 80207 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:12,795 : INFO : EPOCH 5 - PROGRESS: at 68.16% examples, 81483 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:13,804 : INFO : EPOCH 5 - PROGRESS: at 75.42% examples, 82356 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:14,847 : INFO : EPOCH 5 - PROGRESS: at 82.68% examples, 82673 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:15,939 : INFO : EPOCH 5 - PROGRESS: at 90.50% examples, 83242 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:16,980 : INFO : EPOCH 5 - PROGRESS: at 97.77% examples, 83453 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:46:17,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:46:17,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:46:17,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:46:17,225 : INFO : EPOCH - 5 : training on 1788017 raw words (1242439 effective words) took 14.8s, 83842 effective words/s\n",
      "2024-05-07 14:46:17,226 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211466 effective words) took 81.3s, 76406 effective words/s', 'datetime': '2024-05-07T14:46:17.226485', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:46:17,226 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:46:17.226485', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:46:17,233 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:46:17,486 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:46:18,210 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:46:18,211 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:46:18,352 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:46:18.352506', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:46:18,354 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:46:18.354775', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:46:18,525 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:46:18,534 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:46:18,536 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:46:18.536580', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:46:18,559 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:46:19,636 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:46:19,911 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:46:19,912 : INFO : resetting layer weights\n",
      "2024-05-07 14:46:19,933 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:46:19.932648', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:46:19,935 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:46:19.935848', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:46:20,996 : INFO : EPOCH 1 - PROGRESS: at 5.03% examples, 63300 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:22,095 : INFO : EPOCH 1 - PROGRESS: at 12.29% examples, 73739 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:23,218 : INFO : EPOCH 1 - PROGRESS: at 19.55% examples, 76465 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:24,260 : INFO : EPOCH 1 - PROGRESS: at 25.70% examples, 75883 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:25,323 : INFO : EPOCH 1 - PROGRESS: at 32.96% examples, 77601 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:26,336 : INFO : EPOCH 1 - PROGRESS: at 40.22% examples, 79490 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:27,343 : INFO : EPOCH 1 - PROGRESS: at 48.60% examples, 82668 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:28,352 : INFO : EPOCH 1 - PROGRESS: at 56.98% examples, 84759 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:29,357 : INFO : EPOCH 1 - PROGRESS: at 65.92% examples, 87156 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:30,441 : INFO : EPOCH 1 - PROGRESS: at 73.74% examples, 87510 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:31,441 : INFO : EPOCH 1 - PROGRESS: at 81.56% examples, 88355 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:32,459 : INFO : EPOCH 1 - PROGRESS: at 88.83% examples, 88442 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:33,679 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 87144 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:34,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:46:34,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:46:34,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:46:34,374 : INFO : EPOCH - 1 : training on 1788017 raw words (1241664 effective words) took 14.4s, 86214 effective words/s\n",
      "2024-05-07 14:46:35,576 : INFO : EPOCH 2 - PROGRESS: at 5.59% examples, 61599 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:36,652 : INFO : EPOCH 2 - PROGRESS: at 12.29% examples, 69829 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:37,732 : INFO : EPOCH 2 - PROGRESS: at 20.67% examples, 78921 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:38,762 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 79695 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:39,827 : INFO : EPOCH 2 - PROGRESS: at 34.08% examples, 79232 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:40,830 : INFO : EPOCH 2 - PROGRESS: at 41.90% examples, 82020 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:41,884 : INFO : EPOCH 2 - PROGRESS: at 49.72% examples, 83429 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:42,884 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 84617 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:43,937 : INFO : EPOCH 2 - PROGRESS: at 66.48% examples, 86655 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:44,938 : INFO : EPOCH 2 - PROGRESS: at 74.86% examples, 88417 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:46,071 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 89352 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:47,109 : INFO : EPOCH 2 - PROGRESS: at 92.74% examples, 90800 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:47,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:46:47,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:46:47,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:46:47,924 : INFO : EPOCH - 2 : training on 1788017 raw words (1242038 effective words) took 13.5s, 91893 effective words/s\n",
      "2024-05-07 14:46:48,965 : INFO : EPOCH 3 - PROGRESS: at 6.15% examples, 77996 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:50,048 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 95048 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:51,108 : INFO : EPOCH 3 - PROGRESS: at 24.02% examples, 96633 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:52,117 : INFO : EPOCH 3 - PROGRESS: at 32.40% examples, 98199 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:53,179 : INFO : EPOCH 3 - PROGRESS: at 41.34% examples, 99587 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:54,197 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 102151 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:55,216 : INFO : EPOCH 3 - PROGRESS: at 60.89% examples, 104300 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:56,266 : INFO : EPOCH 3 - PROGRESS: at 69.83% examples, 104419 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:46:57,273 : INFO : EPOCH 3 - PROGRESS: at 79.33% examples, 105962 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:58,339 : INFO : EPOCH 3 - PROGRESS: at 88.83% examples, 106430 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:46:59,361 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 106638 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:46:59,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:46:59,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:46:59,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:46:59,556 : INFO : EPOCH - 3 : training on 1788017 raw words (1242114 effective words) took 11.6s, 107087 effective words/s\n",
      "2024-05-07 14:47:00,593 : INFO : EPOCH 4 - PROGRESS: at 6.15% examples, 78220 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:01,708 : INFO : EPOCH 4 - PROGRESS: at 15.64% examples, 93618 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:02,740 : INFO : EPOCH 4 - PROGRESS: at 24.58% examples, 98937 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:03,778 : INFO : EPOCH 4 - PROGRESS: at 34.08% examples, 102493 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:04,793 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 102569 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:05,804 : INFO : EPOCH 4 - PROGRESS: at 51.40% examples, 103670 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:06,815 : INFO : EPOCH 4 - PROGRESS: at 60.34% examples, 103874 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:07,918 : INFO : EPOCH 4 - PROGRESS: at 70.39% examples, 104996 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:09,002 : INFO : EPOCH 4 - PROGRESS: at 80.45% examples, 106322 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:10,085 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 107310 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:10,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:47:11,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:47:11,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:47:11,044 : INFO : EPOCH - 4 : training on 1788017 raw words (1242231 effective words) took 11.5s, 108445 effective words/s\n",
      "2024-05-07 14:47:12,248 : INFO : EPOCH 5 - PROGRESS: at 7.26% examples, 80252 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:13,365 : INFO : EPOCH 5 - PROGRESS: at 17.32% examples, 96507 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:14,383 : INFO : EPOCH 5 - PROGRESS: at 26.26% examples, 100962 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:15,447 : INFO : EPOCH 5 - PROGRESS: at 34.08% examples, 98454 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:16,455 : INFO : EPOCH 5 - PROGRESS: at 41.90% examples, 98080 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:17,455 : INFO : EPOCH 5 - PROGRESS: at 49.72% examples, 97863 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:18,549 : INFO : EPOCH 5 - PROGRESS: at 59.22% examples, 98749 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:19,616 : INFO : EPOCH 5 - PROGRESS: at 68.72% examples, 100001 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:20,624 : INFO : EPOCH 5 - PROGRESS: at 77.09% examples, 100578 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:21,689 : INFO : EPOCH 5 - PROGRESS: at 85.47% examples, 100203 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:22,695 : INFO : EPOCH 5 - PROGRESS: at 93.30% examples, 99892 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:23,386 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:47:23,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:47:23,517 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:47:23,518 : INFO : EPOCH - 5 : training on 1788017 raw words (1241730 effective words) took 12.4s, 99886 effective words/s\n",
      "2024-05-07 14:47:23,519 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209777 effective words) took 63.6s, 97664 effective words/s', 'datetime': '2024-05-07T14:47:23.519646', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:47:23,521 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:47:23.521497', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:47:23,538 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:47:23,758 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:47:24,364 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:47:24,365 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:47:24,502 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:47:24.502877', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:47:24,503 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:47:24.503930', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:47:24,669 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:47:24,683 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:47:24,683 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:47:24.683745', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:47:24,697 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:47:25,740 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:47:26,003 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:47:26,003 : INFO : resetting layer weights\n",
      "2024-05-07 14:47:26,020 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:47:26.020411', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:47:26,021 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:47:26.021394', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:47:27,105 : INFO : EPOCH 1 - PROGRESS: at 5.59% examples, 68639 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:28,236 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 81352 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:29,319 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 86877 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:30,413 : INFO : EPOCH 1 - PROGRESS: at 30.73% examples, 89019 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:31,499 : INFO : EPOCH 1 - PROGRESS: at 39.11% examples, 90490 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:32,511 : INFO : EPOCH 1 - PROGRESS: at 48.04% examples, 93459 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:33,581 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 95350 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:34,597 : INFO : EPOCH 1 - PROGRESS: at 67.04% examples, 97536 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:35,628 : INFO : EPOCH 1 - PROGRESS: at 73.18% examples, 95104 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:36,636 : INFO : EPOCH 1 - PROGRESS: at 79.89% examples, 93965 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:37,711 : INFO : EPOCH 1 - PROGRESS: at 88.83% examples, 94846 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:38,852 : INFO : EPOCH 1 - PROGRESS: at 97.77% examples, 95055 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:47:38,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:47:39,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:47:39,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:47:39,037 : INFO : EPOCH - 1 : training on 1788017 raw words (1242346 effective words) took 13.0s, 95712 effective words/s\n",
      "2024-05-07 14:47:40,087 : INFO : EPOCH 2 - PROGRESS: at 5.59% examples, 70725 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:41,230 : INFO : EPOCH 2 - PROGRESS: at 15.64% examples, 91995 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:42,291 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 94623 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:43,331 : INFO : EPOCH 2 - PROGRESS: at 32.96% examples, 97552 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:44,332 : INFO : EPOCH 2 - PROGRESS: at 41.34% examples, 98813 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:45,368 : INFO : EPOCH 2 - PROGRESS: at 49.16% examples, 97971 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:46,448 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 97242 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:47,527 : INFO : EPOCH 2 - PROGRESS: at 65.36% examples, 96070 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:48,566 : INFO : EPOCH 2 - PROGRESS: at 72.63% examples, 95092 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:49,614 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 94947 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:50,680 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 95174 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:51,736 : INFO : EPOCH 2 - PROGRESS: at 95.53% examples, 93817 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:52,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:47:52,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:47:52,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:47:52,338 : INFO : EPOCH - 2 : training on 1788017 raw words (1242102 effective words) took 13.3s, 93645 effective words/s\n",
      "2024-05-07 14:47:53,522 : INFO : EPOCH 3 - PROGRESS: at 2.23% examples, 25149 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:54,662 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 50104 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:55,782 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 64509 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:56,862 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 72560 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:57,882 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 77993 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:47:58,908 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 80628 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:47:59,978 : INFO : EPOCH 3 - PROGRESS: at 47.49% examples, 78390 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:00,993 : INFO : EPOCH 3 - PROGRESS: at 54.75% examples, 79356 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:02,102 : INFO : EPOCH 3 - PROGRESS: at 63.13% examples, 80609 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:03,190 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 82202 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:04,202 : INFO : EPOCH 3 - PROGRESS: at 79.89% examples, 84026 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:05,218 : INFO : EPOCH 3 - PROGRESS: at 88.83% examples, 86020 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:06,247 : INFO : EPOCH 3 - PROGRESS: at 97.21% examples, 87153 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:06,462 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:48:06,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:48:06,594 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:48:06,595 : INFO : EPOCH - 3 : training on 1788017 raw words (1242191 effective words) took 14.2s, 87356 effective words/s\n",
      "2024-05-07 14:48:07,695 : INFO : EPOCH 4 - PROGRESS: at 5.59% examples, 68161 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:08,715 : INFO : EPOCH 4 - PROGRESS: at 15.08% examples, 92267 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:09,803 : INFO : EPOCH 4 - PROGRESS: at 24.02% examples, 96348 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:10,812 : INFO : EPOCH 4 - PROGRESS: at 33.52% examples, 101353 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:11,849 : INFO : EPOCH 4 - PROGRESS: at 41.90% examples, 101225 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:12,927 : INFO : EPOCH 4 - PROGRESS: at 49.16% examples, 98153 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:13,955 : INFO : EPOCH 4 - PROGRESS: at 58.10% examples, 98975 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:14,996 : INFO : EPOCH 4 - PROGRESS: at 67.04% examples, 99677 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:16,014 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 100164 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:17,092 : INFO : EPOCH 4 - PROGRESS: at 82.12% examples, 97749 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:18,117 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 98178 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:19,496 : INFO : EPOCH 4 - PROGRESS: at 96.09% examples, 93016 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:20,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:48:20,148 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:48:20,175 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:48:20,176 : INFO : EPOCH - 4 : training on 1788017 raw words (1242421 effective words) took 13.5s, 91803 effective words/s\n",
      "2024-05-07 14:48:21,424 : INFO : EPOCH 5 - PROGRESS: at 3.91% examples, 42234 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:22,473 : INFO : EPOCH 5 - PROGRESS: at 8.94% examples, 51125 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:23,582 : INFO : EPOCH 5 - PROGRESS: at 15.64% examples, 59308 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:24,776 : INFO : EPOCH 5 - PROGRESS: at 22.35% examples, 62386 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:25,887 : INFO : EPOCH 5 - PROGRESS: at 27.93% examples, 62701 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:27,081 : INFO : EPOCH 5 - PROGRESS: at 32.96% examples, 60716 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:28,162 : INFO : EPOCH 5 - PROGRESS: at 37.43% examples, 59417 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:29,191 : INFO : EPOCH 5 - PROGRESS: at 43.02% examples, 60365 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:30,365 : INFO : EPOCH 5 - PROGRESS: at 48.04% examples, 59516 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:31,512 : INFO : EPOCH 5 - PROGRESS: at 53.63% examples, 59463 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:32,520 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 59458 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:33,627 : INFO : EPOCH 5 - PROGRESS: at 63.69% examples, 59113 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:34,744 : INFO : EPOCH 5 - PROGRESS: at 69.83% examples, 59831 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:35,861 : INFO : EPOCH 5 - PROGRESS: at 75.42% examples, 60067 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:37,217 : INFO : EPOCH 5 - PROGRESS: at 81.01% examples, 59377 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:48:38,384 : INFO : EPOCH 5 - PROGRESS: at 85.47% examples, 58582 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:39,479 : INFO : EPOCH 5 - PROGRESS: at 90.50% examples, 58538 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:40,654 : INFO : EPOCH 5 - PROGRESS: at 96.09% examples, 58546 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:40,995 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:48:41,219 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:48:41,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:48:41,255 : INFO : EPOCH - 5 : training on 1788017 raw words (1242379 effective words) took 21.0s, 59103 effective words/s\n",
      "2024-05-07 14:48:41,258 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211439 effective words) took 75.2s, 82559 effective words/s', 'datetime': '2024-05-07T14:48:41.258868', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:48:41,259 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:48:41.259872', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:48:41,284 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #22: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 76.29865209261577, 'train_time_std': 7.637534456941762}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 14:48:41,659 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:48:43,198 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:48:43,203 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:48:43,526 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:48:43.526362', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:48:43,527 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:48:43.527360', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:48:43,904 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:48:43,909 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:48:43,910 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:48:43.910889', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:48:43,934 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:48:46,118 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:48:46,703 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:48:46,704 : INFO : resetting layer weights\n",
      "2024-05-07 14:48:46,727 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:48:46.726346', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:48:46,727 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:48:46.727343', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:48:47,824 : INFO : EPOCH 1 - PROGRESS: at 2.23% examples, 27954 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:48,846 : INFO : EPOCH 1 - PROGRESS: at 8.38% examples, 52223 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:49,909 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 56799 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:50,910 : INFO : EPOCH 1 - PROGRESS: at 18.44% examples, 56810 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:52,077 : INFO : EPOCH 1 - PROGRESS: at 25.14% examples, 60271 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:53,102 : INFO : EPOCH 1 - PROGRESS: at 31.28% examples, 62435 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:54,254 : INFO : EPOCH 1 - PROGRESS: at 37.99% examples, 64041 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:55,255 : INFO : EPOCH 1 - PROGRESS: at 44.13% examples, 65473 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:56,439 : INFO : EPOCH 1 - PROGRESS: at 50.84% examples, 65952 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:57,572 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 66511 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:48:58,583 : INFO : EPOCH 1 - PROGRESS: at 63.69% examples, 67094 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:48:59,688 : INFO : EPOCH 1 - PROGRESS: at 70.39% examples, 67815 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:00,690 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 68530 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:01,709 : INFO : EPOCH 1 - PROGRESS: at 83.80% examples, 69870 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:02,746 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 71013 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:03,850 : INFO : EPOCH 1 - PROGRESS: at 97.77% examples, 71299 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:49:03,906 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:49:04,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:49:04,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:49:04,104 : INFO : EPOCH - 1 : training on 1788017 raw words (1242341 effective words) took 17.3s, 71756 effective words/s\n",
      "2024-05-07 14:49:05,235 : INFO : EPOCH 2 - PROGRESS: at 3.35% examples, 41366 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:06,331 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 53542 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:07,494 : INFO : EPOCH 2 - PROGRESS: at 15.08% examples, 57955 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:08,604 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 61055 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:09,614 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 64006 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:10,712 : INFO : EPOCH 2 - PROGRESS: at 32.96% examples, 63718 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:11,844 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 64315 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:12,895 : INFO : EPOCH 2 - PROGRESS: at 45.25% examples, 65261 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:13,901 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 65628 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:49:14,986 : INFO : EPOCH 2 - PROGRESS: at 56.98% examples, 65794 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:16,119 : INFO : EPOCH 2 - PROGRESS: at 63.69% examples, 66338 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:49:17,242 : INFO : EPOCH 2 - PROGRESS: at 69.83% examples, 66489 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:18,273 : INFO : EPOCH 2 - PROGRESS: at 75.98% examples, 67144 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:19,337 : INFO : EPOCH 2 - PROGRESS: at 82.12% examples, 67429 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:20,390 : INFO : EPOCH 2 - PROGRESS: at 87.71% examples, 67374 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:21,514 : INFO : EPOCH 2 - PROGRESS: at 93.85% examples, 67388 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:22,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:49:22,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:49:22,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:49:22,499 : INFO : EPOCH - 2 : training on 1788017 raw words (1242222 effective words) took 18.3s, 67860 effective words/s\n",
      "2024-05-07 14:49:23,606 : INFO : EPOCH 3 - PROGRESS: at 3.35% examples, 41543 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:24,658 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 54909 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:25,782 : INFO : EPOCH 3 - PROGRESS: at 15.08% examples, 59640 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:26,839 : INFO : EPOCH 3 - PROGRESS: at 21.23% examples, 63176 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:27,873 : INFO : EPOCH 3 - PROGRESS: at 26.26% examples, 62815 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:49:28,897 : INFO : EPOCH 3 - PROGRESS: at 31.84% examples, 63525 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:29,967 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 63712 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:30,969 : INFO : EPOCH 3 - PROGRESS: at 43.58% examples, 65221 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:32,024 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 65296 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:33,205 : INFO : EPOCH 3 - PROGRESS: at 55.31% examples, 64979 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:49:34,306 : INFO : EPOCH 3 - PROGRESS: at 62.01% examples, 65710 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:35,480 : INFO : EPOCH 3 - PROGRESS: at 68.16% examples, 65590 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:36,530 : INFO : EPOCH 3 - PROGRESS: at 74.30% examples, 66222 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:37,545 : INFO : EPOCH 3 - PROGRESS: at 80.45% examples, 66880 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:38,701 : INFO : EPOCH 3 - PROGRESS: at 86.03% examples, 66362 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:39,758 : INFO : EPOCH 3 - PROGRESS: at 92.18% examples, 66741 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:40,762 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 66867 words/s, in_qsize 4, out_qsize 0\n",
      "2024-05-07 14:49:40,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:49:41,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:49:41,024 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:49:41,028 : INFO : EPOCH - 3 : training on 1788017 raw words (1242424 effective words) took 18.5s, 67316 effective words/s\n",
      "2024-05-07 14:49:42,153 : INFO : EPOCH 4 - PROGRESS: at 3.35% examples, 40861 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:43,174 : INFO : EPOCH 4 - PROGRESS: at 8.38% examples, 51806 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:44,205 : INFO : EPOCH 4 - PROGRESS: at 14.53% examples, 59365 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:45,211 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 60429 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:46,409 : INFO : EPOCH 4 - PROGRESS: at 26.26% examples, 62707 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:47,422 : INFO : EPOCH 4 - PROGRESS: at 32.40% examples, 64637 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:48,455 : INFO : EPOCH 4 - PROGRESS: at 38.55% examples, 66008 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:49,552 : INFO : EPOCH 4 - PROGRESS: at 44.13% examples, 65609 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:50,576 : INFO : EPOCH 4 - PROGRESS: at 50.28% examples, 66520 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:51,741 : INFO : EPOCH 4 - PROGRESS: at 56.98% examples, 66772 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:52,868 : INFO : EPOCH 4 - PROGRESS: at 63.69% examples, 67259 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:49:53,975 : INFO : EPOCH 4 - PROGRESS: at 69.83% examples, 67407 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:55,104 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 68040 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:56,155 : INFO : EPOCH 4 - PROGRESS: at 82.68% examples, 68319 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:57,311 : INFO : EPOCH 4 - PROGRESS: at 89.39% examples, 68621 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:49:58,341 : INFO : EPOCH 4 - PROGRESS: at 94.41% examples, 68126 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:49:59,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:49:59,239 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:49:59,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:49:59,294 : INFO : EPOCH - 4 : training on 1788017 raw words (1242677 effective words) took 18.2s, 68302 effective words/s\n",
      "2024-05-07 14:50:00,498 : INFO : EPOCH 5 - PROGRESS: at 2.23% examples, 25399 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:01,616 : INFO : EPOCH 5 - PROGRESS: at 7.82% examples, 44532 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:02,620 : INFO : EPOCH 5 - PROGRESS: at 13.97% examples, 54473 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:03,842 : INFO : EPOCH 5 - PROGRESS: at 19.55% examples, 55475 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:50:04,980 : INFO : EPOCH 5 - PROGRESS: at 26.26% examples, 59329 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:06,182 : INFO : EPOCH 5 - PROGRESS: at 32.96% examples, 61010 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:07,312 : INFO : EPOCH 5 - PROGRESS: at 39.66% examples, 62886 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:08,462 : INFO : EPOCH 5 - PROGRESS: at 46.37% examples, 63993 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:09,518 : INFO : EPOCH 5 - PROGRESS: at 52.51% examples, 64774 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:10,530 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 65457 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:11,566 : INFO : EPOCH 5 - PROGRESS: at 64.80% examples, 66000 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:12,592 : INFO : EPOCH 5 - PROGRESS: at 70.39% examples, 66138 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:13,700 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 66464 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:14,702 : INFO : EPOCH 5 - PROGRESS: at 82.68% examples, 67065 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:15,828 : INFO : EPOCH 5 - PROGRESS: at 88.83% examples, 67127 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:16,832 : INFO : EPOCH 5 - PROGRESS: at 94.97% examples, 67638 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:17,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:50:17,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:50:17,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:50:17,693 : INFO : EPOCH - 5 : training on 1788017 raw words (1242330 effective words) took 18.3s, 67786 effective words/s\n",
      "2024-05-07 14:50:17,694 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211994 effective words) took 91.0s, 68290 effective words/s', 'datetime': '2024-05-07T14:50:17.694487', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:50:17,695 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:50:17.695488', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:50:17,715 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:50:18,109 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:50:19,327 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:50:19,328 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:50:19,563 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:50:19.563899', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:50:19,564 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:50:19.564896', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:50:19,868 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:50:19,879 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:50:19,881 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:50:19.881105', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:50:19,911 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:50:21,389 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:50:21,891 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:50:21,893 : INFO : resetting layer weights\n",
      "2024-05-07 14:50:21,913 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:50:21.913568', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:50:21,914 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:50:21.914566', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:50:23,182 : INFO : EPOCH 1 - PROGRESS: at 3.91% examples, 41775 words/s, in_qsize 3, out_qsize 2\n",
      "2024-05-07 14:50:24,393 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 56194 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:25,567 : INFO : EPOCH 1 - PROGRESS: at 18.99% examples, 67202 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:26,581 : INFO : EPOCH 1 - PROGRESS: at 26.82% examples, 73859 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:27,630 : INFO : EPOCH 1 - PROGRESS: at 34.64% examples, 77170 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:28,661 : INFO : EPOCH 1 - PROGRESS: at 41.90% examples, 78812 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:29,716 : INFO : EPOCH 1 - PROGRESS: at 50.28% examples, 81416 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:30,893 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 80430 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:31,894 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 78375 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:32,934 : INFO : EPOCH 1 - PROGRESS: at 68.72% examples, 77889 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:33,946 : INFO : EPOCH 1 - PROGRESS: at 74.30% examples, 77184 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:35,033 : INFO : EPOCH 1 - PROGRESS: at 79.89% examples, 76102 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:36,083 : INFO : EPOCH 1 - PROGRESS: at 86.03% examples, 75844 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:37,197 : INFO : EPOCH 1 - PROGRESS: at 92.74% examples, 75777 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:38,151 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:50:38,276 : INFO : EPOCH 1 - PROGRESS: at 99.44% examples, 75772 words/s, in_qsize 1, out_qsize 1\n",
      "2024-05-07 14:50:38,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:50:38,305 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:50:38,306 : INFO : EPOCH - 1 : training on 1788017 raw words (1242178 effective words) took 16.3s, 76061 effective words/s\n",
      "2024-05-07 14:50:39,599 : INFO : EPOCH 2 - PROGRESS: at 3.91% examples, 41861 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:40,712 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 58547 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:41,770 : INFO : EPOCH 2 - PROGRESS: at 16.76% examples, 63030 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:42,814 : INFO : EPOCH 2 - PROGRESS: at 23.46% examples, 67379 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:43,934 : INFO : EPOCH 2 - PROGRESS: at 29.61% examples, 67728 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:44,955 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 68655 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:46,157 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 68829 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:47,173 : INFO : EPOCH 2 - PROGRESS: at 48.60% examples, 69531 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:48,243 : INFO : EPOCH 2 - PROGRESS: at 54.75% examples, 69492 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:49,348 : INFO : EPOCH 2 - PROGRESS: at 60.34% examples, 68558 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:50,397 : INFO : EPOCH 2 - PROGRESS: at 66.48% examples, 68831 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:51,503 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 67825 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:50:52,554 : INFO : EPOCH 2 - PROGRESS: at 77.65% examples, 68290 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:53,698 : INFO : EPOCH 2 - PROGRESS: at 82.68% examples, 67247 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:54,736 : INFO : EPOCH 2 - PROGRESS: at 88.27% examples, 67241 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:50:55,760 : INFO : EPOCH 2 - PROGRESS: at 93.85% examples, 67236 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:56,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:50:56,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:50:56,791 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 67558 words/s, in_qsize 0, out_qsize 1\n",
      "2024-05-07 14:50:56,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:50:56,793 : INFO : EPOCH - 2 : training on 1788017 raw words (1242663 effective words) took 18.4s, 67549 effective words/s\n",
      "2024-05-07 14:50:57,879 : INFO : EPOCH 3 - PROGRESS: at 2.23% examples, 28440 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:50:58,920 : INFO : EPOCH 3 - PROGRESS: at 7.82% examples, 48805 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:00,000 : INFO : EPOCH 3 - PROGRESS: at 13.41% examples, 54344 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:01,004 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 58268 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:02,040 : INFO : EPOCH 3 - PROGRESS: at 24.58% examples, 60259 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:03,054 : INFO : EPOCH 3 - PROGRESS: at 30.17% examples, 61499 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:04,081 : INFO : EPOCH 3 - PROGRESS: at 35.75% examples, 62338 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:05,098 : INFO : EPOCH 3 - PROGRESS: at 41.34% examples, 63140 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:06,245 : INFO : EPOCH 3 - PROGRESS: at 47.49% examples, 63516 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:07,325 : INFO : EPOCH 3 - PROGRESS: at 53.63% examples, 64082 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:08,486 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 63426 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:09,537 : INFO : EPOCH 3 - PROGRESS: at 64.80% examples, 63522 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:10,620 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 63582 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:11,658 : INFO : EPOCH 3 - PROGRESS: at 75.98% examples, 63908 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:12,673 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 64608 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:13,737 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 64259 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:14,804 : INFO : EPOCH 3 - PROGRESS: at 92.18% examples, 63908 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:16,006 : INFO : EPOCH 3 - PROGRESS: at 97.21% examples, 63173 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:16,308 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:51:16,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:51:16,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:51:16,421 : INFO : EPOCH - 3 : training on 1788017 raw words (1242331 effective words) took 19.6s, 63524 effective words/s\n",
      "2024-05-07 14:51:17,538 : INFO : EPOCH 4 - PROGRESS: at 2.23% examples, 27516 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:18,722 : INFO : EPOCH 4 - PROGRESS: at 8.38% examples, 48065 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:19,783 : INFO : EPOCH 4 - PROGRESS: at 14.53% examples, 55909 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:20,836 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 57051 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:21,884 : INFO : EPOCH 4 - PROGRESS: at 25.14% examples, 59014 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:22,889 : INFO : EPOCH 4 - PROGRESS: at 29.61% examples, 58499 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:24,147 : INFO : EPOCH 4 - PROGRESS: at 35.20% examples, 57811 words/s, in_qsize 6, out_qsize 1\n",
      "2024-05-07 14:51:25,150 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 59224 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:26,308 : INFO : EPOCH 4 - PROGRESS: at 46.37% examples, 59211 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:27,317 : INFO : EPOCH 4 - PROGRESS: at 51.96% examples, 60051 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:28,328 : INFO : EPOCH 4 - PROGRESS: at 55.87% examples, 58855 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:29,365 : INFO : EPOCH 4 - PROGRESS: at 59.22% examples, 57229 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:30,515 : INFO : EPOCH 4 - PROGRESS: at 64.80% examples, 57370 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:31,553 : INFO : EPOCH 4 - PROGRESS: at 68.72% examples, 56641 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:32,581 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 56508 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:33,648 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 56684 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:34,673 : INFO : EPOCH 4 - PROGRESS: at 82.68% examples, 56534 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:35,733 : INFO : EPOCH 4 - PROGRESS: at 87.71% examples, 56679 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:36,748 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 56569 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:37,759 : INFO : EPOCH 4 - PROGRESS: at 97.21% examples, 56823 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:38,089 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:51:38,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:51:38,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:51:38,328 : INFO : EPOCH - 4 : training on 1788017 raw words (1241670 effective words) took 21.8s, 56858 effective words/s\n",
      "2024-05-07 14:51:39,604 : INFO : EPOCH 5 - PROGRESS: at 2.23% examples, 23896 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:40,684 : INFO : EPOCH 5 - PROGRESS: at 7.26% examples, 40768 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:41,739 : INFO : EPOCH 5 - PROGRESS: at 11.73% examples, 44864 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:42,897 : INFO : EPOCH 5 - PROGRESS: at 16.76% examples, 47365 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:43,992 : INFO : EPOCH 5 - PROGRESS: at 21.79% examples, 49432 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:45,057 : INFO : EPOCH 5 - PROGRESS: at 26.26% examples, 50028 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:46,098 : INFO : EPOCH 5 - PROGRESS: at 31.84% examples, 52201 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:47,383 : INFO : EPOCH 5 - PROGRESS: at 37.43% examples, 52463 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:48,398 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 53388 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:49,513 : INFO : EPOCH 5 - PROGRESS: at 47.49% examples, 53666 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:50,517 : INFO : EPOCH 5 - PROGRESS: at 52.51% examples, 54255 words/s, in_qsize 4, out_qsize 1\n",
      "2024-05-07 14:51:51,547 : INFO : EPOCH 5 - PROGRESS: at 56.98% examples, 54066 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:52,551 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 54961 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:53,881 : INFO : EPOCH 5 - PROGRESS: at 68.16% examples, 54696 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:54,938 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 55031 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:55,958 : INFO : EPOCH 5 - PROGRESS: at 78.21% examples, 55449 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:57,014 : INFO : EPOCH 5 - PROGRESS: at 83.24% examples, 55643 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:51:58,228 : INFO : EPOCH 5 - PROGRESS: at 88.83% examples, 55742 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:51:59,416 : INFO : EPOCH 5 - PROGRESS: at 93.85% examples, 55555 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:00,417 : INFO : EPOCH 5 - PROGRESS: at 98.32% examples, 55564 words/s, in_qsize 3, out_qsize 0\n",
      "2024-05-07 14:52:00,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:52:00,598 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:52:00,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:52:00,720 : INFO : EPOCH - 5 : training on 1788017 raw words (1242330 effective words) took 22.3s, 55666 effective words/s\n",
      "2024-05-07 14:52:00,721 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211172 effective words) took 98.8s, 62863 effective words/s', 'datetime': '2024-05-07T14:52:00.721085', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:52:00,727 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:52:00.727078', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2024-05-07 14:52:00,754 : INFO : collecting all words and their counts\n",
      "2024-05-07 14:52:01,263 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-07 14:52:02,853 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2024-05-07 14:52:02,856 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 14:52:03,198 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2024-05-07T14:52:03.198985', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:52:03,199 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2024-05-07T14:52:03.199962', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:52:03,645 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2024-05-07 14:52:03,654 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2024-05-07 14:52:03,656 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2024-05-07T14:52:03.656095', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 14:52:03,694 : INFO : constructing a huffman tree from 20167 words\n",
      "2024-05-07 14:52:05,612 : INFO : built huffman tree with maximum node depth 18\n",
      "2024-05-07 14:52:06,231 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2024-05-07 14:52:06,232 : INFO : resetting layer weights\n",
      "2024-05-07 14:52:06,257 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-07T14:52:06.257777', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2024-05-07 14:52:06,260 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T14:52:06.260885', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:52:07,423 : INFO : EPOCH 1 - PROGRESS: at 2.23% examples, 26499 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:08,435 : INFO : EPOCH 1 - PROGRESS: at 7.82% examples, 47653 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:09,641 : INFO : EPOCH 1 - PROGRESS: at 13.41% examples, 51504 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:10,714 : INFO : EPOCH 1 - PROGRESS: at 18.44% examples, 53458 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:11,754 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 56201 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:12,763 : INFO : EPOCH 1 - PROGRESS: at 29.05% examples, 57279 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:13,784 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 57664 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:14,832 : INFO : EPOCH 1 - PROGRESS: at 39.11% examples, 57978 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:15,847 : INFO : EPOCH 1 - PROGRESS: at 44.13% examples, 58295 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:17,014 : INFO : EPOCH 1 - PROGRESS: at 49.72% examples, 58417 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:18,017 : INFO : EPOCH 1 - PROGRESS: at 55.31% examples, 59120 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:19,105 : INFO : EPOCH 1 - PROGRESS: at 61.45% examples, 59834 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:20,150 : INFO : EPOCH 1 - PROGRESS: at 67.04% examples, 60289 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:21,306 : INFO : EPOCH 1 - PROGRESS: at 73.18% examples, 60787 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:22,366 : INFO : EPOCH 1 - PROGRESS: at 78.77% examples, 61149 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:23,429 : INFO : EPOCH 1 - PROGRESS: at 84.36% examples, 61419 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:24,440 : INFO : EPOCH 1 - PROGRESS: at 89.94% examples, 61840 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:25,443 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 61823 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:26,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:52:26,342 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:52:26,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:52:26,392 : INFO : EPOCH - 1 : training on 1788017 raw words (1242321 effective words) took 20.1s, 61934 effective words/s\n",
      "2024-05-07 14:52:27,520 : INFO : EPOCH 2 - PROGRESS: at 2.23% examples, 27267 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:28,530 : INFO : EPOCH 2 - PROGRESS: at 7.82% examples, 48479 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:29,550 : INFO : EPOCH 2 - PROGRESS: at 13.41% examples, 55178 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:30,782 : INFO : EPOCH 2 - PROGRESS: at 18.99% examples, 55868 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:31,812 : INFO : EPOCH 2 - PROGRESS: at 25.14% examples, 59611 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:32,979 : INFO : EPOCH 2 - PROGRESS: at 30.73% examples, 59499 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:34,082 : INFO : EPOCH 2 - PROGRESS: at 36.87% examples, 60882 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:35,212 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 60971 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:36,324 : INFO : EPOCH 2 - PROGRESS: at 48.60% examples, 61851 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:37,423 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 61776 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:38,477 : INFO : EPOCH 2 - PROGRESS: at 60.34% examples, 62475 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:39,496 : INFO : EPOCH 2 - PROGRESS: at 65.92% examples, 62809 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:40,559 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 63066 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:41,719 : INFO : EPOCH 2 - PROGRESS: at 77.09% examples, 62922 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:43,007 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 63017 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:44,053 : INFO : EPOCH 2 - PROGRESS: at 89.39% examples, 63234 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:45,092 : INFO : EPOCH 2 - PROGRESS: at 94.41% examples, 63042 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:45,761 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:52:45,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:52:46,000 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:52:46,004 : INFO : EPOCH - 2 : training on 1788017 raw words (1242306 effective words) took 19.5s, 63581 effective words/s\n",
      "2024-05-07 14:52:47,125 : INFO : EPOCH 3 - PROGRESS: at 2.23% examples, 27325 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:48,128 : INFO : EPOCH 3 - PROGRESS: at 8.38% examples, 52242 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:49,273 : INFO : EPOCH 3 - PROGRESS: at 13.97% examples, 55345 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:50,577 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 53549 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:51,826 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 49252 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:52,859 : INFO : EPOCH 3 - PROGRESS: at 27.37% examples, 51135 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:53,873 : INFO : EPOCH 3 - PROGRESS: at 32.96% examples, 53258 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:54,880 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 52652 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:55,963 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 53241 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:57,019 : INFO : EPOCH 3 - PROGRESS: at 48.04% examples, 55049 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:52:58,140 : INFO : EPOCH 3 - PROGRESS: at 53.63% examples, 55518 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:52:59,181 : INFO : EPOCH 3 - PROGRESS: at 59.78% examples, 56707 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:00,191 : INFO : EPOCH 3 - PROGRESS: at 65.36% examples, 57506 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:01,349 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 58153 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:02,490 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 59278 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:03,565 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 59994 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:04,727 : INFO : EPOCH 3 - PROGRESS: at 91.06% examples, 60735 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:05,740 : INFO : EPOCH 3 - PROGRESS: at 97.21% examples, 61473 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:06,029 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:53:06,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:53:06,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:53:06,336 : INFO : EPOCH - 3 : training on 1788017 raw words (1242141 effective words) took 20.3s, 61302 effective words/s\n",
      "2024-05-07 14:53:07,676 : INFO : EPOCH 4 - PROGRESS: at 3.91% examples, 39443 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:08,758 : INFO : EPOCH 4 - PROGRESS: at 10.06% examples, 54596 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:09,758 : INFO : EPOCH 4 - PROGRESS: at 16.20% examples, 61260 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:10,787 : INFO : EPOCH 4 - PROGRESS: at 21.23% examples, 61417 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:11,974 : INFO : EPOCH 4 - PROGRESS: at 27.93% examples, 63572 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:13,059 : INFO : EPOCH 4 - PROGRESS: at 34.64% examples, 65525 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:14,228 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 65609 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:15,252 : INFO : EPOCH 4 - PROGRESS: at 46.37% examples, 65758 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:16,402 : INFO : EPOCH 4 - PROGRESS: at 52.51% examples, 65745 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:17,431 : INFO : EPOCH 4 - PROGRESS: at 58.66% examples, 66239 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:18,490 : INFO : EPOCH 4 - PROGRESS: at 64.25% examples, 66040 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:19,524 : INFO : EPOCH 4 - PROGRESS: at 69.83% examples, 66139 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:20,556 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 66318 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:21,730 : INFO : EPOCH 4 - PROGRESS: at 82.12% examples, 66625 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:22,771 : INFO : EPOCH 4 - PROGRESS: at 88.27% examples, 67106 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:23,772 : INFO : EPOCH 4 - PROGRESS: at 94.41% examples, 67606 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:24,809 : INFO : EPOCH 4 - PROGRESS: at 98.32% examples, 66459 words/s, in_qsize 3, out_qsize 0\n",
      "2024-05-07 14:53:24,909 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:53:25,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:53:25,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:53:25,050 : INFO : EPOCH - 4 : training on 1788017 raw words (1242259 effective words) took 18.6s, 66616 effective words/s\n",
      "2024-05-07 14:53:26,321 : INFO : EPOCH 5 - PROGRESS: at 3.91% examples, 42464 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:27,416 : INFO : EPOCH 5 - PROGRESS: at 10.06% examples, 56404 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:28,418 : INFO : EPOCH 5 - PROGRESS: at 16.20% examples, 62637 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:29,424 : INFO : EPOCH 5 - PROGRESS: at 20.67% examples, 61231 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:30,440 : INFO : EPOCH 5 - PROGRESS: at 25.14% examples, 60112 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:31,458 : INFO : EPOCH 5 - PROGRESS: at 30.73% examples, 61344 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:32,480 : INFO : EPOCH 5 - PROGRESS: at 35.75% examples, 61275 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:33,525 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 61210 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:34,526 : INFO : EPOCH 5 - PROGRESS: at 45.81% examples, 61232 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:35,571 : INFO : EPOCH 5 - PROGRESS: at 50.84% examples, 61053 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:36,649 : INFO : EPOCH 5 - PROGRESS: at 56.98% examples, 61735 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:37,723 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 61762 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:38,915 : INFO : EPOCH 5 - PROGRESS: at 68.72% examples, 61953 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:40,017 : INFO : EPOCH 5 - PROGRESS: at 74.86% examples, 62579 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:41,038 : INFO : EPOCH 5 - PROGRESS: at 79.89% examples, 62505 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:42,070 : INFO : EPOCH 5 - PROGRESS: at 85.47% examples, 62779 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-07 14:53:43,085 : INFO : EPOCH 5 - PROGRESS: at 91.06% examples, 63134 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:44,096 : INFO : EPOCH 5 - PROGRESS: at 96.09% examples, 63057 words/s, in_qsize 6, out_qsize 0\n",
      "2024-05-07 14:53:44,506 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2024-05-07 14:53:44,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2024-05-07 14:53:44,728 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2024-05-07 14:53:44,729 : INFO : EPOCH - 5 : training on 1788017 raw words (1242419 effective words) took 19.6s, 63407 effective words/s\n",
      "2024-05-07 14:53:44,730 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211446 effective words) took 98.5s, 63080 effective words/s', 'datetime': '2024-05-07T14:53:44.730883', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2024-05-07 14:53:44,731 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2024-05-07T14:53:44.731903', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #23: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 101.15597867965698, 'train_time_std': 3.364319659538593}\n",
      "   train_data  compute_loss  sg  hs  train_time_mean  train_time_std\n",
      "4        25kB          True   1   0         0.874524        0.026599\n",
      "5        25kB         False   1   0         0.837606        0.051528\n",
      "6        25kB          True   1   1         1.678334        0.063938\n",
      "7        25kB         False   1   1         1.671332        0.054492\n",
      "0        25kB          True   0   0         0.526081        0.077177\n",
      "1        25kB         False   0   0         0.553888        0.022924\n",
      "2        25kB          True   0   1         0.803109        0.058140\n",
      "3        25kB         False   0   1         0.816609        0.060893\n",
      "12        1MB          True   1   0         3.097496        0.095374\n",
      "13        1MB         False   1   0         3.263569        0.129919\n",
      "14        1MB          True   1   1         5.921029        0.593726\n",
      "15        1MB         False   1   1         5.589968        0.248631\n",
      "8         1MB          True   0   0         1.130064        0.025197\n",
      "9         1MB         False   0   0         1.199664        0.084304\n",
      "10        1MB          True   0   1         1.902780        0.068003\n",
      "11        1MB         False   0   1         2.035825        0.195007\n",
      "20       10MB          True   1   0        35.540812        0.712204\n",
      "21       10MB         False   1   0        44.604375        2.249080\n",
      "22       10MB          True   1   1        76.298652        7.637534\n",
      "23       10MB         False   1   1       101.155979        3.364320\n",
      "16       10MB          True   0   0        11.741263        1.107861\n",
      "17       10MB         False   0   0        11.965096        2.193017\n",
      "18       10MB          True   0   1        24.094276        2.050139\n",
      "19       10MB         False   0   1        23.061164        1.599109\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reduce logging verbosity\n",
    "logging.root.level = logging.ERROR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_time_values = []\n",
    "seed_val = 42\n",
    "sg_values = [0, 1]\n",
    "hs_values = [0, 1]\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    input_data_subset = input_data[:3]\n",
    "else:\n",
    "    input_data_subset = input_data\n",
    "\n",
    "\n",
    "for data in input_data_subset:\n",
    "    for sg_val in sg_values:\n",
    "        for hs_val in hs_values:\n",
    "            for loss_flag in [True, False]:\n",
    "                time_taken_list = []\n",
    "                for i in range(3):\n",
    "                    start_time = time.time()\n",
    "                    w2v_model = gensim.models.Word2Vec(\n",
    "                        data,\n",
    "                        compute_loss=loss_flag,\n",
    "                        sg=sg_val,\n",
    "                        hs=hs_val,\n",
    "                        seed=seed_val,\n",
    "                    )\n",
    "                    time_taken_list.append(time.time() - start_time)\n",
    "\n",
    "                time_taken_list = np.array(time_taken_list)\n",
    "                time_mean = np.mean(time_taken_list)\n",
    "                time_std = np.std(time_taken_list)\n",
    "\n",
    "                model_result = {\n",
    "                    'train_data': data.name,\n",
    "                    'compute_loss': loss_flag,\n",
    "                    'sg': sg_val,\n",
    "                    'hs': hs_val,\n",
    "                    'train_time_mean': time_mean,\n",
    "                    'train_time_std': time_std,\n",
    "                }\n",
    "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
    "                train_time_values.append(model_result)\n",
    "\n",
    "train_times_table = pd.DataFrame(train_time_values)\n",
    "train_times_table = train_times_table.sort_values(\n",
    "    by=['train_data', 'sg', 'hs', 'compute_loss'],\n",
    "    ascending=[False, False, True, False],\n",
    ")\n",
    "print(train_times_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising Word Embeddings\n",
    "---------------------------\n",
    "\n",
    "The word embeddings made by the model can be visualised by reducing\n",
    "dimensionality of the words to 2 dimensions using tSNE.\n",
    "\n",
    "Visualisations can be used to notice semantic and syntactic trends in the data.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Semantic: words like cat, dog, cow, etc. have a tendency to lie close by\n",
    "* Syntactic: words like run, running or cut, cutting lie close together.\n",
    "\n",
    "Vector relations like vKing - vMan = vQueen - vWoman can also be noticed.\n",
    "\n",
    ".. Important::\n",
    "  The model used for the visualisation is trained on a small corpus. Thus\n",
    "  some of the relations might not be so clear.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:35:33.087685100Z",
     "start_time": "2024-05-07T06:35:33.072727800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    # extract the words & their vectors, as numpy arrays\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial we learned how to train word2vec models on your custom data\n",
    "and also how to evaluate it. Hope that you too will find this popular tool\n",
    "useful in your Machine Learning tasks!\n",
    "\n",
    "Links\n",
    "-----\n",
    "\n",
    "- API docs: :py:mod:`gensim.models.word2vec`\n",
    "- `Original C toolkit and word2vec papers by Google <https://code.google.com/archive/p/word2vec/>`_.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
